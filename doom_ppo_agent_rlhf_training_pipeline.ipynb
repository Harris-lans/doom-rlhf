{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLHF Trainining Pipeline for PPO Agent to Play Levels from the Doom Game\n",
    "\n",
    "## Creating UI Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from typing import Callable\n",
    "from datetime import datetime\n",
    "\n",
    "# Function for rendering widgets\n",
    "def create_html_heading(text, level=1, centered=True):\n",
    "    html_tag = f'<h{level}>{text}</h{level}>'\n",
    "    layout = widgets.Layout(display='flex', justify_content='center') if centered else None\n",
    "    return widgets.HTML(html_tag, layout=layout)\n",
    "\n",
    "def create_video_player(video_path: str):\n",
    "    return widgets.Video.from_file(video_path)\n",
    "\n",
    "def create_button(description, tooltip, button_style=''):\n",
    "    return widgets.Button(description=description, disabled=False, button_style=button_style,\n",
    "                          tooltip=tooltip, layout=widgets.Layout(display='flex', justify_content='center', margin='4px'))\n",
    "\n",
    "def create_loading_spinner():\n",
    "    css = \"\"\"\n",
    "    .loader {\n",
    "        border: 8px solid #f3f3f3;\n",
    "        border-top: 8px solid #3498db;\n",
    "        border-radius: 50%;\n",
    "        width: 100px;\n",
    "        height: 100px;\n",
    "        animation: spin 2s linear infinite;\n",
    "    }\n",
    "\n",
    "    @keyframes spin {\n",
    "        0% { transform: rotate(0deg); }\n",
    "        100% { transform: rotate(360deg); }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Create the custom CSS and apply it to the heading\n",
    "    heading_style = widgets.HTML(f'<style>{css}</style>')\n",
    "    # Create the loading spinner widget\n",
    "    loading_spinner = widgets.HTML('<div class=\"loader\"></div>', layout=widgets.Layout(display='flex', justify_content='center'))\n",
    "    \n",
    "    return heading_style, loading_spinner\n",
    "\n",
    "def create_preference_selection_component(trajectory_1_video_path: str, trajectory_2_video_path: str, on_trajectory_1_chosen: Callable, on_trajectory_2_chosen: Callable, on_both_trajectories_chosen: Callable):\n",
    "    # Creating GUI Components\n",
    "    window_label = create_html_heading('Which trajectory do you prefer?', centered=True)\n",
    "    trajectory_1_label = create_html_heading('Trajectory 1', level=2, centered=True)\n",
    "    trajectory_2_label = create_html_heading('Trajectory 2', level=2, centered=True)\n",
    "    trajectory_1_video_player = create_video_player(trajectory_1_video_path)\n",
    "    trajectory_2_video_player = create_video_player(trajectory_2_video_path)\n",
    "    prefer_trajectory_1_button = create_button('Select 1', 'You prefer Trajectory 1')\n",
    "    prefer_trajectory_2_button = create_button('Select 2', 'You prefer Trajectory 2')\n",
    "    prefer_both_trajectories_button = create_button('Both', 'You prefer both Trajectories')\n",
    "    \n",
    "    prefer_trajectory_1_button.on_click(on_trajectory_1_chosen)\n",
    "    prefer_trajectory_2_button.on_click(on_trajectory_2_chosen)\n",
    "    prefer_both_trajectories_button.on_click(on_both_trajectories_chosen)\n",
    "\n",
    "    window_label.layout.flex = '1'\n",
    "\n",
    "    # Rendering components\n",
    "    preference_selection_layout = widgets.VBox([\n",
    "        window_label,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                trajectory_1_label,\n",
    "                trajectory_1_video_player,\n",
    "                prefer_trajectory_1_button\n",
    "            ], layout=widgets.Layout(align_items='center', justify_content='space-between', width='40%', height='100%')),\n",
    "            widgets.VBox([\n",
    "                trajectory_2_label,\n",
    "                trajectory_2_video_player,\n",
    "                prefer_trajectory_2_button\n",
    "            ], layout=widgets.Layout(align_items='center', justify_content='space-between', width='40%', height='100%'))\n",
    "        ], layout=widgets.Layout(justify_content='space-between', flex='4', width='100%')),\n",
    "        widgets.HBox([\n",
    "            prefer_both_trajectories_button\n",
    "        ], layout=widgets.Layout(justify_content='space-between', flex='1'))\n",
    "    ], layout=widgets.Layout(align_items='center', justify_content='space-between'))\n",
    "\n",
    "    return preference_selection_layout\n",
    "\n",
    "def create_loading_component(message):\n",
    "    # Create the heading widget and apply the style\n",
    "    heading = create_html_heading(message, centered=True)\n",
    "    # Create the loading spinner widget\n",
    "    heading_style, loading_spinner = create_loading_spinner()\n",
    "\n",
    "    # Create the outer VBox layout with widgets\n",
    "    outer_vbox = widgets.VBox([heading_style, heading, loading_spinner], layout=widgets.Layout(align_items='center', justify_content='center'))\n",
    "\n",
    "    return outer_vbox\n",
    "\n",
    "def create_logs_component():\n",
    "    logs_label = widgets.HTML('<h1>Logs</h1>')\n",
    "    logs_output = widgets.Output(description=\"Output\")\n",
    "    logs_layout = widgets.VBox([\n",
    "            logs_label,\n",
    "            widgets.Box([\n",
    "                logs_output\n",
    "            ], layout=widgets.Layout(flex='1', width='98%', overflow_y='scroll'))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return logs_layout, logs_output\n",
    "\n",
    "logs_component, logs_output = create_logs_component()\n",
    "layout = widgets.HBox([])\n",
    "\n",
    "def hide_all_screens():\n",
    "    layout.children = []\n",
    "\n",
    "def show_preference_selection_screen(trajectory_1_video_path: str, trajectory_2_video_path: str, on_trajectory_1_chosen: Callable, on_trajectory_2_chosen: Callable, on_both_trajectories_chosen: Callable):\n",
    "    preference_selection_component = create_preference_selection_component(trajectory_1_video_path, trajectory_2_video_path, on_trajectory_1_chosen, on_trajectory_2_chosen, on_both_trajectories_chosen)\n",
    "\n",
    "    # Updating layout of components to fit the screen layout\n",
    "    preference_selection_component.layout.padding = '15px' \n",
    "    preference_selection_component.layout.margin = '7.5px' \n",
    "    preference_selection_component.layout.border = '3px dashed cornflowerblue' \n",
    "    preference_selection_component.layout.flex = '1' \n",
    "    preference_selection_component.layout.height = '600px'\n",
    "\n",
    "    layout.children = [ preference_selection_component ]\n",
    "\n",
    "def show_loading_screen(message: str):\n",
    "    loading_component = create_loading_component(message)\n",
    "\n",
    "    # Updating layout of components to fit the screen layout\n",
    "    loading_component.layout.padding = '15px'\n",
    "    loading_component.layout.margin = '7.5px' \n",
    "    loading_component.layout.border = '3px dashed cornflowerblue' \n",
    "    loading_component.layout.flex = '1' \n",
    "    loading_component.layout.height = '600px'\n",
    "\n",
    "    layout.children = [ loading_component ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_info(message: str):\n",
    "    current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    message = f\"[{current_timestamp}][INFO] {message}\"\n",
    "    print(message)\n",
    "\n",
    "def log_error(message: str):\n",
    "    current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    message = f\"[{current_timestamp}][ERROR] {message}\\n\"\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from utils.video import generate_video_from_doom_play_segments\n",
    "import random\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import asyncio\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from utils.replay_buffer import ReplayBuffer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from agents.doom_ppo_agent import DoomPpoAgent\n",
    "from reward_predictors.doom_human_preference_reward_predictor import DoomHumanPreferenceRewardPredictor\n",
    "import gymnasium as gym\n",
    "\n",
    "# Recording start time\n",
    "start_datetime = datetime.now()\n",
    "start_datetime_timestamp_str = start_datetime.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "start_time = start_datetime.timestamp()\n",
    "\n",
    "def ask_user_for_preference(trajectory_1_video_path: str, trajectory_2_video_path: str):\n",
    "    future = asyncio.Future()\n",
    "\n",
    "    def on_trajectory_1_chosen(_):\n",
    "        future.set_result(0)\n",
    "    \n",
    "    def on_trajectory_2_chosen(_):\n",
    "        future.set_result(1)\n",
    "    \n",
    "    def on_both_trajectories_chosen(_):\n",
    "        future.set_result(0.5)\n",
    "\n",
    "    show_preference_selection_screen(trajectory_1_video_path, trajectory_2_video_path, on_trajectory_1_chosen, on_trajectory_2_chosen, on_both_trajectories_chosen)\n",
    "\n",
    "    return future\n",
    "\n",
    "def create_random_pairs(elements):\n",
    "    # Shuffle the elements array\n",
    "    shuffled_elements = elements.copy()\n",
    "    random.shuffle(shuffled_elements)\n",
    "    \n",
    "    # Create pairs of consecutive elements\n",
    "    pairs = [(shuffled_elements[i], shuffled_elements[i+1]) for i in range(0, len(shuffled_elements), 2)]\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "async def pre_train(envs: gym.vector.SyncVectorEnv, \n",
    "                    agent: DoomPpoAgent, \n",
    "                    reward_predictor: DoomHumanPreferenceRewardPredictor,\n",
    "                    pipeline_args: dict,\n",
    "                    reward_predictor_args: dict):\n",
    "    # Creating replay buffer for storing transition for training\n",
    "    replay_buffer = ReplayBuffer(pipeline_args.get('env_replay_buffer_size'), \n",
    "                                 envs.num_envs, \n",
    "                                 envs.envs[0].raw_observation_space, \n",
    "                                 envs.single_observation_space, \n",
    "                                 envs.single_action_space)\n",
    "\n",
    "    # Initializing pre-training variables \n",
    "    global_step = 0\n",
    "    observations, infos = envs.reset()\n",
    "    terminations = [0 for _ in range(envs.num_envs)]\n",
    "    current_num_preference_requests = 0\n",
    "    all_preferences_collected = False\n",
    "\n",
    "    while not all_preferences_collected:\n",
    "        show_loading_screen(f\"Exploring Enviroment to Pre-Train Reward Predictor...\")\n",
    "        \n",
    "        for step in range(0, replay_buffer.num_steps_per_env):\n",
    "            global_step += envs.num_envs\n",
    "\n",
    "            # Getting next action and it's value\n",
    "            actions, log_probs, probs, values = agent.forward(observations)\n",
    "            values = values.flatten()\n",
    "            \n",
    "            # Performing actions in the environments\n",
    "            observations_, _, terminations_, _, infos = envs.step(actions)\n",
    "\n",
    "            # Predicting reward for the observations and the corresponding actions\n",
    "            rewards = reward_predictor.forward(observations)\n",
    "\n",
    "            # Saving transitions in replay buffer\n",
    "            replay_buffer[step] = (\n",
    "                np.stack(infos[\"raw_observations\"]),\n",
    "                observations,\n",
    "                actions,\n",
    "                log_probs,\n",
    "                rewards,\n",
    "                values,\n",
    "                terminations\n",
    "            )\n",
    "\n",
    "            # Saving new observation and termination status for next step\n",
    "            observations = observations_\n",
    "            terminations = terminations_\n",
    "\n",
    "        # Preparing trajectories and videos for asking user for preference\n",
    "        show_loading_screen(\"Preparing trajectories for asking user for preference...\")\n",
    "        # Generating segments from replay buffer\n",
    "        segments = replay_buffer.get_segments(segment_length=pipeline_args.get('num_frames_in_trajectory_video'))\n",
    "        # Remove on segment if there are odd number of segments\n",
    "        segments = segments if len(segments) % 2 == 0 else segments[:-1]\n",
    "        trajectory_pairs = create_random_pairs(segments)\n",
    "\n",
    "        # Collecting human preferences and training\n",
    "        for trajectory_1, trajectory_2 in trajectory_pairs:\n",
    "            generate_video_from_doom_play_segments(trajectory_1, './temp/trajectory_1.mp4')\n",
    "            generate_video_from_doom_play_segments(trajectory_2, './temp/trajectory_2.mp4')\n",
    "            \n",
    "            # Asking user for their preference\n",
    "            user_preference = await ask_user_for_preference('./temp/trajectory_1.mp4', './temp/trajectory_2.mp4')\n",
    "\n",
    "            # Training reward predictor based on the user preference\n",
    "            log_info(f\"user_preference = {user_preference}\")\n",
    "            show_loading_screen(\"Pre-training reward predictor...\")\n",
    "            reward_predictor_training_stats = reward_predictor.train(trajectory_1, trajectory_2, user_preference, reward_predictor_args.get('num_training_epochs'))\n",
    "            log_info(f\"reward_predictor_training_loss={reward_predictor_training_stats['loss']}\")\n",
    "            current_num_preference_requests += 1\n",
    "\n",
    "            log_info(f\"Recieved {current_num_preference_requests} preferences!\")\n",
    "\n",
    "            # Exiting the preference collection loop if the target number of requests is met\n",
    "            if current_num_preference_requests >= pipeline_args.get('num_pre_train_requests'):\n",
    "                all_preferences_collected = True\n",
    "                break\n",
    "        \n",
    "    # Saving pre-training model\n",
    "    model_save_path = f\"./models/rlhf_pipeline/training_run_{start_datetime_timestamp_str}/doom_reward_predictor/pre_training\"\n",
    "    log_info(f\"Saving pre-training reward predictor model to `{model_save_path}`...\")\n",
    "    reward_predictor.save_models(model_save_path)\n",
    "    log_info(f\"Successfully saved pre-training reward predictor model to `{model_save_path}`!\")\n",
    "\n",
    "async def train(envs: gym.vector.SyncVectorEnv, \n",
    "                agent: DoomPpoAgent, \n",
    "                reward_predictor: DoomHumanPreferenceRewardPredictor,\n",
    "                pipeline_args: dict,\n",
    "                agent_args: dict,\n",
    "                reward_predictor_args: dict):\n",
    "    # Setting up other training config \n",
    "    batch_size = int(envs.num_envs * pipeline_args.get('env_replay_buffer_size'))\n",
    "    mini_batch_size = batch_size // agent_args.get('num_mini_batches')\n",
    "    num_updates = pipeline_args.get('total_timesteps') // batch_size\n",
    "\n",
    "    print(f\"num_training_epochs={agent_args.get('num_training_epochs')}\")\n",
    "\n",
    "    # Creating replay buffer for storing transition for training\n",
    "    replay_buffer = ReplayBuffer(pipeline_args.get('env_replay_buffer_size'), \n",
    "                                 envs.num_envs, \n",
    "                                 envs.envs[0].raw_observation_space, \n",
    "                                 envs.single_observation_space, \n",
    "                                 envs.single_action_space)\n",
    "\n",
    "    # Setting up Tensorboard for saving training stats if requested\n",
    "    if pipeline_args.get('track_stats'):\n",
    "        tensorboard_writer = SummaryWriter(f\"logs/doom_basic_level/rlhf_training_{start_datetime_timestamp_str}\")\n",
    "\n",
    "    # Initializing variables for tracking the training process \n",
    "    global_step = 0\n",
    "    agent_training_iteration = 0 \n",
    "    observations, infos = envs.reset()\n",
    "    terminations = [0 for _ in range(envs.num_envs)]\n",
    "    reward_predictor_reward_sums = np.zeros(envs.num_envs, dtype=np.float32)\n",
    "    env_reward_sums = np.zeros(envs.num_envs, dtype=np.float32)\n",
    "    reward_predictor_episodic_returns = []\n",
    "\n",
    "\n",
    "    for update in range(1, num_updates + 1):\n",
    "        show_loading_screen(f\"Training PPO Agent...\")\n",
    "        \n",
    "        for step in range(0, replay_buffer.num_steps_per_env):\n",
    "            global_step += envs.num_envs\n",
    "\n",
    "            # Getting next action and it's value\n",
    "            actions, log_probs, probs, values = agent.forward(observations)\n",
    "            values = values.flatten()\n",
    "            \n",
    "            # Performing actions in the environments\n",
    "            observations_, env_rewards, terminations_, _, infos = envs.step(actions)\n",
    "\n",
    "            # Predicting reward for the observations and the corresponding actions\n",
    "            rewards = reward_predictor.forward(observations)\n",
    "            reward_predictor_reward_sums = reward_predictor_reward_sums + rewards\n",
    "            env_reward_sums = env_reward_sums + env_rewards\n",
    "\n",
    "            # Saving transitions in replay buffer\n",
    "            replay_buffer[step] = (\n",
    "                np.stack(infos[\"raw_observations\"]),\n",
    "                observations,\n",
    "                actions,\n",
    "                log_probs,\n",
    "                rewards,\n",
    "                values,\n",
    "                terminations\n",
    "            )\n",
    "\n",
    "            # Saving new observation and termination status for next step\n",
    "            observations = observations_\n",
    "            terminations = terminations_\n",
    "\n",
    "            # Record episodic returns based on reward predictor rewards and environment rewards\n",
    "            for index, termination in enumerate(terminations):\n",
    "                if termination == 1:\n",
    "                    reward_predictor_reward_sum = reward_predictor_reward_sums[index]\n",
    "                    env_reward_sum = env_reward_sums[index]\n",
    "\n",
    "                    reward_predictor_episodic_returns.append(reward_predictor_reward_sum)\n",
    "\n",
    "                    log_info(f\"global_step={global_step}, episodic_reward_predictor_return={reward_predictor_reward_sum}\")\n",
    "                    log_info(f\"global_step={global_step}, episodic_env_return={env_reward_sum}\")\n",
    "\n",
    "                    # Writing reward stats to TensorBoard\n",
    "                    if pipeline_args.get('track_stats'):\n",
    "                        tensorboard_writer.add_scalar(\"ppo_agent/charts/episodic_reward_predictor_return\", reward_predictor_reward_sum, global_step)\n",
    "                        tensorboard_writer.add_scalar(\"ppo_agent/charts/episodic_env_return\", env_reward_sum, global_step)\n",
    "\n",
    "                    # Resetting rewards sum\n",
    "                    reward_predictor_reward_sums[index] = 0\n",
    "                    env_reward_sums[index] = 0\n",
    "\n",
    "        # Calculating current mean episodic return\n",
    "        current_mean_episodic_return = np.mean(reward_predictor_episodic_returns)\n",
    "        reward_predictor_episodic_returns.clear()\n",
    "        log_info(f\"Current Mean Episodic Return = {current_mean_episodic_return}\")\n",
    "\n",
    "        # Checking if the current mean is higher than previous highest mean \n",
    "        # and if the number of steps taken exceeds the model save threshold, and then saving the model\n",
    "        # if current_mean_episodic_return > best_average_return:\n",
    "        # Saving the model\n",
    "        model_save_path = f\"./models/rlhf_pipeline/training_run_{start_datetime_timestamp_str}/doom_ppo_agent/checkpoint_step_{global_step}\"\n",
    "        log_info(f\"Saving models to `{model_save_path}`...\")\n",
    "        agent.save_models(model_save_path)\n",
    "        log_info(f\"Successfully saved models to `{model_save_path}`!\")\n",
    "            \n",
    "        # Calculating learning rate annealing coefficient for the agent\n",
    "        lr_anneal_coef = 1.0 - (update - 1.0) / num_updates\n",
    "\n",
    "        # Training the agent\n",
    "        agent_training_stats = agent.train(\n",
    "            replay_buffer=replay_buffer,\n",
    "            gamma=agent_args.get('gamma'),\n",
    "            enable_gae=agent_args.get('enable_gae'),\n",
    "            gae_lambda=agent_args.get('gae_lambda'),\n",
    "            clip_value_loss=agent_args.get('clip_value_loss'),\n",
    "            clip_coef=agent_args.get('clip_coef'),\n",
    "            max_norm_grad=agent_args.get('max_norm_grad'),\n",
    "            value_coef=agent_args.get('value_coef'),\n",
    "            entropy_coef=agent_args.get('entropy_coef'),\n",
    "            lr_anneal_coef=lr_anneal_coef,\n",
    "            target_kl=agent_args.get('target_kl'),\n",
    "            norm_adv=agent_args.get('norm_adv'),\n",
    "            mini_batch_size=mini_batch_size,\n",
    "            num_training_epochs=agent_args.get('num_training_epochs'),\n",
    "        )\n",
    "        agent_training_iteration += 1\n",
    "        log_info(f\"SPS: {int(global_step / (time.time() - start_time))}\")\n",
    "\n",
    "        if pipeline_args.get('track_stats'):\n",
    "            tensorboard_writer.add_scalar(\"charts/learning_rate\", agent_training_stats.learning_rate, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/losses/value_loss\", agent_training_stats.value_loss, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/losses/policy_loss\", agent_training_stats.policy_loss, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/losses/entropy_loss\", agent_training_stats.entropy_loss, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/charts/old_approx_kl\", agent_training_stats.old_approx_kl, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/charts/approx_kl\", agent_training_stats.approx_kl, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/charts/clip_fraction\", agent_training_stats.clip_fraction, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/charts/explained_variance\", agent_training_stats.explained_variance, global_step)\n",
    "            tensorboard_writer.add_scalar(\"ppo_agent/charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "        if agent_training_iteration % pipeline_args.get('training_phase_human_feedback_interval') == 0:\n",
    "            # Preparing trajectories and videos for asking user for preference\n",
    "            show_loading_screen(\"Preparing trajectories for asking user for preference...\")\n",
    "            segments = replay_buffer.get_segments(segment_length=pipeline_args.get('num_frames_in_trajectory_video'))\n",
    "\n",
    "            trajectory_pairs = create_random_pairs(segments)\n",
    "\n",
    "            for trajectory_1, trajectory_2 in trajectory_pairs:\n",
    "                generate_video_from_doom_play_segments(trajectory_1, './temp/trajectory_1.mp4')\n",
    "                generate_video_from_doom_play_segments(trajectory_2, './temp/trajectory_2.mp4')\n",
    "                \n",
    "                # Asking user for their preference\n",
    "                user_preference = await ask_user_for_preference('./temp/trajectory_1.mp4', './temp/trajectory_2.mp4')\n",
    "                log_info(f\"user_preference = {user_preference}\")\n",
    "\n",
    "                # Training reward predictor based on the user preference\n",
    "                show_loading_screen(\"Pre-training reward predictor...\")\n",
    "                reward_predictor_training_stats = reward_predictor.train(trajectory_1, trajectory_2, user_preference, reward_predictor_args.get('num_training_epochs'))\n",
    "                log_info(f\"reward_predictor_training_loss={reward_predictor_training_stats['loss']}\")\n",
    "\n",
    "                if pipeline_args.get('track_stats'):\n",
    "                    # Writing loss value to tensorboard\n",
    "                    tensorboard_writer.add_scalar(\"reward_predictor/losses/loss\", reward_predictor_training_stats[\"loss\"], global_step)\n",
    "\n",
    "async def run_training_pipeline(envs: gym.vector.SyncVectorEnv, \n",
    "                                agent: DoomPpoAgent, \n",
    "                                reward_predictor: DoomHumanPreferenceRewardPredictor,\n",
    "                                pipeline_args: dict,\n",
    "                                agent_args: dict,\n",
    "                                reward_predictor_args: dict):\n",
    "    try:\n",
    "        if pipeline_args.get('enable_pre_training'):\n",
    "            await pre_train(envs, \n",
    "                            agent, \n",
    "                            reward_predictor, \n",
    "                            pipeline_args=pipeline_args,\n",
    "                            reward_predictor_args=reward_predictor_args)\n",
    "        await train(envs, \n",
    "                    agent, \n",
    "                    reward_predictor, \n",
    "                    pipeline_args,\n",
    "                    agent_args,\n",
    "                    reward_predictor_args)\n",
    "    except Exception as error:\n",
    "                # Catch the error and print the entire stack trace\n",
    "                traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Training Pipeline\n",
    "\n",
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_args = {\n",
    "    'env_cfg': 'envs/vizdoom/scenarios/basic.cfg',\n",
    "    'total_timesteps': 300000,\n",
    "    'render_env': True,\n",
    "    'model_save_threshold': 4000,\n",
    "    'enable_gpu': True,\n",
    "    'track_stats': True,\n",
    "    'num_envs': 8,\n",
    "    'env_replay_buffer_size': 256,\n",
    "    'enable_pre_training': True,\n",
    "    'num_pre_train_requests': 250,\n",
    "    'num_frames_in_trajectory_video': 64,\n",
    "    'training_phase_human_feedback_interval': 7\n",
    "}\n",
    "\n",
    "agent_args = {\n",
    "    'learning_rate': 0.0001,\n",
    "    'anneal_lr': True,\n",
    "    'enable_gae': True,\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    'num_mini_batches': 32,\n",
    "    'num_training_epochs': 10,\n",
    "    'norm_adv': True,\n",
    "    'clip_coef': 0.1,\n",
    "    'clip_value_loss': True,\n",
    "    'entropy_coef': 0.01,\n",
    "    'value_coef': 0.5,\n",
    "    'max_norm_grad': 0.5,\n",
    "    'target_kl': None\n",
    "}\n",
    "\n",
    "reward_predictor_args = {\n",
    "    'learning_rate': 1e-4,\n",
    "    'hidden_layer_size': 64,\n",
    "    'num_training_epochs': 1,\n",
    "    # 'model_path': '...'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc337a8a8c2443a9589195749ff268c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\anaconda3\\envs\\doom-rlhf\\lib\\site-packages\\gymnasium\\core.py:297: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-13 12:30:33][INFO] Loading reward predictor model from ./models/rlhf_pipeline/training_run_2023_08_31_14_33_02/doom_reward_predictor/pre_training...\n",
      "[2023-09-13 12:30:35][INFO] Successfully loaded reward predictor model from ./models/rlhf_pipeline/training_run_2023_08_31_14_33_02/doom_reward_predictor/pre_training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_training_epochs=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\anaconda3\\envs\\doom-rlhf\\lib\\site-packages\\gymnasium\\core.py:297: UserWarning: \u001b[33mWARN: env.raw_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.raw_observation_space` for environment variables or `env.get_attr('raw_observation_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-13 12:30:39][INFO] global_step=56, episodic_reward_predictor_return=0.0633968934416771\n",
      "[2023-09-13 12:30:39][INFO] global_step=56, episodic_env_return=94.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=64, episodic_reward_predictor_return=0.3254360854625702\n",
      "[2023-09-13 12:30:39][INFO] global_step=64, episodic_env_return=93.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=72, episodic_reward_predictor_return=-0.20194083452224731\n",
      "[2023-09-13 12:30:39][INFO] global_step=72, episodic_env_return=92.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=112, episodic_reward_predictor_return=-0.10715746879577637\n",
      "[2023-09-13 12:30:39][INFO] global_step=112, episodic_env_return=95.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=128, episodic_reward_predictor_return=0.057514481246471405\n",
      "[2023-09-13 12:30:39][INFO] global_step=128, episodic_env_return=92.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=160, episodic_reward_predictor_return=-0.20512744784355164\n",
      "[2023-09-13 12:30:39][INFO] global_step=160, episodic_env_return=90.0\n",
      "[2023-09-13 12:30:39][INFO] global_step=176, episodic_reward_predictor_return=0.02572721615433693\n",
      "[2023-09-13 12:30:39][INFO] global_step=176, episodic_env_return=95.0\n",
      "[2023-09-13 12:30:40][INFO] global_step=352, episodic_reward_predictor_return=-0.7307387590408325\n",
      "[2023-09-13 12:30:40][INFO] global_step=352, episodic_env_return=47.0\n",
      "[2023-09-13 12:30:40][INFO] global_step=400, episodic_reward_predictor_return=-0.07467375695705414\n",
      "[2023-09-13 12:30:40][INFO] global_step=400, episodic_env_return=60.0\n",
      "[2023-09-13 12:30:41][INFO] global_step=472, episodic_reward_predictor_return=0.44061216711997986\n",
      "[2023-09-13 12:30:41][INFO] global_step=472, episodic_env_return=92.0\n",
      "[2023-09-13 12:30:43][INFO] global_step=1128, episodic_reward_predictor_return=-0.17880544066429138\n",
      "[2023-09-13 12:30:43][INFO] global_step=1128, episodic_env_return=-16.0\n",
      "[2023-09-13 12:30:46][INFO] global_step=1792, episodic_reward_predictor_return=-2.0101702213287354\n",
      "[2023-09-13 12:30:46][INFO] global_step=1792, episodic_env_return=-178.0\n",
      "[2023-09-13 12:30:46][INFO] global_step=1856, episodic_reward_predictor_return=0.31649065017700195\n",
      "[2023-09-13 12:30:46][INFO] global_step=1856, episodic_env_return=93.0\n",
      "[2023-09-13 12:30:46][INFO] global_step=1904, episodic_reward_predictor_return=0.41711705923080444\n",
      "[2023-09-13 12:30:46][INFO] global_step=1904, episodic_env_return=95.0\n",
      "[2023-09-13 12:30:47][INFO] Current Mean Episodic Return = -0.13302281498908997\n",
      "[2023-09-13 12:30:47][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_2048`...\n",
      "[2023-09-13 12:30:47][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_2048`!\n",
      "[2023-09-13 12:30:50][INFO] SPS: 94\n",
      "[2023-09-13 12:30:52][INFO] global_step=2184, episodic_reward_predictor_return=0.8096369504928589\n",
      "[2023-09-13 12:30:52][INFO] global_step=2184, episodic_env_return=61.0\n",
      "[2023-09-13 12:30:54][INFO] global_step=2280, episodic_reward_predictor_return=-2.008739471435547\n",
      "[2023-09-13 12:30:54][INFO] global_step=2280, episodic_env_return=-234.0\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_reward_predictor_return=-3.892883062362671\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_env_return=-380.0\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_reward_predictor_return=-1.0339834690093994\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_env_return=-375.0\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_reward_predictor_return=-5.260370254516602\n",
      "[2023-09-13 12:30:56][INFO] global_step=2400, episodic_env_return=-370.0\n",
      "[2023-09-13 12:30:57][INFO] global_step=2472, episodic_reward_predictor_return=0.23536616563796997\n",
      "[2023-09-13 12:30:57][INFO] global_step=2472, episodic_env_return=92.0\n",
      "[2023-09-13 12:30:57][INFO] global_step=2520, episodic_reward_predictor_return=0.21257436275482178\n",
      "[2023-09-13 12:30:57][INFO] global_step=2520, episodic_env_return=95.0\n",
      "[2023-09-13 12:30:58][INFO] global_step=2536, episodic_reward_predictor_return=0.7103531360626221\n",
      "[2023-09-13 12:30:58][INFO] global_step=2536, episodic_env_return=64.0\n",
      "[2023-09-13 12:30:58][INFO] global_step=2576, episodic_reward_predictor_return=-4.403176307678223\n",
      "[2023-09-13 12:30:58][INFO] global_step=2576, episodic_env_return=-375.0\n",
      "[2023-09-13 12:30:59][INFO] global_step=2608, episodic_reward_predictor_return=0.40893101692199707\n",
      "[2023-09-13 12:30:59][INFO] global_step=2608, episodic_env_return=90.0\n",
      "[2023-09-13 12:31:00][INFO] global_step=2648, episodic_reward_predictor_return=0.21618148684501648\n",
      "[2023-09-13 12:31:00][INFO] global_step=2648, episodic_env_return=92.0\n",
      "[2023-09-13 12:31:00][INFO] global_step=2664, episodic_reward_predictor_return=0.47693711519241333\n",
      "[2023-09-13 12:31:00][INFO] global_step=2664, episodic_env_return=63.0\n",
      "[2023-09-13 12:31:00][INFO] global_step=2680, episodic_reward_predictor_return=0.9365059733390808\n",
      "[2023-09-13 12:31:00][INFO] global_step=2680, episodic_env_return=83.0\n",
      "[2023-09-13 12:31:01][INFO] global_step=2720, episodic_reward_predictor_return=0.3118971586227417\n",
      "[2023-09-13 12:31:01][INFO] global_step=2720, episodic_env_return=94.0\n",
      "[2023-09-13 12:31:03][INFO] global_step=2872, episodic_reward_predictor_return=0.7550477385520935\n",
      "[2023-09-13 12:31:03][INFO] global_step=2872, episodic_env_return=-370.0\n",
      "[2023-09-13 12:31:05][INFO] global_step=2960, episodic_reward_predictor_return=0.744536280632019\n",
      "[2023-09-13 12:31:05][INFO] global_step=2960, episodic_env_return=66.0\n",
      "[2023-09-13 12:31:11][INFO] global_step=3352, episodic_reward_predictor_return=0.7060256004333496\n",
      "[2023-09-13 12:31:11][INFO] global_step=3352, episodic_env_return=-12.0\n",
      "[2023-09-13 12:31:14][INFO] global_step=3528, episodic_reward_predictor_return=-6.304417610168457\n",
      "[2023-09-13 12:31:14][INFO] global_step=3528, episodic_env_return=-380.0\n",
      "[2023-09-13 12:31:23][INFO] Current Mean Episodic Return = -0.9099765419960022\n",
      "[2023-09-13 12:31:23][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_4096`...\n",
      "[2023-09-13 12:31:23][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_4096`!\n",
      "[2023-09-13 12:31:26][INFO] SPS: 71\n",
      "[2023-09-13 12:31:33][INFO] global_step=4584, episodic_reward_predictor_return=-2.3571431636810303\n",
      "[2023-09-13 12:31:33][INFO] global_step=4584, episodic_env_return=-375.0\n",
      "[2023-09-13 12:31:35][INFO] global_step=4672, episodic_reward_predictor_return=0.4767424762248993\n",
      "[2023-09-13 12:31:35][INFO] global_step=4672, episodic_env_return=90.0\n",
      "[2023-09-13 12:31:36][INFO] global_step=4736, episodic_reward_predictor_return=0.3278304934501648\n",
      "[2023-09-13 12:31:36][INFO] global_step=4736, episodic_env_return=93.0\n",
      "[2023-09-13 12:31:37][INFO] global_step=4800, episodic_reward_predictor_return=3.8147196769714355\n",
      "[2023-09-13 12:31:37][INFO] global_step=4800, episodic_env_return=-380.0\n",
      "[2023-09-13 12:31:38][INFO] global_step=4848, episodic_reward_predictor_return=0.15428535640239716\n",
      "[2023-09-13 12:31:38][INFO] global_step=4848, episodic_env_return=95.0\n",
      "[2023-09-13 12:31:39][INFO] global_step=4896, episodic_reward_predictor_return=0.08429301530122757\n",
      "[2023-09-13 12:31:39][INFO] global_step=4896, episodic_env_return=95.0\n",
      "[2023-09-13 12:31:41][INFO] global_step=5048, episodic_reward_predictor_return=-1.1742045879364014\n",
      "[2023-09-13 12:31:41][INFO] global_step=5048, episodic_env_return=-375.0\n",
      "[2023-09-13 12:31:42][INFO] global_step=5080, episodic_reward_predictor_return=-2.2560410499572754\n",
      "[2023-09-13 12:31:42][INFO] global_step=5080, episodic_env_return=-375.0\n",
      "[2023-09-13 12:31:43][INFO] global_step=5128, episodic_reward_predictor_return=0.6361781358718872\n",
      "[2023-09-13 12:31:43][INFO] global_step=5128, episodic_env_return=91.0\n",
      "[2023-09-13 12:31:43][INFO] global_step=5168, episodic_reward_predictor_return=0.4370947778224945\n",
      "[2023-09-13 12:31:43][INFO] global_step=5168, episodic_env_return=90.0\n",
      "[2023-09-13 12:31:43][INFO] global_step=5176, episodic_reward_predictor_return=0.1758926659822464\n",
      "[2023-09-13 12:31:43][INFO] global_step=5176, episodic_env_return=95.0\n",
      "[2023-09-13 12:31:45][INFO] global_step=5232, episodic_reward_predictor_return=0.2996155321598053\n",
      "[2023-09-13 12:31:45][INFO] global_step=5232, episodic_env_return=94.0\n",
      "[2023-09-13 12:31:45][INFO] global_step=5272, episodic_reward_predictor_return=-5.6445231437683105\n",
      "[2023-09-13 12:31:45][INFO] global_step=5272, episodic_env_return=-375.0\n",
      "[2023-09-13 12:31:46][INFO] global_step=5344, episodic_reward_predictor_return=0.5266998410224915\n",
      "[2023-09-13 12:31:46][INFO] global_step=5344, episodic_env_return=92.0\n",
      "[2023-09-13 12:31:47][INFO] global_step=5360, episodic_reward_predictor_return=-2.5084149837493896\n",
      "[2023-09-13 12:31:47][INFO] global_step=5360, episodic_env_return=-365.0\n",
      "[2023-09-13 12:31:53][INFO] global_step=5752, episodic_reward_predictor_return=-4.740992069244385\n",
      "[2023-09-13 12:31:53][INFO] global_step=5752, episodic_env_return=-370.0\n",
      "[2023-09-13 12:31:56][INFO] global_step=5928, episodic_reward_predictor_return=-2.8860459327697754\n",
      "[2023-09-13 12:31:56][INFO] global_step=5928, episodic_env_return=-380.0\n",
      "[2023-09-13 12:31:57][INFO] global_step=6016, episodic_reward_predictor_return=0.9966646432876587\n",
      "[2023-09-13 12:31:57][INFO] global_step=6016, episodic_env_return=63.0\n",
      "[2023-09-13 12:31:59][INFO] Current Mean Episodic Return = -0.7576305270195007\n",
      "[2023-09-13 12:31:59][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_6144`...\n",
      "[2023-09-13 12:32:00][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_6144`!\n",
      "[2023-09-13 12:32:02][INFO] SPS: 65\n",
      "[2023-09-13 12:32:03][INFO] global_step=6192, episodic_reward_predictor_return=0.7963066101074219\n",
      "[2023-09-13 12:32:03][INFO] global_step=6192, episodic_env_return=63.0\n",
      "[2023-09-13 12:32:13][INFO] global_step=6816, episodic_reward_predictor_return=1.478370189666748\n",
      "[2023-09-13 12:32:13][INFO] global_step=6816, episodic_env_return=8.0\n",
      "[2023-09-13 12:32:18][INFO] global_step=7136, episodic_reward_predictor_return=0.3040473461151123\n",
      "[2023-09-13 12:32:18][INFO] global_step=7136, episodic_env_return=-380.0\n",
      "[2023-09-13 12:32:20][INFO] global_step=7296, episodic_reward_predictor_return=-3.5539498329162598\n",
      "[2023-09-13 12:32:20][INFO] global_step=7296, episodic_env_return=-375.0\n",
      "[2023-09-13 12:32:21][INFO] global_step=7312, episodic_reward_predictor_return=5.893205165863037\n",
      "[2023-09-13 12:32:21][INFO] global_step=7312, episodic_env_return=-210.0\n",
      "[2023-09-13 12:32:25][INFO] global_step=7568, episodic_reward_predictor_return=-6.373625755310059\n",
      "[2023-09-13 12:32:25][INFO] global_step=7568, episodic_env_return=-370.0\n",
      "[2023-09-13 12:32:26][INFO] global_step=7632, episodic_reward_predictor_return=-3.5545830726623535\n",
      "[2023-09-13 12:32:26][INFO] global_step=7632, episodic_env_return=-365.0\n",
      "[2023-09-13 12:32:28][INFO] global_step=7760, episodic_reward_predictor_return=1.7984024286270142\n",
      "[2023-09-13 12:32:28][INFO] global_step=7760, episodic_env_return=-380.0\n",
      "[2023-09-13 12:32:29][INFO] global_step=7808, episodic_reward_predictor_return=0.827701985836029\n",
      "[2023-09-13 12:32:29][INFO] global_step=7808, episodic_env_return=79.0\n",
      "[2023-09-13 12:32:29][INFO] global_step=7816, episodic_reward_predictor_return=0.5177677273750305\n",
      "[2023-09-13 12:32:29][INFO] global_step=7816, episodic_env_return=94.0\n",
      "[2023-09-13 12:32:30][INFO] global_step=7864, episodic_reward_predictor_return=0.17646390199661255\n",
      "[2023-09-13 12:32:30][INFO] global_step=7864, episodic_env_return=95.0\n",
      "[2023-09-13 12:32:31][INFO] global_step=7928, episodic_reward_predictor_return=0.3483940362930298\n",
      "[2023-09-13 12:32:31][INFO] global_step=7928, episodic_env_return=93.0\n",
      "[2023-09-13 12:32:31][INFO] global_step=7960, episodic_reward_predictor_return=2.2934257984161377\n",
      "[2023-09-13 12:32:31][INFO] global_step=7960, episodic_env_return=0.0\n",
      "[2023-09-13 12:32:32][INFO] global_step=7976, episodic_reward_predictor_return=0.48768702149391174\n",
      "[2023-09-13 12:32:32][INFO] global_step=7976, episodic_env_return=95.0\n",
      "[2023-09-13 12:32:35][INFO] global_step=8192, episodic_reward_predictor_return=1.1997023820877075\n",
      "[2023-09-13 12:32:35][INFO] global_step=8192, episodic_env_return=43.0\n",
      "[2023-09-13 12:32:35][INFO] Current Mean Episodic Return = 0.17595437169075012\n",
      "[2023-09-13 12:32:35][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_8192`...\n",
      "[2023-09-13 12:32:35][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_8192`!\n",
      "[2023-09-13 12:32:38][INFO] SPS: 63\n",
      "[2023-09-13 12:32:38][INFO] global_step=8208, episodic_reward_predictor_return=2.670708417892456\n",
      "[2023-09-13 12:32:38][INFO] global_step=8208, episodic_env_return=-243.0\n",
      "[2023-09-13 12:32:47][INFO] global_step=8768, episodic_reward_predictor_return=2.2051150798797607\n",
      "[2023-09-13 12:32:47][INFO] global_step=8768, episodic_env_return=-133.0\n",
      "[2023-09-13 12:32:47][INFO] global_step=8792, episodic_reward_predictor_return=2.810713052749634\n",
      "[2023-09-13 12:32:47][INFO] global_step=8792, episodic_env_return=-92.0\n",
      "[2023-09-13 12:32:52][INFO] global_step=9064, episodic_reward_predictor_return=0.9765160083770752\n",
      "[2023-09-13 12:32:52][INFO] global_step=9064, episodic_env_return=59.0\n",
      "[2023-09-13 12:32:53][INFO] global_step=9136, episodic_reward_predictor_return=0.5503715872764587\n",
      "[2023-09-13 12:32:53][INFO] global_step=9136, episodic_env_return=92.0\n",
      "[2023-09-13 12:32:54][INFO] global_step=9216, episodic_reward_predictor_return=0.7924551367759705\n",
      "[2023-09-13 12:32:54][INFO] global_step=9216, episodic_env_return=-370.0\n",
      "[2023-09-13 12:32:56][INFO] global_step=9288, episodic_reward_predictor_return=0.2778272330760956\n",
      "[2023-09-13 12:32:56][INFO] global_step=9288, episodic_env_return=92.0\n",
      "[2023-09-13 12:33:00][INFO] global_step=9536, episodic_reward_predictor_return=-5.630368232727051\n",
      "[2023-09-13 12:33:00][INFO] global_step=9536, episodic_env_return=-380.0\n",
      "[2023-09-13 12:33:08][INFO] global_step=10040, episodic_reward_predictor_return=1.5670183897018433\n",
      "[2023-09-13 12:33:08][INFO] global_step=10040, episodic_env_return=-13.0\n",
      "[2023-09-13 12:33:08][INFO] global_step=10072, episodic_reward_predictor_return=0.35751354694366455\n",
      "[2023-09-13 12:33:08][INFO] global_step=10072, episodic_env_return=19.0\n",
      "[2023-09-13 12:33:10][INFO] global_step=10144, episodic_reward_predictor_return=0.4269716739654541\n",
      "[2023-09-13 12:33:10][INFO] global_step=10144, episodic_env_return=88.0\n",
      "[2023-09-13 12:33:11][INFO] Current Mean Episodic Return = 0.6368038058280945\n",
      "[2023-09-13 12:33:11][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_10240`...\n",
      "[2023-09-13 12:33:11][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_10240`!\n",
      "[2023-09-13 12:33:14][INFO] SPS: 61\n",
      "[2023-09-13 12:33:16][INFO] global_step=10360, episodic_reward_predictor_return=4.049217700958252\n",
      "[2023-09-13 12:33:16][INFO] global_step=10360, episodic_env_return=-380.0\n",
      "[2023-09-13 12:33:16][INFO] global_step=10376, episodic_reward_predictor_return=4.935220241546631\n",
      "[2023-09-13 12:33:16][INFO] global_step=10376, episodic_env_return=-385.0\n",
      "[2023-09-13 12:33:17][INFO] global_step=10416, episodic_reward_predictor_return=0.4638984799385071\n",
      "[2023-09-13 12:33:17][INFO] global_step=10416, episodic_env_return=94.0\n",
      "[2023-09-13 12:33:20][INFO] global_step=10592, episodic_reward_predictor_return=-6.426919937133789\n",
      "[2023-09-13 12:33:20][INFO] global_step=10592, episodic_env_return=-380.0\n",
      "[2023-09-13 12:33:20][INFO] global_step=10608, episodic_reward_predictor_return=0.42973729968070984\n",
      "[2023-09-13 12:33:20][INFO] global_step=10608, episodic_env_return=-380.0\n",
      "[2023-09-13 12:33:24][INFO] global_step=10856, episodic_reward_predictor_return=0.455798476934433\n",
      "[2023-09-13 12:33:24][INFO] global_step=10856, episodic_env_return=63.0\n",
      "[2023-09-13 12:33:24][INFO] global_step=10864, episodic_reward_predictor_return=1.0461572408676147\n",
      "[2023-09-13 12:33:24][INFO] global_step=10864, episodic_env_return=30.0\n",
      "[2023-09-13 12:33:25][INFO] global_step=10880, episodic_reward_predictor_return=0.9728254675865173\n",
      "[2023-09-13 12:33:25][INFO] global_step=10880, episodic_env_return=62.0\n",
      "[2023-09-13 12:33:25][INFO] global_step=10904, episodic_reward_predictor_return=0.093709796667099\n",
      "[2023-09-13 12:33:25][INFO] global_step=10904, episodic_env_return=95.0\n",
      "[2023-09-13 12:33:26][INFO] global_step=10944, episodic_reward_predictor_return=0.45394015312194824\n",
      "[2023-09-13 12:33:26][INFO] global_step=10944, episodic_env_return=93.0\n",
      "[2023-09-13 12:33:28][INFO] global_step=11080, episodic_reward_predictor_return=-0.17349347472190857\n",
      "[2023-09-13 12:33:28][INFO] global_step=11080, episodic_env_return=-55.0\n",
      "[2023-09-13 12:33:28][INFO] global_step=11088, episodic_reward_predictor_return=0.1331399530172348\n",
      "[2023-09-13 12:33:28][INFO] global_step=11088, episodic_env_return=73.0\n",
      "[2023-09-13 12:33:29][INFO] global_step=11128, episodic_reward_predictor_return=0.3809072971343994\n",
      "[2023-09-13 12:33:29][INFO] global_step=11128, episodic_env_return=95.0\n",
      "[2023-09-13 12:33:30][INFO] global_step=11192, episodic_reward_predictor_return=4.057611465454102\n",
      "[2023-09-13 12:33:30][INFO] global_step=11192, episodic_env_return=-380.0\n",
      "[2023-09-13 12:33:30][INFO] global_step=11200, episodic_reward_predictor_return=0.7023491263389587\n",
      "[2023-09-13 12:33:30][INFO] global_step=11200, episodic_env_return=64.0\n",
      "[2023-09-13 12:33:31][INFO] global_step=11248, episodic_reward_predictor_return=0.3452262878417969\n",
      "[2023-09-13 12:33:31][INFO] global_step=11248, episodic_env_return=95.0\n",
      "[2023-09-13 12:33:32][INFO] global_step=11304, episodic_reward_predictor_return=0.26747775077819824\n",
      "[2023-09-13 12:33:32][INFO] global_step=11304, episodic_env_return=94.0\n",
      "[2023-09-13 12:33:36][INFO] global_step=11536, episodic_reward_predictor_return=-5.654452800750732\n",
      "[2023-09-13 12:33:36][INFO] global_step=11536, episodic_env_return=-370.0\n",
      "[2023-09-13 12:33:37][INFO] global_step=11600, episodic_reward_predictor_return=0.19630786776542664\n",
      "[2023-09-13 12:33:37][INFO] global_step=11600, episodic_env_return=93.0\n",
      "[2023-09-13 12:33:38][INFO] global_step=11648, episodic_reward_predictor_return=0.5575760006904602\n",
      "[2023-09-13 12:33:38][INFO] global_step=11648, episodic_env_return=95.0\n",
      "[2023-09-13 12:33:41][INFO] global_step=11848, episodic_reward_predictor_return=1.05272376537323\n",
      "[2023-09-13 12:33:41][INFO] global_step=11848, episodic_env_return=-128.0\n",
      "[2023-09-13 12:33:46][INFO] global_step=12112, episodic_reward_predictor_return=0.14028440415859222\n",
      "[2023-09-13 12:33:46][INFO] global_step=12112, episodic_env_return=28.0\n",
      "[2023-09-13 12:33:46][INFO] global_step=12136, episodic_reward_predictor_return=1.1635907888412476\n",
      "[2023-09-13 12:33:46][INFO] global_step=12136, episodic_env_return=-65.0\n",
      "[2023-09-13 12:33:47][INFO] global_step=12184, episodic_reward_predictor_return=0.4282337427139282\n",
      "[2023-09-13 12:33:47][INFO] global_step=12184, episodic_env_return=92.0\n",
      "[2023-09-13 12:33:49][INFO] Current Mean Episodic Return = 0.4196278154850006\n",
      "[2023-09-13 12:33:49][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_12288`...\n",
      "[2023-09-13 12:33:49][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_12288`!\n",
      "[2023-09-13 12:33:51][INFO] SPS: 60\n",
      "[2023-09-13 12:33:53][INFO] global_step=12376, episodic_reward_predictor_return=0.68498295545578\n",
      "[2023-09-13 12:33:53][INFO] global_step=12376, episodic_env_return=-243.0\n",
      "[2023-09-13 12:33:54][INFO] global_step=12432, episodic_reward_predictor_return=0.3844716548919678\n",
      "[2023-09-13 12:33:54][INFO] global_step=12432, episodic_env_return=94.0\n",
      "[2023-09-13 12:33:57][INFO] global_step=12648, episodic_reward_predictor_return=1.0126820802688599\n",
      "[2023-09-13 12:33:57][INFO] global_step=12648, episodic_env_return=-134.0\n",
      "[2023-09-13 12:33:58][INFO] global_step=12696, episodic_reward_predictor_return=0.21395060420036316\n",
      "[2023-09-13 12:33:58][INFO] global_step=12696, episodic_env_return=95.0\n",
      "[2023-09-13 12:33:59][INFO] global_step=12752, episodic_reward_predictor_return=0.27245306968688965\n",
      "[2023-09-13 12:33:59][INFO] global_step=12752, episodic_env_return=94.0\n",
      "[2023-09-13 12:34:00][INFO] global_step=12848, episodic_reward_predictor_return=0.4471418857574463\n",
      "[2023-09-13 12:34:00][INFO] global_step=12848, episodic_env_return=89.0\n",
      "[2023-09-13 12:34:02][INFO] global_step=12912, episodic_reward_predictor_return=0.4597157835960388\n",
      "[2023-09-13 12:34:02][INFO] global_step=12912, episodic_env_return=93.0\n",
      "[2023-09-13 12:34:02][INFO] global_step=12960, episodic_reward_predictor_return=0.3269556164741516\n",
      "[2023-09-13 12:34:02][INFO] global_step=12960, episodic_env_return=95.0\n",
      "[2023-09-13 12:34:05][INFO] global_step=13104, episodic_reward_predictor_return=2.100644111633301\n",
      "[2023-09-13 12:34:05][INFO] global_step=13104, episodic_env_return=7.0\n",
      "[2023-09-13 12:34:08][INFO] global_step=13264, episodic_reward_predictor_return=2.659249782562256\n",
      "[2023-09-13 12:34:08][INFO] global_step=13264, episodic_env_return=-385.0\n",
      "[2023-09-13 12:34:09][INFO] global_step=13328, episodic_reward_predictor_return=0.37101882696151733\n",
      "[2023-09-13 12:34:09][INFO] global_step=13328, episodic_env_return=68.0\n",
      "[2023-09-13 12:34:09][INFO] global_step=13336, episodic_reward_predictor_return=0.4519120156764984\n",
      "[2023-09-13 12:34:09][INFO] global_step=13336, episodic_env_return=92.0\n",
      "[2023-09-13 12:34:12][INFO] global_step=13544, episodic_reward_predictor_return=1.014382004737854\n",
      "[2023-09-13 12:34:12][INFO] global_step=13544, episodic_env_return=70.0\n",
      "[2023-09-13 12:34:13][INFO] global_step=13592, episodic_reward_predictor_return=4.210928916931152\n",
      "[2023-09-13 12:34:13][INFO] global_step=13592, episodic_env_return=-380.0\n",
      "[2023-09-13 12:34:13][INFO] global_step=13608, episodic_reward_predictor_return=0.3504272401332855\n",
      "[2023-09-13 12:34:13][INFO] global_step=13608, episodic_env_return=93.0\n",
      "[2023-09-13 12:34:15][INFO] global_step=13704, episodic_reward_predictor_return=-4.001250267028809\n",
      "[2023-09-13 12:34:15][INFO] global_step=13704, episodic_env_return=-390.0\n",
      "[2023-09-13 12:34:16][INFO] global_step=13776, episodic_reward_predictor_return=0.31145015358924866\n",
      "[2023-09-13 12:34:16][INFO] global_step=13776, episodic_env_return=92.0\n",
      "[2023-09-13 12:34:18][INFO] global_step=13904, episodic_reward_predictor_return=0.4987694025039673\n",
      "[2023-09-13 12:34:18][INFO] global_step=13904, episodic_env_return=-180.0\n",
      "[2023-09-13 12:34:20][INFO] global_step=13976, episodic_reward_predictor_return=0.56158447265625\n",
      "[2023-09-13 12:34:20][INFO] global_step=13976, episodic_env_return=92.0\n",
      "[2023-09-13 12:34:24][INFO] global_step=14248, episodic_reward_predictor_return=-6.7325873374938965\n",
      "[2023-09-13 12:34:24][INFO] global_step=14248, episodic_env_return=-370.0\n",
      "[2023-09-13 12:34:26][INFO] Current Mean Episodic Return = 0.27994415163993835\n",
      "[2023-09-13 12:34:26][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_14336`...\n",
      "[2023-09-13 12:34:26][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_14336`!\n",
      "[2023-09-13 12:34:29][INFO] SPS: 59\n",
      "[2023-09-13 12:34:43][INFO] user_preference = 0\n",
      "[2023-09-13 12:34:43][INFO] reward_predictor_training_loss=0.011321977712213993\n",
      "[2023-09-13 12:34:57][INFO] user_preference = 1\n",
      "[2023-09-13 12:34:57][INFO] reward_predictor_training_loss=0.004017544910311699\n",
      "[2023-09-13 12:41:55][INFO] user_preference = 0\n",
      "[2023-09-13 12:41:55][INFO] reward_predictor_training_loss=0.9224636554718018\n",
      "[2023-09-13 12:42:03][INFO] user_preference = 1\n",
      "[2023-09-13 12:42:03][INFO] reward_predictor_training_loss=0.42183101177215576\n",
      "[2023-09-13 12:42:14][INFO] user_preference = 0\n",
      "[2023-09-13 12:42:14][INFO] reward_predictor_training_loss=6.04019021987915\n",
      "[2023-09-13 12:42:23][INFO] user_preference = 1\n",
      "[2023-09-13 12:42:23][INFO] reward_predictor_training_loss=3.4019720554351807\n",
      "[2023-09-13 12:43:03][INFO] user_preference = 0\n",
      "[2023-09-13 12:43:03][INFO] reward_predictor_training_loss=0.004287660121917725\n",
      "[2023-09-13 12:43:18][INFO] user_preference = 1\n",
      "[2023-09-13 12:43:18][INFO] reward_predictor_training_loss=0.012646072544157505\n",
      "[2023-09-13 12:43:26][INFO] user_preference = 0\n",
      "[2023-09-13 12:43:27][INFO] reward_predictor_training_loss=0.10078919678926468\n",
      "[2023-09-13 12:43:36][INFO] user_preference = 0\n",
      "[2023-09-13 12:43:37][INFO] reward_predictor_training_loss=0.4559561610221863\n",
      "[2023-09-13 12:43:47][INFO] user_preference = 0\n",
      "[2023-09-13 12:43:47][INFO] reward_predictor_training_loss=0.05098899453878403\n",
      "[2023-09-13 12:43:57][INFO] user_preference = 0\n",
      "[2023-09-13 12:43:58][INFO] reward_predictor_training_loss=0.5225974917411804\n",
      "[2023-09-13 12:44:20][INFO] user_preference = 1\n",
      "[2023-09-13 12:44:20][INFO] reward_predictor_training_loss=2.361643075942993\n",
      "[2023-09-13 12:44:27][INFO] user_preference = 1\n",
      "[2023-09-13 12:44:27][INFO] reward_predictor_training_loss=0.24098427593708038\n",
      "[2023-09-13 12:44:50][INFO] user_preference = 0\n",
      "[2023-09-13 12:44:50][INFO] reward_predictor_training_loss=1.3951138257980347\n",
      "[2023-09-13 12:44:58][INFO] user_preference = 0\n",
      "[2023-09-13 12:44:59][INFO] reward_predictor_training_loss=2.56899311352754e-05\n",
      "[2023-09-13 12:44:59][INFO] global_step=14344, episodic_reward_predictor_return=1.4691648483276367\n",
      "[2023-09-13 12:44:59][INFO] global_step=14344, episodic_env_return=15.0\n",
      "[2023-09-13 12:45:03][INFO] global_step=14584, episodic_reward_predictor_return=0.9610544443130493\n",
      "[2023-09-13 12:45:03][INFO] global_step=14584, episodic_env_return=-375.0\n",
      "[2023-09-13 12:45:04][INFO] global_step=14656, episodic_reward_predictor_return=1.7648136615753174\n",
      "[2023-09-13 12:45:04][INFO] global_step=14656, episodic_env_return=-62.0\n",
      "[2023-09-13 12:45:05][INFO] global_step=14736, episodic_reward_predictor_return=-2.3931307792663574\n",
      "[2023-09-13 12:45:05][INFO] global_step=14736, episodic_env_return=-176.0\n",
      "[2023-09-13 12:45:07][INFO] global_step=14824, episodic_reward_predictor_return=0.672685980796814\n",
      "[2023-09-13 12:45:07][INFO] global_step=14824, episodic_env_return=90.0\n",
      "[2023-09-13 12:45:07][INFO] global_step=14832, episodic_reward_predictor_return=0.9420672655105591\n",
      "[2023-09-13 12:45:07][INFO] global_step=14832, episodic_env_return=79.0\n",
      "[2023-09-13 12:45:08][INFO] global_step=14904, episodic_reward_predictor_return=0.27166640758514404\n",
      "[2023-09-13 12:45:08][INFO] global_step=14904, episodic_env_return=91.0\n",
      "[2023-09-13 12:45:09][INFO] global_step=14936, episodic_reward_predictor_return=0.5729675889015198\n",
      "[2023-09-13 12:45:09][INFO] global_step=14936, episodic_env_return=88.0\n",
      "[2023-09-13 12:45:09][INFO] global_step=14952, episodic_reward_predictor_return=0.7668644189834595\n",
      "[2023-09-13 12:45:09][INFO] global_step=14952, episodic_env_return=10.0\n",
      "[2023-09-13 12:45:17][INFO] global_step=15408, episodic_reward_predictor_return=0.77805095911026\n",
      "[2023-09-13 12:45:17][INFO] global_step=15408, episodic_env_return=27.0\n",
      "[2023-09-13 12:45:19][INFO] global_step=15528, episodic_reward_predictor_return=0.3625046908855438\n",
      "[2023-09-13 12:45:19][INFO] global_step=15528, episodic_env_return=86.0\n",
      "[2023-09-13 12:45:21][INFO] global_step=15688, episodic_reward_predictor_return=-1.9785839319229126\n",
      "[2023-09-13 12:45:21][INFO] global_step=15688, episodic_env_return=-269.0\n",
      "[2023-09-13 12:45:22][INFO] global_step=15696, episodic_reward_predictor_return=-1.008742332458496\n",
      "[2023-09-13 12:45:22][INFO] global_step=15696, episodic_env_return=-18.0\n",
      "[2023-09-13 12:45:23][INFO] global_step=15768, episodic_reward_predictor_return=0.18370264768600464\n",
      "[2023-09-13 12:45:23][INFO] global_step=15768, episodic_env_return=91.0\n",
      "[2023-09-13 12:45:24][INFO] global_step=15824, episodic_reward_predictor_return=0.11225152760744095\n",
      "[2023-09-13 12:45:24][INFO] global_step=15824, episodic_env_return=94.0\n",
      "[2023-09-13 12:45:25][INFO] global_step=15928, episodic_reward_predictor_return=1.5062059164047241\n",
      "[2023-09-13 12:45:25][INFO] global_step=15928, episodic_env_return=-203.0\n",
      "[2023-09-13 12:45:27][INFO] global_step=16008, episodic_reward_predictor_return=-0.008385220542550087\n",
      "[2023-09-13 12:45:27][INFO] global_step=16008, episodic_env_return=-380.0\n",
      "[2023-09-13 12:45:28][INFO] global_step=16056, episodic_reward_predictor_return=0.3957827389240265\n",
      "[2023-09-13 12:45:28][INFO] global_step=16056, episodic_env_return=85.0\n",
      "[2023-09-13 12:45:28][INFO] global_step=16104, episodic_reward_predictor_return=0.14299623668193817\n",
      "[2023-09-13 12:45:28][INFO] global_step=16104, episodic_env_return=95.0\n",
      "[2023-09-13 12:45:28][INFO] global_step=16104, episodic_reward_predictor_return=0.15748170018196106\n",
      "[2023-09-13 12:45:28][INFO] global_step=16104, episodic_env_return=89.0\n",
      "[2023-09-13 12:45:33][INFO] Current Mean Episodic Return = 0.28357094526290894\n",
      "[2023-09-13 12:45:33][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_16384`...\n",
      "[2023-09-13 12:45:33][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_16384`!\n",
      "[2023-09-13 12:45:36][INFO] SPS: 18\n",
      "[2023-09-13 12:45:40][INFO] global_step=16648, episodic_reward_predictor_return=-0.2763783037662506\n",
      "[2023-09-13 12:45:40][INFO] global_step=16648, episodic_env_return=-380.0\n",
      "[2023-09-13 12:45:46][INFO] global_step=16984, episodic_reward_predictor_return=-0.33845892548561096\n",
      "[2023-09-13 12:45:46][INFO] global_step=16984, episodic_env_return=-375.0\n",
      "[2023-09-13 12:45:48][INFO] global_step=17128, episodic_reward_predictor_return=0.7672204971313477\n",
      "[2023-09-13 12:45:48][INFO] global_step=17128, episodic_env_return=-144.0\n",
      "[2023-09-13 12:45:51][INFO] global_step=17288, episodic_reward_predictor_return=0.8432315587997437\n",
      "[2023-09-13 12:45:51][INFO] global_step=17288, episodic_env_return=58.0\n",
      "[2023-09-13 12:45:52][INFO] global_step=17352, episodic_reward_predictor_return=0.9686998128890991\n",
      "[2023-09-13 12:45:52][INFO] global_step=17352, episodic_env_return=-365.0\n",
      "[2023-09-13 12:45:53][INFO] global_step=17400, episodic_reward_predictor_return=0.2366991639137268\n",
      "[2023-09-13 12:45:53][INFO] global_step=17400, episodic_env_return=95.0\n",
      "[2023-09-13 12:45:55][INFO] global_step=17528, episodic_reward_predictor_return=-3.3267033100128174\n",
      "[2023-09-13 12:45:55][INFO] global_step=17528, episodic_env_return=-117.0\n",
      "[2023-09-13 12:45:57][INFO] global_step=17640, episodic_reward_predictor_return=0.6375830173492432\n",
      "[2023-09-13 12:45:57][INFO] global_step=17640, episodic_env_return=66.0\n",
      "[2023-09-13 12:45:58][INFO] global_step=17728, episodic_reward_predictor_return=0.71172696352005\n",
      "[2023-09-13 12:45:58][INFO] global_step=17728, episodic_env_return=90.0\n",
      "[2023-09-13 12:45:58][INFO] global_step=17728, episodic_reward_predictor_return=1.4377069473266602\n",
      "[2023-09-13 12:45:58][INFO] global_step=17728, episodic_env_return=36.0\n",
      "[2023-09-13 12:45:59][INFO] global_step=17776, episodic_reward_predictor_return=0.27861592173576355\n",
      "[2023-09-13 12:45:59][INFO] global_step=17776, episodic_env_return=95.0\n",
      "[2023-09-13 12:46:05][INFO] global_step=18096, episodic_reward_predictor_return=0.44902053475379944\n",
      "[2023-09-13 12:46:05][INFO] global_step=18096, episodic_env_return=-375.0\n",
      "[2023-09-13 12:46:07][INFO] global_step=18224, episodic_reward_predictor_return=0.06591278314590454\n",
      "[2023-09-13 12:46:07][INFO] global_step=18224, episodic_env_return=24.0\n",
      "[2023-09-13 12:46:07][INFO] global_step=18224, episodic_reward_predictor_return=-0.2435240000486374\n",
      "[2023-09-13 12:46:07][INFO] global_step=18224, episodic_env_return=-380.0\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_reward_predictor_return=0.30996620655059814\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_env_return=89.0\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_reward_predictor_return=0.10054069012403488\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_env_return=89.0\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_reward_predictor_return=0.5850308537483215\n",
      "[2023-09-13 12:46:09][INFO] global_step=18320, episodic_env_return=68.0\n",
      "[2023-09-13 12:46:09][INFO] global_step=18368, episodic_reward_predictor_return=1.2247684001922607\n",
      "[2023-09-13 12:46:09][INFO] global_step=18368, episodic_env_return=12.0\n",
      "[2023-09-13 12:46:10][INFO] global_step=18392, episodic_reward_predictor_return=0.49264848232269287\n",
      "[2023-09-13 12:46:10][INFO] global_step=18392, episodic_env_return=92.0\n",
      "[2023-09-13 12:46:10][INFO] global_step=18416, episodic_reward_predictor_return=0.30985552072525024\n",
      "[2023-09-13 12:46:10][INFO] global_step=18416, episodic_env_return=95.0\n",
      "[2023-09-13 12:46:10][INFO] Current Mean Episodic Return = 0.26170814037323\n",
      "[2023-09-13 12:46:10][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_18432`...\n",
      "[2023-09-13 12:46:11][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_18432`!\n",
      "[2023-09-13 12:46:13][INFO] SPS: 19\n",
      "[2023-09-13 12:46:14][INFO] global_step=18504, episodic_reward_predictor_return=2.153818130493164\n",
      "[2023-09-13 12:46:14][INFO] global_step=18504, episodic_env_return=-370.0\n",
      "[2023-09-13 12:46:15][INFO] global_step=18576, episodic_reward_predictor_return=1.2224096059799194\n",
      "[2023-09-13 12:46:15][INFO] global_step=18576, episodic_env_return=64.0\n",
      "[2023-09-13 12:46:23][INFO] global_step=19048, episodic_reward_predictor_return=-7.206475257873535\n",
      "[2023-09-13 12:46:23][INFO] global_step=19048, episodic_env_return=-385.0\n",
      "[2023-09-13 12:46:25][INFO] global_step=19152, episodic_reward_predictor_return=0.39571794867515564\n",
      "[2023-09-13 12:46:25][INFO] global_step=19152, episodic_env_return=88.0\n",
      "[2023-09-13 12:46:25][INFO] global_step=19160, episodic_reward_predictor_return=0.8772966861724854\n",
      "[2023-09-13 12:46:25][INFO] global_step=19160, episodic_env_return=13.0\n",
      "[2023-09-13 12:46:26][INFO] global_step=19208, episodic_reward_predictor_return=0.5012218952178955\n",
      "[2023-09-13 12:46:26][INFO] global_step=19208, episodic_env_return=94.0\n",
      "[2023-09-13 12:46:27][INFO] global_step=19272, episodic_reward_predictor_return=0.5811439752578735\n",
      "[2023-09-13 12:46:27][INFO] global_step=19272, episodic_env_return=87.0\n",
      "[2023-09-13 12:46:30][INFO] global_step=19448, episodic_reward_predictor_return=0.5560953617095947\n",
      "[2023-09-13 12:46:30][INFO] global_step=19448, episodic_env_return=-56.0\n",
      "[2023-09-13 12:46:31][INFO] global_step=19528, episodic_reward_predictor_return=2.4164929389953613\n",
      "[2023-09-13 12:46:31][INFO] global_step=19528, episodic_env_return=-370.0\n",
      "[2023-09-13 12:46:34][INFO] global_step=19704, episodic_reward_predictor_return=0.9262887835502625\n",
      "[2023-09-13 12:46:34][INFO] global_step=19704, episodic_env_return=24.0\n",
      "[2023-09-13 12:46:35][INFO] global_step=19752, episodic_reward_predictor_return=0.25587472319602966\n",
      "[2023-09-13 12:46:35][INFO] global_step=19752, episodic_env_return=95.0\n",
      "[2023-09-13 12:46:38][INFO] global_step=19928, episodic_reward_predictor_return=-3.4231183528900146\n",
      "[2023-09-13 12:46:38][INFO] global_step=19928, episodic_env_return=-375.0\n",
      "[2023-09-13 12:46:40][INFO] global_step=20056, episodic_reward_predictor_return=0.4836238622665405\n",
      "[2023-09-13 12:46:40][INFO] global_step=20056, episodic_env_return=85.0\n",
      "[2023-09-13 12:46:42][INFO] global_step=20144, episodic_reward_predictor_return=0.6104505062103271\n",
      "[2023-09-13 12:46:42][INFO] global_step=20144, episodic_env_return=90.0\n",
      "[2023-09-13 12:46:43][INFO] global_step=20216, episodic_reward_predictor_return=0.564112663269043\n",
      "[2023-09-13 12:46:43][INFO] global_step=20216, episodic_env_return=92.0\n",
      "[2023-09-13 12:46:47][INFO] Current Mean Episodic Return = 0.060996923595666885\n",
      "[2023-09-13 12:46:47][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_20480`...\n",
      "[2023-09-13 12:46:47][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_20480`!\n",
      "[2023-09-13 12:46:50][INFO] SPS: 20\n",
      "[2023-09-13 12:46:54][INFO] global_step=20720, episodic_reward_predictor_return=-5.548745155334473\n",
      "[2023-09-13 12:46:54][INFO] global_step=20720, episodic_env_return=-370.0\n",
      "[2023-09-13 12:46:55][INFO] global_step=20816, episodic_reward_predictor_return=-0.8923892378807068\n",
      "[2023-09-13 12:46:55][INFO] global_step=20816, episodic_env_return=-380.0\n",
      "[2023-09-13 12:46:57][INFO] global_step=20904, episodic_reward_predictor_return=-6.53508996963501\n",
      "[2023-09-13 12:46:57][INFO] global_step=20904, episodic_env_return=-375.0\n",
      "[2023-09-13 12:46:58][INFO] global_step=20960, episodic_reward_predictor_return=0.5982266664505005\n",
      "[2023-09-13 12:46:58][INFO] global_step=20960, episodic_env_return=94.0\n",
      "[2023-09-13 12:46:58][INFO] global_step=20992, episodic_reward_predictor_return=1.0871509313583374\n",
      "[2023-09-13 12:46:58][INFO] global_step=20992, episodic_env_return=62.0\n",
      "[2023-09-13 12:47:00][INFO] global_step=21096, episodic_reward_predictor_return=2.4877028465270996\n",
      "[2023-09-13 12:47:00][INFO] global_step=21096, episodic_env_return=-182.0\n",
      "[2023-09-13 12:47:02][INFO] global_step=21184, episodic_reward_predictor_return=0.8516208529472351\n",
      "[2023-09-13 12:47:02][INFO] global_step=21184, episodic_env_return=90.0\n",
      "[2023-09-13 12:47:02][INFO] global_step=21184, episodic_reward_predictor_return=0.7644258141517639\n",
      "[2023-09-13 12:47:02][INFO] global_step=21184, episodic_env_return=-166.0\n",
      "[2023-09-13 12:47:03][INFO] global_step=21272, episodic_reward_predictor_return=1.201168417930603\n",
      "[2023-09-13 12:47:03][INFO] global_step=21272, episodic_env_return=57.0\n",
      "[2023-09-13 12:47:03][INFO] global_step=21280, episodic_reward_predictor_return=0.6169297099113464\n",
      "[2023-09-13 12:47:03][INFO] global_step=21280, episodic_env_return=89.0\n",
      "[2023-09-13 12:47:12][INFO] global_step=21776, episodic_reward_predictor_return=1.2357500791549683\n",
      "[2023-09-13 12:47:12][INFO] global_step=21776, episodic_env_return=-17.0\n",
      "[2023-09-13 12:47:14][INFO] global_step=21928, episodic_reward_predictor_return=0.8702432513237\n",
      "[2023-09-13 12:47:14][INFO] global_step=21928, episodic_env_return=-380.0\n",
      "[2023-09-13 12:47:18][INFO] global_step=22152, episodic_reward_predictor_return=-2.6988227367401123\n",
      "[2023-09-13 12:47:18][INFO] global_step=22152, episodic_env_return=-370.0\n",
      "[2023-09-13 12:47:20][INFO] global_step=22256, episodic_reward_predictor_return=1.3148282766342163\n",
      "[2023-09-13 12:47:20][INFO] global_step=22256, episodic_env_return=31.0\n",
      "[2023-09-13 12:47:25][INFO] Current Mean Episodic Return = -0.3319285809993744\n",
      "[2023-09-13 12:47:25][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_22528`...\n",
      "[2023-09-13 12:47:25][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_22528`!\n",
      "[2023-09-13 12:47:27][INFO] SPS: 22\n",
      "[2023-09-13 12:47:28][INFO] global_step=22552, episodic_reward_predictor_return=1.4512195587158203\n",
      "[2023-09-13 12:47:28][INFO] global_step=22552, episodic_env_return=59.0\n",
      "[2023-09-13 12:47:28][INFO] global_step=22600, episodic_reward_predictor_return=2.634329080581665\n",
      "[2023-09-13 12:47:28][INFO] global_step=22600, episodic_env_return=-162.0\n",
      "[2023-09-13 12:47:29][INFO] global_step=22616, episodic_reward_predictor_return=0.08881270885467529\n",
      "[2023-09-13 12:47:29][INFO] global_step=22616, episodic_env_return=-370.0\n",
      "[2023-09-13 12:47:30][INFO] global_step=22720, episodic_reward_predictor_return=0.6208001375198364\n",
      "[2023-09-13 12:47:30][INFO] global_step=22720, episodic_env_return=86.0\n",
      "[2023-09-13 12:47:31][INFO] global_step=22752, episodic_reward_predictor_return=0.6514968276023865\n",
      "[2023-09-13 12:47:31][INFO] global_step=22752, episodic_env_return=71.0\n",
      "[2023-09-13 12:47:32][INFO] global_step=22816, episodic_reward_predictor_return=0.1757754385471344\n",
      "[2023-09-13 12:47:32][INFO] global_step=22816, episodic_env_return=93.0\n",
      "[2023-09-13 12:47:34][INFO] global_step=22944, episodic_reward_predictor_return=1.5611034631729126\n",
      "[2023-09-13 12:47:34][INFO] global_step=22944, episodic_env_return=55.0\n",
      "[2023-09-13 12:47:45][INFO] global_step=23584, episodic_reward_predictor_return=-8.433014869689941\n",
      "[2023-09-13 12:47:45][INFO] global_step=23584, episodic_env_return=-370.0\n",
      "[2023-09-13 12:47:46][INFO] global_step=23672, episodic_reward_predictor_return=2.3727266788482666\n",
      "[2023-09-13 12:47:46][INFO] global_step=23672, episodic_env_return=-380.0\n",
      "[2023-09-13 12:47:47][INFO] global_step=23680, episodic_reward_predictor_return=0.8832834959030151\n",
      "[2023-09-13 12:47:47][INFO] global_step=23680, episodic_env_return=-375.0\n",
      "[2023-09-13 12:47:48][INFO] global_step=23752, episodic_reward_predictor_return=0.48869872093200684\n",
      "[2023-09-13 12:47:48][INFO] global_step=23752, episodic_env_return=75.0\n",
      "[2023-09-13 12:47:58][INFO] global_step=24328, episodic_reward_predictor_return=1.917668104171753\n",
      "[2023-09-13 12:47:58][INFO] global_step=24328, episodic_env_return=-365.0\n",
      "[2023-09-13 12:48:00][INFO] global_step=24472, episodic_reward_predictor_return=-4.382026195526123\n",
      "[2023-09-13 12:48:00][INFO] global_step=24472, episodic_env_return=-254.0\n",
      "[2023-09-13 12:48:02][INFO] Current Mean Episodic Return = 0.0023748325183987617\n",
      "[2023-09-13 12:48:02][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_24576`...\n",
      "[2023-09-13 12:48:02][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_24576`!\n",
      "[2023-09-13 12:48:05][INFO] SPS: 23\n",
      "[2023-09-13 12:48:13][INFO] global_step=25120, episodic_reward_predictor_return=2.7533349990844727\n",
      "[2023-09-13 12:48:13][INFO] global_step=25120, episodic_env_return=-365.0\n",
      "[2023-09-13 12:48:15][INFO] global_step=25216, episodic_reward_predictor_return=-1.9369748830795288\n",
      "[2023-09-13 12:48:15][INFO] global_step=25216, episodic_env_return=-375.0\n",
      "[2023-09-13 12:48:17][INFO] global_step=25328, episodic_reward_predictor_return=0.6219466924667358\n",
      "[2023-09-13 12:48:17][INFO] global_step=25328, episodic_env_return=75.0\n",
      "[2023-09-13 12:48:17][INFO] global_step=25344, episodic_reward_predictor_return=-0.10503996163606644\n",
      "[2023-09-13 12:48:17][INFO] global_step=25344, episodic_env_return=-375.0\n",
      "[2023-09-13 12:48:18][INFO] global_step=25400, episodic_reward_predictor_return=0.28234297037124634\n",
      "[2023-09-13 12:48:18][INFO] global_step=25400, episodic_env_return=94.0\n",
      "[2023-09-13 12:48:21][INFO] global_step=25552, episodic_reward_predictor_return=-0.6730990409851074\n",
      "[2023-09-13 12:48:21][INFO] global_step=25552, episodic_env_return=-183.0\n",
      "[2023-09-13 12:48:30][INFO] global_step=26072, episodic_reward_predictor_return=-3.2577004432678223\n",
      "[2023-09-13 12:48:30][INFO] global_step=26072, episodic_env_return=-370.0\n",
      "[2023-09-13 12:48:31][INFO] global_step=26152, episodic_reward_predictor_return=-1.871738314628601\n",
      "[2023-09-13 12:48:31][INFO] global_step=26152, episodic_env_return=-385.0\n",
      "[2023-09-13 12:48:35][INFO] global_step=26384, episodic_reward_predictor_return=0.805777370929718\n",
      "[2023-09-13 12:48:35][INFO] global_step=26384, episodic_env_return=-47.0\n",
      "[2023-09-13 12:48:39][INFO] global_step=26600, episodic_reward_predictor_return=1.346754789352417\n",
      "[2023-09-13 12:48:39][INFO] global_step=26600, episodic_env_return=25.0\n",
      "[2023-09-13 12:48:39][INFO] Current Mean Episodic Return = -0.2034396231174469\n",
      "[2023-09-13 12:48:39][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_26624`...\n",
      "[2023-09-13 12:48:39][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_26624`!\n",
      "[2023-09-13 12:48:42][INFO] SPS: 24\n",
      "[2023-09-13 12:48:44][INFO] global_step=26728, episodic_reward_predictor_return=-2.8258702754974365\n",
      "[2023-09-13 12:48:44][INFO] global_step=26728, episodic_env_return=-370.0\n",
      "[2023-09-13 12:48:45][INFO] global_step=26840, episodic_reward_predictor_return=0.3900301158428192\n",
      "[2023-09-13 12:48:45][INFO] global_step=26840, episodic_env_return=87.0\n",
      "[2023-09-13 12:48:46][INFO] global_step=26872, episodic_reward_predictor_return=-7.317492961883545\n",
      "[2023-09-13 12:48:46][INFO] global_step=26872, episodic_env_return=-375.0\n",
      "[2023-09-13 12:48:46][INFO] global_step=26896, episodic_reward_predictor_return=0.4556216597557068\n",
      "[2023-09-13 12:48:46][INFO] global_step=26896, episodic_env_return=94.0\n",
      "[2023-09-13 12:48:49][INFO] global_step=27056, episodic_reward_predictor_return=0.4416472315788269\n",
      "[2023-09-13 12:48:49][INFO] global_step=27056, episodic_env_return=81.0\n",
      "[2023-09-13 12:48:59][INFO] global_step=27616, episodic_reward_predictor_return=2.2932448387145996\n",
      "[2023-09-13 12:48:59][INFO] global_step=27616, episodic_env_return=-370.0\n",
      "[2023-09-13 12:49:00][INFO] global_step=27704, episodic_reward_predictor_return=0.47114261984825134\n",
      "[2023-09-13 12:49:00][INFO] global_step=27704, episodic_env_return=90.0\n",
      "[2023-09-13 12:49:01][INFO] global_step=27728, episodic_reward_predictor_return=2.3251895904541016\n",
      "[2023-09-13 12:49:01][INFO] global_step=27728, episodic_env_return=-360.0\n",
      "[2023-09-13 12:49:03][INFO] global_step=27840, episodic_reward_predictor_return=0.6034250855445862\n",
      "[2023-09-13 12:49:03][INFO] global_step=27840, episodic_env_return=-50.0\n",
      "[2023-09-13 12:49:04][INFO] global_step=27952, episodic_reward_predictor_return=0.5603805780410767\n",
      "[2023-09-13 12:49:04][INFO] global_step=27952, episodic_env_return=-370.0\n",
      "[2023-09-13 12:49:15][INFO] global_step=28552, episodic_reward_predictor_return=-1.178122878074646\n",
      "[2023-09-13 12:49:15][INFO] global_step=28552, episodic_env_return=-385.0\n",
      "[2023-09-13 12:49:17][INFO] Current Mean Episodic Return = -0.3437094986438751\n",
      "[2023-09-13 12:49:17][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_28672`...\n",
      "[2023-09-13 12:49:17][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_28672`!\n",
      "[2023-09-13 12:49:19][INFO] SPS: 25\n",
      "[2023-09-13 12:50:54][INFO] user_preference = 1\n",
      "[2023-09-13 12:50:54][INFO] reward_predictor_training_loss=0.0106177544221282\n",
      "[2023-09-13 12:51:05][INFO] user_preference = 1\n",
      "[2023-09-13 12:51:05][INFO] reward_predictor_training_loss=0.0020984956063330173\n",
      "[2023-09-13 12:51:17][INFO] user_preference = 1\n",
      "[2023-09-13 12:51:17][INFO] reward_predictor_training_loss=0.2993859052658081\n",
      "[2023-09-13 12:51:36][INFO] user_preference = 0\n",
      "[2023-09-13 12:51:36][INFO] reward_predictor_training_loss=0.00472527788951993\n",
      "[2023-09-13 12:51:52][INFO] user_preference = 0.5\n",
      "[2023-09-13 12:51:52][INFO] reward_predictor_training_loss=0.7027139067649841\n",
      "[2023-09-13 12:52:23][INFO] user_preference = 0\n",
      "[2023-09-13 12:52:23][INFO] reward_predictor_training_loss=0.00039144069887697697\n",
      "[2023-09-13 12:52:32][INFO] user_preference = 0\n",
      "[2023-09-13 12:52:32][INFO] reward_predictor_training_loss=0.0005398061475716531\n",
      "[2023-09-13 12:52:39][INFO] user_preference = 0\n",
      "[2023-09-13 12:52:40][INFO] reward_predictor_training_loss=0.048246633261442184\n",
      "[2023-09-13 12:52:47][INFO] user_preference = 0\n",
      "[2023-09-13 12:52:47][INFO] reward_predictor_training_loss=2.3393008708953857\n",
      "[2023-09-13 12:52:57][INFO] user_preference = 1\n",
      "[2023-09-13 12:52:57][INFO] reward_predictor_training_loss=0.6910446286201477\n",
      "[2023-09-13 12:53:06][INFO] user_preference = 1\n",
      "[2023-09-13 12:53:06][INFO] reward_predictor_training_loss=0.6599299311637878\n",
      "[2023-09-13 12:53:19][INFO] user_preference = 0\n",
      "[2023-09-13 12:53:19][INFO] reward_predictor_training_loss=0.10465480387210846\n",
      "[2023-09-13 12:53:33][INFO] user_preference = 0\n",
      "[2023-09-13 12:53:33][INFO] reward_predictor_training_loss=0.29602158069610596\n",
      "[2023-09-13 12:53:45][INFO] user_preference = 1\n",
      "[2023-09-13 12:53:45][INFO] reward_predictor_training_loss=0.00610704580321908\n",
      "[2023-09-13 12:53:55][INFO] user_preference = 0\n",
      "[2023-09-13 12:53:56][INFO] reward_predictor_training_loss=1.8155944347381592\n",
      "[2023-09-13 12:54:05][INFO] user_preference = 0\n",
      "[2023-09-13 12:54:06][INFO] reward_predictor_training_loss=0.4661250412464142\n",
      "[2023-09-13 12:54:07][INFO] global_step=28784, episodic_reward_predictor_return=-7.276437759399414\n",
      "[2023-09-13 12:54:07][INFO] global_step=28784, episodic_env_return=-375.0\n",
      "[2023-09-13 12:54:09][INFO] global_step=28872, episodic_reward_predictor_return=-0.5943995714187622\n",
      "[2023-09-13 12:54:09][INFO] global_step=28872, episodic_env_return=-44.0\n",
      "[2023-09-13 12:54:11][INFO] global_step=29000, episodic_reward_predictor_return=1.1672852039337158\n",
      "[2023-09-13 12:54:11][INFO] global_step=29000, episodic_env_return=-375.0\n",
      "[2023-09-13 12:54:13][INFO] global_step=29152, episodic_reward_predictor_return=1.1647001504898071\n",
      "[2023-09-13 12:54:13][INFO] global_step=29152, episodic_env_return=50.0\n",
      "[2023-09-13 12:54:19][INFO] global_step=29456, episodic_reward_predictor_return=-6.861072540283203\n",
      "[2023-09-13 12:54:19][INFO] global_step=29456, episodic_env_return=-380.0\n",
      "[2023-09-13 12:54:20][INFO] global_step=29512, episodic_reward_predictor_return=0.6229914426803589\n",
      "[2023-09-13 12:54:20][INFO] global_step=29512, episodic_env_return=51.0\n",
      "[2023-09-13 12:54:22][INFO] global_step=29680, episodic_reward_predictor_return=-0.1934196650981903\n",
      "[2023-09-13 12:54:22][INFO] global_step=29680, episodic_env_return=-25.0\n",
      "[2023-09-13 12:54:25][INFO] global_step=29856, episodic_reward_predictor_return=0.08075383305549622\n",
      "[2023-09-13 12:54:25][INFO] global_step=29856, episodic_env_return=53.0\n",
      "[2023-09-13 12:54:26][INFO] global_step=29896, episodic_reward_predictor_return=0.9250831007957458\n",
      "[2023-09-13 12:54:26][INFO] global_step=29896, episodic_env_return=74.0\n",
      "[2023-09-13 12:54:28][INFO] global_step=29992, episodic_reward_predictor_return=0.6005672216415405\n",
      "[2023-09-13 12:54:28][INFO] global_step=29992, episodic_env_return=89.0\n",
      "[2023-09-13 12:54:29][INFO] global_step=30088, episodic_reward_predictor_return=0.3382708430290222\n",
      "[2023-09-13 12:54:29][INFO] global_step=30088, episodic_env_return=89.0\n",
      "[2023-09-13 12:54:30][INFO] global_step=30104, episodic_reward_predictor_return=-5.189258098602295\n",
      "[2023-09-13 12:54:30][INFO] global_step=30104, episodic_env_return=-375.0\n",
      "[2023-09-13 12:54:30][INFO] global_step=30128, episodic_reward_predictor_return=-6.173055171966553\n",
      "[2023-09-13 12:54:30][INFO] global_step=30128, episodic_env_return=-385.0\n",
      "[2023-09-13 12:54:32][INFO] global_step=30240, episodic_reward_predictor_return=-6.04917049407959\n",
      "[2023-09-13 12:54:32][INFO] global_step=30240, episodic_env_return=-370.0\n",
      "[2023-09-13 12:54:33][INFO] global_step=30328, episodic_reward_predictor_return=0.5370367765426636\n",
      "[2023-09-13 12:54:33][INFO] global_step=30328, episodic_env_return=73.0\n",
      "[2023-09-13 12:54:34][INFO] global_step=30376, episodic_reward_predictor_return=0.9799830913543701\n",
      "[2023-09-13 12:54:34][INFO] global_step=30376, episodic_env_return=21.0\n",
      "[2023-09-13 12:54:38][INFO] global_step=30616, episodic_reward_predictor_return=0.3904052972793579\n",
      "[2023-09-13 12:54:38][INFO] global_step=30616, episodic_env_return=66.0\n",
      "[2023-09-13 12:54:39][INFO] global_step=30680, episodic_reward_predictor_return=0.844369649887085\n",
      "[2023-09-13 12:54:39][INFO] global_step=30680, episodic_env_return=57.0\n",
      "[2023-09-13 12:54:40][INFO] Current Mean Episodic Return = -1.371409296989441\n",
      "[2023-09-13 12:54:40][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_30720`...\n",
      "[2023-09-13 12:54:40][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_30720`!\n",
      "[2023-09-13 12:54:43][INFO] SPS: 21\n",
      "[2023-09-13 12:54:46][INFO] global_step=30904, episodic_reward_predictor_return=0.37601643800735474\n",
      "[2023-09-13 12:54:46][INFO] global_step=30904, episodic_env_return=73.0\n",
      "[2023-09-13 12:54:46][INFO] global_step=30952, episodic_reward_predictor_return=-2.42618727684021\n",
      "[2023-09-13 12:54:46][INFO] global_step=30952, episodic_env_return=-370.0\n",
      "[2023-09-13 12:54:47][INFO] global_step=31008, episodic_reward_predictor_return=0.5531449317932129\n",
      "[2023-09-13 12:54:47][INFO] global_step=31008, episodic_env_return=47.0\n",
      "[2023-09-13 12:54:47][INFO] global_step=31016, episodic_reward_predictor_return=2.0652618408203125\n",
      "[2023-09-13 12:54:47][INFO] global_step=31016, episodic_env_return=-196.0\n",
      "[2023-09-13 12:54:48][INFO] global_step=31040, episodic_reward_predictor_return=0.552401065826416\n",
      "[2023-09-13 12:54:48][INFO] global_step=31040, episodic_env_return=-48.0\n",
      "[2023-09-13 12:54:48][INFO] global_step=31072, episodic_reward_predictor_return=0.1993962973356247\n",
      "[2023-09-13 12:54:48][INFO] global_step=31072, episodic_env_return=93.0\n",
      "[2023-09-13 12:54:49][INFO] global_step=31088, episodic_reward_predictor_return=0.29611268639564514\n",
      "[2023-09-13 12:54:49][INFO] global_step=31088, episodic_env_return=92.0\n",
      "[2023-09-13 12:54:51][INFO] global_step=31200, episodic_reward_predictor_return=0.06933138519525528\n",
      "[2023-09-13 12:54:51][INFO] global_step=31200, episodic_env_return=85.0\n",
      "[2023-09-13 12:54:53][INFO] global_step=31376, episodic_reward_predictor_return=0.9852471947669983\n",
      "[2023-09-13 12:54:53][INFO] global_step=31376, episodic_env_return=54.0\n",
      "[2023-09-13 12:54:58][INFO] global_step=31616, episodic_reward_predictor_return=0.2454710751771927\n",
      "[2023-09-13 12:54:58][INFO] global_step=31616, episodic_env_return=-111.0\n",
      "[2023-09-13 12:55:00][INFO] global_step=31776, episodic_reward_predictor_return=1.6347417831420898\n",
      "[2023-09-13 12:55:00][INFO] global_step=31776, episodic_env_return=-22.0\n",
      "[2023-09-13 12:55:01][INFO] global_step=31840, episodic_reward_predictor_return=0.07519027590751648\n",
      "[2023-09-13 12:55:01][INFO] global_step=31840, episodic_env_return=93.0\n",
      "[2023-09-13 12:55:02][INFO] global_step=31856, episodic_reward_predictor_return=-1.8638832569122314\n",
      "[2023-09-13 12:55:02][INFO] global_step=31856, episodic_env_return=-370.0\n",
      "[2023-09-13 12:55:03][INFO] global_step=31920, episodic_reward_predictor_return=1.1716187000274658\n",
      "[2023-09-13 12:55:03][INFO] global_step=31920, episodic_env_return=1.0\n",
      "[2023-09-13 12:55:04][INFO] global_step=32008, episodic_reward_predictor_return=0.3733423054218292\n",
      "[2023-09-13 12:55:04][INFO] global_step=32008, episodic_env_return=82.0\n",
      "[2023-09-13 12:55:07][INFO] global_step=32160, episodic_reward_predictor_return=0.7447923421859741\n",
      "[2023-09-13 12:55:07][INFO] global_step=32160, episodic_env_return=66.0\n",
      "[2023-09-13 12:55:13][INFO] global_step=32528, episodic_reward_predictor_return=-0.516574501991272\n",
      "[2023-09-13 12:55:13][INFO] global_step=32528, episodic_env_return=-370.0\n",
      "[2023-09-13 12:55:17][INFO] global_step=32760, episodic_reward_predictor_return=0.9541823267936707\n",
      "[2023-09-13 12:55:17][INFO] global_step=32760, episodic_env_return=-8.0\n",
      "[2023-09-13 12:55:17][INFO] Current Mean Episodic Return = 0.30497804284095764\n",
      "[2023-09-13 12:55:17][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_32768`...\n",
      "[2023-09-13 12:55:17][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_32768`!\n",
      "[2023-09-13 12:55:20][INFO] SPS: 21\n",
      "[2023-09-13 12:55:20][INFO] global_step=32808, episodic_reward_predictor_return=1.166085958480835\n",
      "[2023-09-13 12:55:20][INFO] global_step=32808, episodic_env_return=-35.0\n",
      "[2023-09-13 12:55:28][INFO] global_step=33304, episodic_reward_predictor_return=-1.7673529386520386\n",
      "[2023-09-13 12:55:28][INFO] global_step=33304, episodic_env_return=-370.0\n",
      "[2023-09-13 12:55:29][INFO] global_step=33352, episodic_reward_predictor_return=0.4771748483181\n",
      "[2023-09-13 12:55:29][INFO] global_step=33352, episodic_env_return=12.0\n",
      "[2023-09-13 12:55:31][INFO] global_step=33488, episodic_reward_predictor_return=0.3887230157852173\n",
      "[2023-09-13 12:55:31][INFO] global_step=33488, episodic_env_return=84.0\n",
      "[2023-09-13 12:55:31][INFO] global_step=33488, episodic_reward_predictor_return=0.1939736157655716\n",
      "[2023-09-13 12:55:31][INFO] global_step=33488, episodic_env_return=-365.0\n",
      "[2023-09-13 12:55:32][INFO] global_step=33536, episodic_reward_predictor_return=0.08561412245035172\n",
      "[2023-09-13 12:55:32][INFO] global_step=33536, episodic_env_return=95.0\n",
      "[2023-09-13 12:55:35][INFO] global_step=33720, episodic_reward_predictor_return=0.33552882075309753\n",
      "[2023-09-13 12:55:35][INFO] global_step=33720, episodic_env_return=67.0\n",
      "[2023-09-13 12:55:36][INFO] global_step=33760, episodic_reward_predictor_return=0.9883555173873901\n",
      "[2023-09-13 12:55:36][INFO] global_step=33760, episodic_env_return=73.0\n",
      "[2023-09-13 12:55:36][INFO] global_step=33776, episodic_reward_predictor_return=-0.9425628781318665\n",
      "[2023-09-13 12:55:36][INFO] global_step=33776, episodic_env_return=-380.0\n",
      "[2023-09-13 12:55:39][INFO] global_step=33960, episodic_reward_predictor_return=0.9280642867088318\n",
      "[2023-09-13 12:55:39][INFO] global_step=33960, episodic_env_return=76.0\n",
      "[2023-09-13 12:55:40][INFO] global_step=34016, episodic_reward_predictor_return=-1.5683510303497314\n",
      "[2023-09-13 12:55:40][INFO] global_step=34016, episodic_env_return=-365.0\n",
      "[2023-09-13 12:55:41][INFO] global_step=34064, episodic_reward_predictor_return=0.8526279926300049\n",
      "[2023-09-13 12:55:41][INFO] global_step=34064, episodic_env_return=-4.0\n",
      "[2023-09-13 12:55:43][INFO] global_step=34192, episodic_reward_predictor_return=-1.1363445520401\n",
      "[2023-09-13 12:55:43][INFO] global_step=34192, episodic_env_return=-203.0\n",
      "[2023-09-13 12:55:45][INFO] global_step=34344, episodic_reward_predictor_return=0.34144502878189087\n",
      "[2023-09-13 12:55:45][INFO] global_step=34344, episodic_env_return=48.0\n",
      "[2023-09-13 12:55:47][INFO] global_step=34440, episodic_reward_predictor_return=0.7369908094406128\n",
      "[2023-09-13 12:55:47][INFO] global_step=34440, episodic_env_return=43.0\n",
      "[2023-09-13 12:55:52][INFO] global_step=34768, episodic_reward_predictor_return=1.1582393646240234\n",
      "[2023-09-13 12:55:52][INFO] global_step=34768, episodic_env_return=38.0\n",
      "[2023-09-13 12:55:53][INFO] Current Mean Episodic Return = 0.13988827168941498\n",
      "[2023-09-13 12:55:53][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_34816`...\n",
      "[2023-09-13 12:55:53][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_34816`!\n",
      "[2023-09-13 12:55:56][INFO] SPS: 22\n",
      "[2023-09-13 12:55:56][INFO] global_step=34824, episodic_reward_predictor_return=0.336776465177536\n",
      "[2023-09-13 12:55:56][INFO] global_step=34824, episodic_env_return=-60.0\n",
      "[2023-09-13 12:55:57][INFO] global_step=34928, episodic_reward_predictor_return=1.0509469509124756\n",
      "[2023-09-13 12:55:57][INFO] global_step=34928, episodic_env_return=-370.0\n",
      "[2023-09-13 12:56:02][INFO] global_step=35208, episodic_reward_predictor_return=-2.7368221282958984\n",
      "[2023-09-13 12:56:02][INFO] global_step=35208, episodic_env_return=-385.0\n",
      "[2023-09-13 12:56:03][INFO] global_step=35296, episodic_reward_predictor_return=1.4765546321868896\n",
      "[2023-09-13 12:56:03][INFO] global_step=35296, episodic_env_return=-21.0\n",
      "[2023-09-13 12:56:05][INFO] global_step=35392, episodic_reward_predictor_return=0.2581993639469147\n",
      "[2023-09-13 12:56:05][INFO] global_step=35392, episodic_env_return=25.0\n",
      "[2023-09-13 12:56:08][INFO] global_step=35552, episodic_reward_predictor_return=0.4837098717689514\n",
      "[2023-09-13 12:56:08][INFO] global_step=35552, episodic_env_return=69.0\n",
      "[2023-09-13 12:56:15][INFO] global_step=36000, episodic_reward_predictor_return=0.6524239778518677\n",
      "[2023-09-13 12:56:15][INFO] global_step=36000, episodic_env_return=35.0\n",
      "[2023-09-13 12:56:17][INFO] global_step=36120, episodic_reward_predictor_return=-1.3269743919372559\n",
      "[2023-09-13 12:56:17][INFO] global_step=36120, episodic_env_return=-375.0\n",
      "[2023-09-13 12:56:20][INFO] global_step=36288, episodic_reward_predictor_return=0.5020620226860046\n",
      "[2023-09-13 12:56:20][INFO] global_step=36288, episodic_env_return=80.0\n",
      "[2023-09-13 12:56:22][INFO] global_step=36464, episodic_reward_predictor_return=0.7912037372589111\n",
      "[2023-09-13 12:56:22][INFO] global_step=36464, episodic_env_return=-370.0\n",
      "[2023-09-13 12:56:25][INFO] global_step=36592, episodic_reward_predictor_return=-0.9268563985824585\n",
      "[2023-09-13 12:56:25][INFO] global_step=36592, episodic_env_return=-385.0\n",
      "[2023-09-13 12:56:27][INFO] global_step=36768, episodic_reward_predictor_return=0.25012901425361633\n",
      "[2023-09-13 12:56:27][INFO] global_step=36768, episodic_env_return=26.0\n",
      "[2023-09-13 12:56:29][INFO] Current Mean Episodic Return = 0.06761275976896286\n",
      "[2023-09-13 12:56:29][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_36864`...\n",
      "[2023-09-13 12:56:29][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_36864`!\n",
      "[2023-09-13 12:56:31][INFO] SPS: 23\n",
      "[2023-09-13 12:56:32][INFO] global_step=36888, episodic_reward_predictor_return=0.4134378135204315\n",
      "[2023-09-13 12:56:32][INFO] global_step=36888, episodic_env_return=86.0\n",
      "[2023-09-13 12:56:33][INFO] global_step=36968, episodic_reward_predictor_return=1.5927749872207642\n",
      "[2023-09-13 12:56:33][INFO] global_step=36968, episodic_env_return=-199.0\n",
      "[2023-09-13 12:56:35][INFO] global_step=37096, episodic_reward_predictor_return=0.31924912333488464\n",
      "[2023-09-13 12:56:35][INFO] global_step=37096, episodic_env_return=75.0\n",
      "[2023-09-13 12:56:36][INFO] global_step=37168, episodic_reward_predictor_return=1.9545127153396606\n",
      "[2023-09-13 12:56:36][INFO] global_step=37168, episodic_env_return=-355.0\n",
      "[2023-09-13 12:56:36][INFO] global_step=37184, episodic_reward_predictor_return=1.0332682132720947\n",
      "[2023-09-13 12:56:36][INFO] global_step=37184, episodic_env_return=74.0\n",
      "[2023-09-13 12:56:37][INFO] global_step=37224, episodic_reward_predictor_return=0.14608249068260193\n",
      "[2023-09-13 12:56:37][INFO] global_step=37224, episodic_env_return=94.0\n",
      "[2023-09-13 12:56:39][INFO] global_step=37352, episodic_reward_predictor_return=0.18448059260845184\n",
      "[2023-09-13 12:56:39][INFO] global_step=37352, episodic_env_return=75.0\n",
      "[2023-09-13 12:56:41][INFO] global_step=37488, episodic_reward_predictor_return=1.0956867933273315\n",
      "[2023-09-13 12:56:41][INFO] global_step=37488, episodic_env_return=47.0\n",
      "[2023-09-13 12:56:44][INFO] global_step=37608, episodic_reward_predictor_return=-3.2295217514038086\n",
      "[2023-09-13 12:56:44][INFO] global_step=37608, episodic_env_return=-370.0\n",
      "[2023-09-13 12:56:44][INFO] global_step=37616, episodic_reward_predictor_return=0.4293386936187744\n",
      "[2023-09-13 12:56:44][INFO] global_step=37616, episodic_env_return=85.0\n",
      "[2023-09-13 12:56:45][INFO] global_step=37664, episodic_reward_predictor_return=0.3471706509590149\n",
      "[2023-09-13 12:56:45][INFO] global_step=37664, episodic_env_return=95.0\n",
      "[2023-09-13 12:56:47][INFO] global_step=37792, episodic_reward_predictor_return=-0.39759331941604614\n",
      "[2023-09-13 12:56:47][INFO] global_step=37792, episodic_env_return=-375.0\n",
      "[2023-09-13 12:56:47][INFO] global_step=37808, episodic_reward_predictor_return=0.38890567421913147\n",
      "[2023-09-13 12:56:47][INFO] global_step=37808, episodic_env_return=83.0\n",
      "[2023-09-13 12:56:47][INFO] global_step=37840, episodic_reward_predictor_return=0.7550956606864929\n",
      "[2023-09-13 12:56:47][INFO] global_step=37840, episodic_env_return=72.0\n",
      "[2023-09-13 12:56:53][INFO] global_step=38152, episodic_reward_predictor_return=0.6111235618591309\n",
      "[2023-09-13 12:56:53][INFO] global_step=38152, episodic_env_return=57.0\n",
      "[2023-09-13 12:56:56][INFO] global_step=38328, episodic_reward_predictor_return=-0.8560145497322083\n",
      "[2023-09-13 12:56:56][INFO] global_step=38328, episodic_env_return=-46.0\n",
      "[2023-09-13 12:56:57][INFO] global_step=38400, episodic_reward_predictor_return=1.6184078454971313\n",
      "[2023-09-13 12:56:57][INFO] global_step=38400, episodic_env_return=-350.0\n",
      "[2023-09-13 12:57:01][INFO] global_step=38624, episodic_reward_predictor_return=1.1315412521362305\n",
      "[2023-09-13 12:57:01][INFO] global_step=38624, episodic_env_return=42.0\n",
      "[2023-09-13 12:57:01][INFO] global_step=38656, episodic_reward_predictor_return=-3.2789835929870605\n",
      "[2023-09-13 12:57:01][INFO] global_step=38656, episodic_env_return=-243.0\n",
      "[2023-09-13 12:57:05][INFO] Current Mean Episodic Return = 0.22415593266487122\n",
      "[2023-09-13 12:57:05][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_38912`...\n",
      "[2023-09-13 12:57:05][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_38912`!\n",
      "[2023-09-13 12:57:08][INFO] SPS: 24\n",
      "[2023-09-13 12:57:09][INFO] global_step=38992, episodic_reward_predictor_return=-8.882048606872559\n",
      "[2023-09-13 12:57:09][INFO] global_step=38992, episodic_env_return=-375.0\n",
      "[2023-09-13 12:57:10][INFO] global_step=39040, episodic_reward_predictor_return=0.4939948320388794\n",
      "[2023-09-13 12:57:10][INFO] global_step=39040, episodic_env_return=16.0\n",
      "[2023-09-13 12:57:19][INFO] global_step=39624, episodic_reward_predictor_return=-1.0922728776931763\n",
      "[2023-09-13 12:57:19][INFO] global_step=39624, episodic_env_return=-370.0\n",
      "[2023-09-13 12:57:20][INFO] global_step=39680, episodic_reward_predictor_return=-1.3760331869125366\n",
      "[2023-09-13 12:57:20][INFO] global_step=39680, episodic_env_return=-57.0\n",
      "[2023-09-13 12:57:23][INFO] global_step=39832, episodic_reward_predictor_return=0.843279242515564\n",
      "[2023-09-13 12:57:23][INFO] global_step=39832, episodic_env_return=70.0\n",
      "[2023-09-13 12:57:26][INFO] global_step=40032, episodic_reward_predictor_return=-0.8015719652175903\n",
      "[2023-09-13 12:57:26][INFO] global_step=40032, episodic_env_return=-48.0\n",
      "[2023-09-13 12:57:27][INFO] global_step=40072, episodic_reward_predictor_return=-0.28604257106781006\n",
      "[2023-09-13 12:57:27][INFO] global_step=40072, episodic_env_return=-177.0\n",
      "[2023-09-13 12:57:28][INFO] global_step=40112, episodic_reward_predictor_return=0.7044346332550049\n",
      "[2023-09-13 12:57:28][INFO] global_step=40112, episodic_env_return=47.0\n",
      "[2023-09-13 12:57:29][INFO] global_step=40184, episodic_reward_predictor_return=-0.0007759910076856613\n",
      "[2023-09-13 12:57:29][INFO] global_step=40184, episodic_env_return=87.0\n",
      "[2023-09-13 12:57:29][INFO] global_step=40192, episodic_reward_predictor_return=-6.266889572143555\n",
      "[2023-09-13 12:57:29][INFO] global_step=40192, episodic_env_return=-365.0\n",
      "[2023-09-13 12:57:29][INFO] global_step=40208, episodic_reward_predictor_return=-0.6713400483131409\n",
      "[2023-09-13 12:57:29][INFO] global_step=40208, episodic_env_return=-375.0\n",
      "[2023-09-13 12:57:31][INFO] global_step=40328, episodic_reward_predictor_return=0.3428165316581726\n",
      "[2023-09-13 12:57:31][INFO] global_step=40328, episodic_env_return=69.0\n",
      "[2023-09-13 12:57:31][INFO] global_step=40336, episodic_reward_predictor_return=0.1314038634300232\n",
      "[2023-09-13 12:57:31][INFO] global_step=40336, episodic_env_return=-158.0\n",
      "[2023-09-13 12:57:33][INFO] global_step=40408, episodic_reward_predictor_return=0.222990021109581\n",
      "[2023-09-13 12:57:33][INFO] global_step=40408, episodic_env_return=68.0\n",
      "[2023-09-13 12:57:34][INFO] global_step=40496, episodic_reward_predictor_return=0.9524139165878296\n",
      "[2023-09-13 12:57:34][INFO] global_step=40496, episodic_env_return=80.0\n",
      "[2023-09-13 12:57:35][INFO] global_step=40568, episodic_reward_predictor_return=0.8085216879844666\n",
      "[2023-09-13 12:57:35][INFO] global_step=40568, episodic_env_return=24.0\n",
      "[2023-09-13 12:57:36][INFO] global_step=40640, episodic_reward_predictor_return=2.189086675643921\n",
      "[2023-09-13 12:57:36][INFO] global_step=40640, episodic_env_return=-10.0\n",
      "[2023-09-13 12:57:38][INFO] global_step=40752, episodic_reward_predictor_return=0.6280457973480225\n",
      "[2023-09-13 12:57:38][INFO] global_step=40752, episodic_env_return=64.0\n",
      "[2023-09-13 12:57:39][INFO] global_step=40824, episodic_reward_predictor_return=1.3167760372161865\n",
      "[2023-09-13 12:57:39][INFO] global_step=40824, episodic_env_return=7.0\n",
      "[2023-09-13 12:57:40][INFO] global_step=40848, episodic_reward_predictor_return=1.113619327545166\n",
      "[2023-09-13 12:57:40][INFO] global_step=40848, episodic_env_return=41.0\n",
      "[2023-09-13 12:57:42][INFO] Current Mean Episodic Return = -0.48147955536842346\n",
      "[2023-09-13 12:57:42][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_40960`...\n",
      "[2023-09-13 12:57:42][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_40960`!\n",
      "[2023-09-13 12:57:44][INFO] SPS: 25\n",
      "[2023-09-13 12:57:51][INFO] global_step=41392, episodic_reward_predictor_return=-3.4362823963165283\n",
      "[2023-09-13 12:57:51][INFO] global_step=41392, episodic_env_return=-370.0\n",
      "[2023-09-13 12:57:53][INFO] global_step=41528, episodic_reward_predictor_return=-1.4906983375549316\n",
      "[2023-09-13 12:57:53][INFO] global_step=41528, episodic_env_return=-40.0\n",
      "[2023-09-13 12:57:58][INFO] global_step=41808, episodic_reward_predictor_return=1.7553428411483765\n",
      "[2023-09-13 12:57:58][INFO] global_step=41808, episodic_env_return=49.0\n",
      "[2023-09-13 12:58:00][INFO] global_step=41960, episodic_reward_predictor_return=-1.3724206686019897\n",
      "[2023-09-13 12:58:00][INFO] global_step=41960, episodic_env_return=-168.0\n",
      "[2023-09-13 12:58:07][INFO] global_step=42328, episodic_reward_predictor_return=-0.2570948600769043\n",
      "[2023-09-13 12:58:07][INFO] global_step=42328, episodic_env_return=26.0\n",
      "[2023-09-13 12:58:07][INFO] global_step=42352, episodic_reward_predictor_return=0.014522142708301544\n",
      "[2023-09-13 12:58:07][INFO] global_step=42352, episodic_env_return=-17.0\n",
      "[2023-09-13 12:58:08][INFO] global_step=42440, episodic_reward_predictor_return=0.3755541741847992\n",
      "[2023-09-13 12:58:08][INFO] global_step=42440, episodic_env_return=90.0\n",
      "[2023-09-13 12:58:10][INFO] global_step=42528, episodic_reward_predictor_return=0.33711478114128113\n",
      "[2023-09-13 12:58:10][INFO] global_step=42528, episodic_env_return=90.0\n",
      "[2023-09-13 12:58:10][INFO] global_step=42568, episodic_reward_predictor_return=-1.486372709274292\n",
      "[2023-09-13 12:58:10][INFO] global_step=42568, episodic_env_return=-186.0\n",
      "[2023-09-13 12:58:12][INFO] global_step=42656, episodic_reward_predictor_return=0.36123234033584595\n",
      "[2023-09-13 12:58:12][INFO] global_step=42656, episodic_env_return=60.0\n",
      "[2023-09-13 12:58:13][INFO] global_step=42736, episodic_reward_predictor_return=-0.7025389075279236\n",
      "[2023-09-13 12:58:13][INFO] global_step=42736, episodic_env_return=-365.0\n",
      "[2023-09-13 12:58:13][INFO] global_step=42736, episodic_reward_predictor_return=0.16360130906105042\n",
      "[2023-09-13 12:58:13][INFO] global_step=42736, episodic_env_return=-220.0\n",
      "[2023-09-13 12:58:16][INFO] global_step=42904, episodic_reward_predictor_return=1.1676175594329834\n",
      "[2023-09-13 12:58:16][INFO] global_step=42904, episodic_env_return=70.0\n",
      "[2023-09-13 12:58:18][INFO] Current Mean Episodic Return = -0.3515710234642029\n",
      "[2023-09-13 12:58:18][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_43008`...\n",
      "[2023-09-13 12:58:18][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_43008`!\n",
      "[2023-09-13 12:58:21][INFO] SPS: 25\n",
      "[2023-09-13 12:58:38][INFO] user_preference = 1\n",
      "[2023-09-13 12:58:38][INFO] reward_predictor_training_loss=2.4128971099853516\n",
      "[2023-09-13 12:59:11][INFO] user_preference = 1\n",
      "[2023-09-13 12:59:11][INFO] reward_predictor_training_loss=0.946326732635498\n",
      "[2023-09-13 12:59:22][INFO] user_preference = 1\n",
      "[2023-09-13 12:59:22][INFO] reward_predictor_training_loss=0.8625400066375732\n",
      "[2023-09-13 12:59:32][INFO] user_preference = 1\n",
      "[2023-09-13 12:59:33][INFO] reward_predictor_training_loss=0.012290295213460922\n",
      "[2023-09-13 12:59:42][INFO] user_preference = 0\n",
      "[2023-09-13 12:59:42][INFO] reward_predictor_training_loss=0.1031457707285881\n",
      "[2023-09-13 12:59:54][INFO] user_preference = 0\n",
      "[2023-09-13 12:59:54][INFO] reward_predictor_training_loss=0.7789473533630371\n",
      "[2023-09-13 13:00:17][INFO] user_preference = 0\n",
      "[2023-09-13 13:00:17][INFO] reward_predictor_training_loss=0.0498068667948246\n",
      "[2023-09-13 13:00:26][INFO] user_preference = 0\n",
      "[2023-09-13 13:00:26][INFO] reward_predictor_training_loss=0.9288679361343384\n",
      "[2023-09-13 13:00:37][INFO] user_preference = 1\n",
      "[2023-09-13 13:00:37][INFO] reward_predictor_training_loss=0.010021848604083061\n",
      "[2023-09-13 13:00:51][INFO] user_preference = 1\n",
      "[2023-09-13 13:00:51][INFO] reward_predictor_training_loss=2.688720703125\n",
      "[2023-09-13 13:01:01][INFO] user_preference = 0\n",
      "[2023-09-13 13:01:01][INFO] reward_predictor_training_loss=0.6196740865707397\n",
      "[2023-09-13 13:01:10][INFO] user_preference = 0\n",
      "[2023-09-13 13:01:10][INFO] reward_predictor_training_loss=0.7236526012420654\n",
      "[2023-09-13 13:01:17][INFO] user_preference = 0\n",
      "[2023-09-13 13:01:17][INFO] reward_predictor_training_loss=0.9994522333145142\n",
      "[2023-09-13 13:01:28][INFO] user_preference = 0\n",
      "[2023-09-13 13:01:28][INFO] reward_predictor_training_loss=1.822049617767334\n",
      "[2023-09-13 13:01:37][INFO] user_preference = 1\n",
      "[2023-09-13 13:01:37][INFO] reward_predictor_training_loss=1.5032554864883423\n",
      "[2023-09-13 13:01:47][INFO] user_preference = 0\n",
      "[2023-09-13 13:01:47][INFO] reward_predictor_training_loss=0.02022123895585537\n",
      "[2023-09-13 13:01:47][INFO] global_step=43016, episodic_reward_predictor_return=2.0309898853302\n",
      "[2023-09-13 13:01:47][INFO] global_step=43016, episodic_env_return=45.0\n",
      "[2023-09-13 13:01:49][INFO] global_step=43120, episodic_reward_predictor_return=0.12966975569725037\n",
      "[2023-09-13 13:01:49][INFO] global_step=43120, episodic_env_return=88.0\n",
      "[2023-09-13 13:01:50][INFO] global_step=43224, episodic_reward_predictor_return=-0.21210657060146332\n",
      "[2023-09-13 13:01:50][INFO] global_step=43224, episodic_env_return=-365.0\n",
      "[2023-09-13 13:01:51][INFO] global_step=43248, episodic_reward_predictor_return=-0.39207959175109863\n",
      "[2023-09-13 13:01:51][INFO] global_step=43248, episodic_env_return=-370.0\n",
      "[2023-09-13 13:01:52][INFO] global_step=43304, episodic_reward_predictor_return=-0.38061395287513733\n",
      "[2023-09-13 13:01:52][INFO] global_step=43304, episodic_env_return=20.0\n",
      "[2023-09-13 13:01:55][INFO] global_step=43488, episodic_reward_predictor_return=-1.437578558921814\n",
      "[2023-09-13 13:01:55][INFO] global_step=43488, episodic_env_return=-39.0\n",
      "[2023-09-13 13:01:55][INFO] global_step=43512, episodic_reward_predictor_return=0.22341802716255188\n",
      "[2023-09-13 13:01:55][INFO] global_step=43512, episodic_env_return=52.0\n",
      "[2023-09-13 13:01:59][INFO] global_step=43728, episodic_reward_predictor_return=-0.7517716288566589\n",
      "[2023-09-13 13:01:59][INFO] global_step=43728, episodic_env_return=33.0\n",
      "[2023-09-13 13:02:01][INFO] global_step=43888, episodic_reward_predictor_return=1.6328620910644531\n",
      "[2023-09-13 13:02:01][INFO] global_step=43888, episodic_env_return=21.0\n",
      "[2023-09-13 13:02:05][INFO] global_step=44120, episodic_reward_predictor_return=0.246245875954628\n",
      "[2023-09-13 13:02:05][INFO] global_step=44120, episodic_env_return=72.0\n",
      "[2023-09-13 13:02:07][INFO] global_step=44256, episodic_reward_predictor_return=0.7013433575630188\n",
      "[2023-09-13 13:02:07][INFO] global_step=44256, episodic_env_return=0.0\n",
      "[2023-09-13 13:02:07][INFO] global_step=44272, episodic_reward_predictor_return=0.2515694499015808\n",
      "[2023-09-13 13:02:07][INFO] global_step=44272, episodic_env_return=82.0\n",
      "[2023-09-13 13:02:09][INFO] global_step=44360, episodic_reward_predictor_return=-1.0704537630081177\n",
      "[2023-09-13 13:02:09][INFO] global_step=44360, episodic_env_return=-365.0\n",
      "[2023-09-13 13:02:21][INFO] Current Mean Episodic Return = 0.07473032921552658\n",
      "[2023-09-13 13:02:21][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_45056`...\n",
      "[2023-09-13 13:02:21][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_45056`!\n",
      "[2023-09-13 13:02:23][INFO] SPS: 23\n",
      "[2023-09-13 13:02:25][INFO] global_step=45136, episodic_reward_predictor_return=-3.993741512298584\n",
      "[2023-09-13 13:02:25][INFO] global_step=45136, episodic_env_return=-370.0\n",
      "[2023-09-13 13:02:27][INFO] global_step=45304, episodic_reward_predictor_return=-8.779723167419434\n",
      "[2023-09-13 13:02:27][INFO] global_step=45304, episodic_env_return=-360.0\n",
      "[2023-09-13 13:02:27][INFO] global_step=45312, episodic_reward_predictor_return=0.38450026512145996\n",
      "[2023-09-13 13:02:27][INFO] global_step=45312, episodic_env_return=-41.0\n",
      "[2023-09-13 13:02:29][INFO] global_step=45424, episodic_reward_predictor_return=-1.7713658809661865\n",
      "[2023-09-13 13:02:29][INFO] global_step=45424, episodic_env_return=-73.0\n",
      "[2023-09-13 13:02:32][INFO] global_step=45624, episodic_reward_predictor_return=-0.04808329790830612\n",
      "[2023-09-13 13:02:32][INFO] global_step=45624, episodic_env_return=-350.0\n",
      "[2023-09-13 13:02:33][INFO] global_step=45632, episodic_reward_predictor_return=-1.78754460811615\n",
      "[2023-09-13 13:02:33][INFO] global_step=45632, episodic_env_return=-187.0\n",
      "[2023-09-13 13:02:33][INFO] global_step=45664, episodic_reward_predictor_return=0.26968690752983093\n",
      "[2023-09-13 13:02:33][INFO] global_step=45664, episodic_env_return=56.0\n",
      "[2023-09-13 13:02:34][INFO] global_step=45728, episodic_reward_predictor_return=0.24196094274520874\n",
      "[2023-09-13 13:02:34][INFO] global_step=45728, episodic_env_return=88.0\n",
      "[2023-09-13 13:02:37][INFO] global_step=45888, episodic_reward_predictor_return=0.26573142409324646\n",
      "[2023-09-13 13:02:37][INFO] global_step=45888, episodic_env_return=73.0\n",
      "[2023-09-13 13:02:37][INFO] global_step=45912, episodic_reward_predictor_return=-2.516580581665039\n",
      "[2023-09-13 13:02:37][INFO] global_step=45912, episodic_env_return=-370.0\n",
      "[2023-09-13 13:02:39][INFO] global_step=46000, episodic_reward_predictor_return=-1.2859137058258057\n",
      "[2023-09-13 13:02:39][INFO] global_step=46000, episodic_env_return=5.0\n",
      "[2023-09-13 13:02:39][INFO] global_step=46032, episodic_reward_predictor_return=1.137787103652954\n",
      "[2023-09-13 13:02:39][INFO] global_step=46032, episodic_env_return=25.0\n",
      "[2023-09-13 13:02:40][INFO] global_step=46064, episodic_reward_predictor_return=-0.03897997736930847\n",
      "[2023-09-13 13:02:40][INFO] global_step=46064, episodic_env_return=42.0\n",
      "[2023-09-13 13:02:42][INFO] global_step=46192, episodic_reward_predictor_return=0.5659279823303223\n",
      "[2023-09-13 13:02:42][INFO] global_step=46192, episodic_env_return=77.0\n",
      "[2023-09-13 13:02:42][INFO] global_step=46200, episodic_reward_predictor_return=0.02365027368068695\n",
      "[2023-09-13 13:02:42][INFO] global_step=46200, episodic_env_return=42.0\n",
      "[2023-09-13 13:02:43][INFO] global_step=46272, episodic_reward_predictor_return=0.2489255666732788\n",
      "[2023-09-13 13:02:43][INFO] global_step=46272, episodic_env_return=91.0\n",
      "[2023-09-13 13:02:47][INFO] global_step=46488, episodic_reward_predictor_return=0.2797364592552185\n",
      "[2023-09-13 13:02:47][INFO] global_step=46488, episodic_env_return=65.0\n",
      "[2023-09-13 13:02:49][INFO] global_step=46632, episodic_reward_predictor_return=-0.498081773519516\n",
      "[2023-09-13 13:02:49][INFO] global_step=46632, episodic_env_return=16.0\n",
      "[2023-09-13 13:02:51][INFO] global_step=46760, episodic_reward_predictor_return=-2.5020179748535156\n",
      "[2023-09-13 13:02:51][INFO] global_step=46760, episodic_env_return=-375.0\n",
      "[2023-09-13 13:02:54][INFO] global_step=46912, episodic_reward_predictor_return=-0.49500399827957153\n",
      "[2023-09-13 13:02:54][INFO] global_step=46912, episodic_env_return=-42.0\n",
      "[2023-09-13 13:02:56][INFO] global_step=47040, episodic_reward_predictor_return=0.5328946709632874\n",
      "[2023-09-13 13:02:56][INFO] global_step=47040, episodic_env_return=27.0\n",
      "[2023-09-13 13:02:57][INFO] Current Mean Episodic Return = -0.9412493705749512\n",
      "[2023-09-13 13:02:57][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_47104`...\n",
      "[2023-09-13 13:02:57][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_47104`!\n",
      "[2023-09-13 13:03:00][INFO] SPS: 24\n",
      "[2023-09-13 13:03:00][INFO] global_step=47160, episodic_reward_predictor_return=0.45094040036201477\n",
      "[2023-09-13 13:03:00][INFO] global_step=47160, episodic_env_return=46.0\n",
      "[2023-09-13 13:03:05][INFO] global_step=47424, episodic_reward_predictor_return=-1.5949299335479736\n",
      "[2023-09-13 13:03:05][INFO] global_step=47424, episodic_env_return=-123.0\n",
      "[2023-09-13 13:03:06][INFO] global_step=47512, episodic_reward_predictor_return=0.7685337662696838\n",
      "[2023-09-13 13:03:06][INFO] global_step=47512, episodic_env_return=-64.0\n",
      "[2023-09-13 13:03:06][INFO] global_step=47536, episodic_reward_predictor_return=-2.8031883239746094\n",
      "[2023-09-13 13:03:06][INFO] global_step=47536, episodic_env_return=-365.0\n",
      "[2023-09-13 13:03:12][INFO] global_step=47840, episodic_reward_predictor_return=0.8997764587402344\n",
      "[2023-09-13 13:03:12][INFO] global_step=47840, episodic_env_return=60.0\n",
      "[2023-09-13 13:03:12][INFO] global_step=47848, episodic_reward_predictor_return=-0.16004009544849396\n",
      "[2023-09-13 13:03:12][INFO] global_step=47848, episodic_env_return=62.0\n",
      "[2023-09-13 13:03:12][INFO] global_step=47856, episodic_reward_predictor_return=0.8056827187538147\n",
      "[2023-09-13 13:03:12][INFO] global_step=47856, episodic_env_return=-6.0\n",
      "[2023-09-13 13:03:14][INFO] global_step=47984, episodic_reward_predictor_return=0.10878576338291168\n",
      "[2023-09-13 13:03:14][INFO] global_step=47984, episodic_env_return=26.0\n",
      "[2023-09-13 13:03:14][INFO] global_step=48000, episodic_reward_predictor_return=0.6431731581687927\n",
      "[2023-09-13 13:03:14][INFO] global_step=48000, episodic_env_return=81.0\n",
      "[2023-09-13 13:03:20][INFO] global_step=48352, episodic_reward_predictor_return=0.5410363674163818\n",
      "[2023-09-13 13:03:20][INFO] global_step=48352, episodic_env_return=38.0\n",
      "[2023-09-13 13:03:22][INFO] global_step=48464, episodic_reward_predictor_return=-1.5507508516311646\n",
      "[2023-09-13 13:03:22][INFO] global_step=48464, episodic_env_return=-355.0\n",
      "[2023-09-13 13:03:24][INFO] global_step=48560, episodic_reward_predictor_return=-0.3669038414955139\n",
      "[2023-09-13 13:03:24][INFO] global_step=48560, episodic_env_return=21.0\n",
      "[2023-09-13 13:03:30][INFO] global_step=48960, episodic_reward_predictor_return=0.1990949809551239\n",
      "[2023-09-13 13:03:30][INFO] global_step=48960, episodic_env_return=51.0\n",
      "[2023-09-13 13:03:31][INFO] global_step=49032, episodic_reward_predictor_return=-1.53135347366333\n",
      "[2023-09-13 13:03:31][INFO] global_step=49032, episodic_env_return=-355.0\n",
      "[2023-09-13 13:03:32][INFO] global_step=49064, episodic_reward_predictor_return=-0.08097614347934723\n",
      "[2023-09-13 13:03:32][INFO] global_step=49064, episodic_env_return=21.0\n",
      "[2023-09-13 13:03:33][INFO] Current Mean Episodic Return = -0.2447412759065628\n",
      "[2023-09-13 13:03:33][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_49152`...\n",
      "[2023-09-13 13:03:33][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_49152`!\n",
      "[2023-09-13 13:03:36][INFO] SPS: 24\n",
      "[2023-09-13 13:03:37][INFO] global_step=49216, episodic_reward_predictor_return=-3.430727481842041\n",
      "[2023-09-13 13:03:37][INFO] global_step=49216, episodic_env_return=-104.0\n",
      "[2023-09-13 13:03:39][INFO] global_step=49312, episodic_reward_predictor_return=-3.3868162631988525\n",
      "[2023-09-13 13:03:39][INFO] global_step=49312, episodic_env_return=-375.0\n",
      "[2023-09-13 13:03:39][INFO] global_step=49320, episodic_reward_predictor_return=0.13652950525283813\n",
      "[2023-09-13 13:03:39][INFO] global_step=49320, episodic_env_return=51.0\n",
      "[2023-09-13 13:03:41][INFO] global_step=49472, episodic_reward_predictor_return=0.715337872505188\n",
      "[2023-09-13 13:03:41][INFO] global_step=49472, episodic_env_return=41.0\n",
      "[2023-09-13 13:03:43][INFO] global_step=49560, episodic_reward_predictor_return=-1.9946813583374023\n",
      "[2023-09-13 13:03:43][INFO] global_step=49560, episodic_env_return=-380.0\n",
      "[2023-09-13 13:03:44][INFO] global_step=49640, episodic_reward_predictor_return=0.15267741680145264\n",
      "[2023-09-13 13:03:44][INFO] global_step=49640, episodic_env_return=60.0\n",
      "[2023-09-13 13:03:47][INFO] global_step=49816, episodic_reward_predictor_return=0.7738600373268127\n",
      "[2023-09-13 13:03:47][INFO] global_step=49816, episodic_env_return=64.0\n",
      "[2023-09-13 13:03:49][INFO] global_step=49944, episodic_reward_predictor_return=0.12299421429634094\n",
      "[2023-09-13 13:03:49][INFO] global_step=49944, episodic_env_return=-14.0\n",
      "[2023-09-13 13:03:50][INFO] global_step=50016, episodic_reward_predictor_return=0.592972457408905\n",
      "[2023-09-13 13:03:50][INFO] global_step=50016, episodic_env_return=9.0\n",
      "[2023-09-13 13:03:54][INFO] global_step=50224, episodic_reward_predictor_return=0.41904258728027344\n",
      "[2023-09-13 13:03:54][INFO] global_step=50224, episodic_env_return=23.0\n",
      "[2023-09-13 13:03:55][INFO] global_step=50304, episodic_reward_predictor_return=0.5185445547103882\n",
      "[2023-09-13 13:03:55][INFO] global_step=50304, episodic_env_return=46.0\n",
      "[2023-09-13 13:03:56][INFO] global_step=50384, episodic_reward_predictor_return=-1.1133817434310913\n",
      "[2023-09-13 13:03:56][INFO] global_step=50384, episodic_env_return=-330.0\n",
      "[2023-09-13 13:03:57][INFO] global_step=50432, episodic_reward_predictor_return=0.4752131700515747\n",
      "[2023-09-13 13:03:57][INFO] global_step=50432, episodic_env_return=44.0\n",
      "[2023-09-13 13:03:57][INFO] global_step=50440, episodic_reward_predictor_return=0.3755694031715393\n",
      "[2023-09-13 13:03:57][INFO] global_step=50440, episodic_env_return=84.0\n",
      "[2023-09-13 13:03:59][INFO] global_step=50544, episodic_reward_predictor_return=0.4059906005859375\n",
      "[2023-09-13 13:03:59][INFO] global_step=50544, episodic_env_return=81.0\n",
      "[2023-09-13 13:04:01][INFO] global_step=50648, episodic_reward_predictor_return=-3.9370832443237305\n",
      "[2023-09-13 13:04:01][INFO] global_step=50648, episodic_env_return=-251.0\n",
      "[2023-09-13 13:04:02][INFO] global_step=50728, episodic_reward_predictor_return=0.7842773199081421\n",
      "[2023-09-13 13:04:02][INFO] global_step=50728, episodic_env_return=-113.0\n",
      "[2023-09-13 13:04:08][INFO] global_step=51072, episodic_reward_predictor_return=0.7332533597946167\n",
      "[2023-09-13 13:04:08][INFO] global_step=51072, episodic_env_return=58.0\n",
      "[2023-09-13 13:04:10][INFO] Current Mean Episodic Return = -0.4253571331501007\n",
      "[2023-09-13 13:04:10][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_51200`...\n",
      "[2023-09-13 13:04:10][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_51200`!\n",
      "[2023-09-13 13:04:13][INFO] SPS: 25\n",
      "[2023-09-13 13:04:21][INFO] global_step=51712, episodic_reward_predictor_return=0.5980349183082581\n",
      "[2023-09-13 13:04:21][INFO] global_step=51712, episodic_env_return=-161.0\n",
      "[2023-09-13 13:04:21][INFO] global_step=51720, episodic_reward_predictor_return=-0.13635779917240143\n",
      "[2023-09-13 13:04:21][INFO] global_step=51720, episodic_env_return=0.0\n",
      "[2023-09-13 13:04:21][INFO] global_step=51752, episodic_reward_predictor_return=0.8229224681854248\n",
      "[2023-09-13 13:04:21][INFO] global_step=51752, episodic_env_return=-70.0\n",
      "[2023-09-13 13:04:24][INFO] global_step=51872, episodic_reward_predictor_return=0.9073262214660645\n",
      "[2023-09-13 13:04:24][INFO] global_step=51872, episodic_env_return=-335.0\n",
      "[2023-09-13 13:04:25][INFO] global_step=51976, episodic_reward_predictor_return=0.2854786813259125\n",
      "[2023-09-13 13:04:25][INFO] global_step=51976, episodic_env_return=-112.0\n",
      "[2023-09-13 13:04:26][INFO] global_step=52048, episodic_reward_predictor_return=0.0035221665166318417\n",
      "[2023-09-13 13:04:26][INFO] global_step=52048, episodic_env_return=54.0\n",
      "[2023-09-13 13:04:28][INFO] global_step=52120, episodic_reward_predictor_return=0.6108763813972473\n",
      "[2023-09-13 13:04:28][INFO] global_step=52120, episodic_env_return=51.0\n",
      "[2023-09-13 13:04:28][INFO] global_step=52136, episodic_reward_predictor_return=-0.17297309637069702\n",
      "[2023-09-13 13:04:28][INFO] global_step=52136, episodic_env_return=-105.0\n",
      "[2023-09-13 13:04:30][INFO] global_step=52264, episodic_reward_predictor_return=0.1445026695728302\n",
      "[2023-09-13 13:04:30][INFO] global_step=52264, episodic_env_return=85.0\n",
      "[2023-09-13 13:04:31][INFO] global_step=52312, episodic_reward_predictor_return=-0.45891231298446655\n",
      "[2023-09-13 13:04:31][INFO] global_step=52312, episodic_env_return=26.0\n",
      "[2023-09-13 13:04:32][INFO] global_step=52368, episodic_reward_predictor_return=0.7318666577339172\n",
      "[2023-09-13 13:04:32][INFO] global_step=52368, episodic_env_return=52.0\n",
      "[2023-09-13 13:04:32][INFO] global_step=52400, episodic_reward_predictor_return=-0.08347006142139435\n",
      "[2023-09-13 13:04:32][INFO] global_step=52400, episodic_env_return=15.0\n",
      "[2023-09-13 13:04:35][INFO] global_step=52576, episodic_reward_predictor_return=0.37922632694244385\n",
      "[2023-09-13 13:04:35][INFO] global_step=52576, episodic_env_return=30.0\n",
      "[2023-09-13 13:04:35][INFO] global_step=52584, episodic_reward_predictor_return=0.7694072127342224\n",
      "[2023-09-13 13:04:35][INFO] global_step=52584, episodic_env_return=61.0\n",
      "[2023-09-13 13:04:36][INFO] global_step=52624, episodic_reward_predictor_return=-3.339423894882202\n",
      "[2023-09-13 13:04:36][INFO] global_step=52624, episodic_env_return=-375.0\n",
      "[2023-09-13 13:04:39][INFO] global_step=52840, episodic_reward_predictor_return=-0.5746126770973206\n",
      "[2023-09-13 13:04:39][INFO] global_step=52840, episodic_env_return=-350.0\n",
      "[2023-09-13 13:04:42][INFO] global_step=52992, episodic_reward_predictor_return=-0.2953060567378998\n",
      "[2023-09-13 13:04:42][INFO] global_step=52992, episodic_env_return=12.0\n",
      "[2023-09-13 13:04:42][INFO] global_step=53016, episodic_reward_predictor_return=0.8557483553886414\n",
      "[2023-09-13 13:04:42][INFO] global_step=53016, episodic_env_return=47.0\n",
      "[2023-09-13 13:04:46][INFO] global_step=53240, episodic_reward_predictor_return=-0.07207085937261581\n",
      "[2023-09-13 13:04:46][INFO] global_step=53240, episodic_env_return=-54.0\n",
      "[2023-09-13 13:04:46][INFO] Current Mean Episodic Return = 0.051357124000787735\n",
      "[2023-09-13 13:04:46][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_53248`...\n",
      "[2023-09-13 13:04:46][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_53248`!\n",
      "[2023-09-13 13:04:49][INFO] SPS: 25\n",
      "[2023-09-13 13:04:52][INFO] global_step=53464, episodic_reward_predictor_return=0.5208854675292969\n",
      "[2023-09-13 13:04:52][INFO] global_step=53464, episodic_env_return=-4.0\n",
      "[2023-09-13 13:04:58][INFO] global_step=53776, episodic_reward_predictor_return=0.7750569581985474\n",
      "[2023-09-13 13:04:58][INFO] global_step=53776, episodic_env_return=-2.0\n",
      "[2023-09-13 13:04:58][INFO] global_step=53784, episodic_reward_predictor_return=0.1835850179195404\n",
      "[2023-09-13 13:04:58][INFO] global_step=53784, episodic_env_return=-32.0\n",
      "[2023-09-13 13:05:12][INFO] global_step=54648, episodic_reward_predictor_return=-0.24259617924690247\n",
      "[2023-09-13 13:05:12][INFO] global_step=54648, episodic_env_return=-13.0\n",
      "[2023-09-13 13:05:13][INFO] global_step=54712, episodic_reward_predictor_return=-4.041472911834717\n",
      "[2023-09-13 13:05:13][INFO] global_step=54712, episodic_env_return=-385.0\n",
      "[2023-09-13 13:05:14][INFO] global_step=54768, episodic_reward_predictor_return=-2.2329142093658447\n",
      "[2023-09-13 13:05:14][INFO] global_step=54768, episodic_env_return=-390.0\n",
      "[2023-09-13 13:05:16][INFO] global_step=54912, episodic_reward_predictor_return=-3.276749610900879\n",
      "[2023-09-13 13:05:16][INFO] global_step=54912, episodic_env_return=-181.0\n",
      "[2023-09-13 13:05:17][INFO] global_step=54976, episodic_reward_predictor_return=-4.0843186378479\n",
      "[2023-09-13 13:05:17][INFO] global_step=54976, episodic_env_return=-380.0\n",
      "[2023-09-13 13:05:20][INFO] global_step=55144, episodic_reward_predictor_return=0.26955682039260864\n",
      "[2023-09-13 13:05:20][INFO] global_step=55144, episodic_env_return=42.0\n",
      "[2023-09-13 13:05:22][INFO] global_step=55240, episodic_reward_predictor_return=0.049511343240737915\n",
      "[2023-09-13 13:05:22][INFO] global_step=55240, episodic_env_return=63.0\n",
      "[2023-09-13 13:05:22][INFO] Current Mean Episodic Return = -1.207945704460144\n",
      "[2023-09-13 13:05:22][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_55296`...\n",
      "[2023-09-13 13:05:23][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_55296`!\n",
      "[2023-09-13 13:05:25][INFO] SPS: 26\n",
      "[2023-09-13 13:05:27][INFO] global_step=55408, episodic_reward_predictor_return=-0.07823966443538666\n",
      "[2023-09-13 13:05:27][INFO] global_step=55408, episodic_env_return=1.0\n",
      "[2023-09-13 13:05:29][INFO] global_step=55512, episodic_reward_predictor_return=0.9076626300811768\n",
      "[2023-09-13 13:05:29][INFO] global_step=55512, episodic_env_return=55.0\n",
      "[2023-09-13 13:05:31][INFO] global_step=55640, episodic_reward_predictor_return=-2.0093424320220947\n",
      "[2023-09-13 13:05:31][INFO] global_step=55640, episodic_env_return=-365.0\n",
      "[2023-09-13 13:05:34][INFO] global_step=55800, episodic_reward_predictor_return=0.6889866590499878\n",
      "[2023-09-13 13:05:34][INFO] global_step=55800, episodic_env_return=26.0\n",
      "[2023-09-13 13:05:35][INFO] global_step=55864, episodic_reward_predictor_return=-2.892329692840576\n",
      "[2023-09-13 13:05:35][INFO] global_step=55864, episodic_env_return=-375.0\n",
      "[2023-09-13 13:05:39][INFO] global_step=56136, episodic_reward_predictor_return=-0.8820387125015259\n",
      "[2023-09-13 13:05:39][INFO] global_step=56136, episodic_env_return=-10.0\n",
      "[2023-09-13 13:05:40][INFO] global_step=56184, episodic_reward_predictor_return=-4.052853107452393\n",
      "[2023-09-13 13:05:40][INFO] global_step=56184, episodic_env_return=-375.0\n",
      "[2023-09-13 13:05:41][INFO] global_step=56224, episodic_reward_predictor_return=-2.2289023399353027\n",
      "[2023-09-13 13:05:41][INFO] global_step=56224, episodic_env_return=-116.0\n",
      "[2023-09-13 13:05:42][INFO] global_step=56288, episodic_reward_predictor_return=-3.7832467555999756\n",
      "[2023-09-13 13:05:42][INFO] global_step=56288, episodic_env_return=-116.0\n",
      "[2023-09-13 13:05:45][INFO] global_step=56472, episodic_reward_predictor_return=0.29208675026893616\n",
      "[2023-09-13 13:05:45][INFO] global_step=56472, episodic_env_return=59.0\n",
      "[2023-09-13 13:05:46][INFO] global_step=56512, episodic_reward_predictor_return=0.006648242473602295\n",
      "[2023-09-13 13:05:46][INFO] global_step=56512, episodic_env_return=5.0\n",
      "[2023-09-13 13:05:50][INFO] global_step=56768, episodic_reward_predictor_return=0.5375990867614746\n",
      "[2023-09-13 13:05:50][INFO] global_step=56768, episodic_env_return=23.0\n",
      "[2023-09-13 13:05:52][INFO] global_step=56856, episodic_reward_predictor_return=0.5892776846885681\n",
      "[2023-09-13 13:05:52][INFO] global_step=56856, episodic_env_return=53.0\n",
      "[2023-09-13 13:05:55][INFO] global_step=57032, episodic_reward_predictor_return=-0.01792009174823761\n",
      "[2023-09-13 13:05:55][INFO] global_step=57032, episodic_env_return=79.0\n",
      "[2023-09-13 13:05:56][INFO] global_step=57096, episodic_reward_predictor_return=-1.1461478471755981\n",
      "[2023-09-13 13:05:56][INFO] global_step=57096, episodic_env_return=-131.0\n",
      "[2023-09-13 13:05:59][INFO] global_step=57248, episodic_reward_predictor_return=-0.2771458625793457\n",
      "[2023-09-13 13:05:59][INFO] global_step=57248, episodic_env_return=-37.0\n",
      "[2023-09-13 13:06:00][INFO] global_step=57320, episodic_reward_predictor_return=0.27667728066444397\n",
      "[2023-09-13 13:06:00][INFO] global_step=57320, episodic_env_return=73.0\n",
      "[2023-09-13 13:06:00][INFO] Current Mean Episodic Return = -0.8276016712188721\n",
      "[2023-09-13 13:06:00][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_57344`...\n",
      "[2023-09-13 13:06:00][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_57344`!\n",
      "[2023-09-13 13:06:03][INFO] SPS: 26\n",
      "[2023-09-13 13:07:58][INFO] user_preference = 0\n",
      "[2023-09-13 13:07:58][INFO] reward_predictor_training_loss=0.665803849697113\n",
      "[2023-09-13 13:08:10][INFO] user_preference = 0\n",
      "[2023-09-13 13:08:10][INFO] reward_predictor_training_loss=0.8059545159339905\n",
      "[2023-09-13 13:08:19][INFO] user_preference = 1\n",
      "[2023-09-13 13:08:20][INFO] reward_predictor_training_loss=0.011685612611472607\n",
      "[2023-09-13 13:08:36][INFO] user_preference = 0\n",
      "[2023-09-13 13:08:36][INFO] reward_predictor_training_loss=0.7511759996414185\n",
      "[2023-09-13 13:08:46][INFO] user_preference = 0\n",
      "[2023-09-13 13:08:46][INFO] reward_predictor_training_loss=0.07950218766927719\n",
      "[2023-09-13 13:08:56][INFO] user_preference = 0\n",
      "[2023-09-13 13:08:56][INFO] reward_predictor_training_loss=1.5496766567230225\n",
      "[2023-09-13 13:09:04][INFO] user_preference = 0\n",
      "[2023-09-13 13:09:05][INFO] reward_predictor_training_loss=1.0692014694213867\n",
      "[2023-09-13 13:09:14][INFO] user_preference = 0\n",
      "[2023-09-13 13:09:14][INFO] reward_predictor_training_loss=0.0026641180738806725\n",
      "[2023-09-13 13:09:34][INFO] user_preference = 1\n",
      "[2023-09-13 13:09:34][INFO] reward_predictor_training_loss=3.144843578338623\n",
      "[2023-09-13 13:09:54][INFO] user_preference = 1\n",
      "[2023-09-13 13:09:54][INFO] reward_predictor_training_loss=0.015806185081601143\n",
      "[2023-09-13 13:10:04][INFO] user_preference = 0\n",
      "[2023-09-13 13:10:04][INFO] reward_predictor_training_loss=0.0019492418505251408\n",
      "[2023-09-13 13:10:14][INFO] user_preference = 0\n",
      "[2023-09-13 13:10:14][INFO] reward_predictor_training_loss=0.3314144015312195\n",
      "[2023-09-13 13:10:24][INFO] user_preference = 0\n",
      "[2023-09-13 13:10:24][INFO] reward_predictor_training_loss=0.010368509218096733\n",
      "[2023-09-13 13:10:37][INFO] user_preference = 1\n",
      "[2023-09-13 13:10:37][INFO] reward_predictor_training_loss=0.14476105570793152\n",
      "[2023-09-13 13:10:51][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:10:51][INFO] reward_predictor_training_loss=0.977544367313385\n",
      "[2023-09-13 13:11:03][INFO] user_preference = 0\n",
      "[2023-09-13 13:11:03][INFO] reward_predictor_training_loss=0.7867699861526489\n",
      "[2023-09-13 13:11:05][INFO] global_step=57456, episodic_reward_predictor_return=0.02019120380282402\n",
      "[2023-09-13 13:11:05][INFO] global_step=57456, episodic_env_return=84.0\n",
      "[2023-09-13 13:11:06][INFO] global_step=57552, episodic_reward_predictor_return=0.17574313282966614\n",
      "[2023-09-13 13:11:06][INFO] global_step=57552, episodic_env_return=-7.0\n",
      "[2023-09-13 13:11:08][INFO] global_step=57696, episodic_reward_predictor_return=-4.380263805389404\n",
      "[2023-09-13 13:11:08][INFO] global_step=57696, episodic_env_return=-242.0\n",
      "[2023-09-13 13:11:12][INFO] global_step=57896, episodic_reward_predictor_return=-0.700921356678009\n",
      "[2023-09-13 13:11:12][INFO] global_step=57896, episodic_env_return=48.0\n",
      "[2023-09-13 13:11:12][INFO] global_step=57904, episodic_reward_predictor_return=-0.03476719558238983\n",
      "[2023-09-13 13:11:12][INFO] global_step=57904, episodic_env_return=45.0\n",
      "[2023-09-13 13:11:14][INFO] global_step=58008, episodic_reward_predictor_return=-6.290952205657959\n",
      "[2023-09-13 13:11:14][INFO] global_step=58008, episodic_env_return=-121.0\n",
      "[2023-09-13 13:11:15][INFO] global_step=58096, episodic_reward_predictor_return=-0.8914729952812195\n",
      "[2023-09-13 13:11:15][INFO] global_step=58096, episodic_env_return=-47.0\n",
      "[2023-09-13 13:11:17][INFO] global_step=58200, episodic_reward_predictor_return=-4.488387107849121\n",
      "[2023-09-13 13:11:17][INFO] global_step=58200, episodic_env_return=-380.0\n",
      "[2023-09-13 13:11:20][INFO] global_step=58384, episodic_reward_predictor_return=-0.7056062817573547\n",
      "[2023-09-13 13:11:20][INFO] global_step=58384, episodic_env_return=-56.0\n",
      "[2023-09-13 13:11:23][INFO] global_step=58528, episodic_reward_predictor_return=-0.7209170460700989\n",
      "[2023-09-13 13:11:23][INFO] global_step=58528, episodic_env_return=50.0\n",
      "[2023-09-13 13:11:23][INFO] global_step=58560, episodic_reward_predictor_return=-0.07869454473257065\n",
      "[2023-09-13 13:11:23][INFO] global_step=58560, episodic_env_return=19.0\n",
      "[2023-09-13 13:11:25][INFO] global_step=58688, episodic_reward_predictor_return=-3.5761215686798096\n",
      "[2023-09-13 13:11:25][INFO] global_step=58688, episodic_env_return=-380.0\n",
      "[2023-09-13 13:11:31][INFO] global_step=59008, episodic_reward_predictor_return=0.09837060421705246\n",
      "[2023-09-13 13:11:31][INFO] global_step=59008, episodic_env_return=23.0\n",
      "[2023-09-13 13:11:32][INFO] global_step=59064, episodic_reward_predictor_return=0.712026059627533\n",
      "[2023-09-13 13:11:32][INFO] global_step=59064, episodic_env_return=34.0\n",
      "[2023-09-13 13:11:35][INFO] global_step=59272, episodic_reward_predictor_return=-0.1035938411951065\n",
      "[2023-09-13 13:11:35][INFO] global_step=59272, episodic_env_return=-71.0\n",
      "[2023-09-13 13:11:37][INFO] Current Mean Episodic Return = -1.397691249847412\n",
      "[2023-09-13 13:11:37][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_59392`...\n",
      "[2023-09-13 13:11:37][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_59392`!\n",
      "[2023-09-13 13:11:40][INFO] SPS: 24\n",
      "[2023-09-13 13:11:45][INFO] global_step=59712, episodic_reward_predictor_return=0.4488682746887207\n",
      "[2023-09-13 13:11:45][INFO] global_step=59712, episodic_env_return=-127.0\n",
      "[2023-09-13 13:11:46][INFO] global_step=59768, episodic_reward_predictor_return=0.09501689672470093\n",
      "[2023-09-13 13:11:46][INFO] global_step=59768, episodic_env_return=34.0\n",
      "[2023-09-13 13:11:48][INFO] global_step=59872, episodic_reward_predictor_return=-4.64621639251709\n",
      "[2023-09-13 13:11:48][INFO] global_step=59872, episodic_env_return=-176.0\n",
      "[2023-09-13 13:11:51][INFO] global_step=60064, episodic_reward_predictor_return=-0.8974896669387817\n",
      "[2023-09-13 13:11:51][INFO] global_step=60064, episodic_env_return=-86.0\n",
      "[2023-09-13 13:11:52][INFO] global_step=60096, episodic_reward_predictor_return=-1.8751174211502075\n",
      "[2023-09-13 13:11:52][INFO] global_step=60096, episodic_env_return=-325.0\n",
      "[2023-09-13 13:11:58][INFO] global_step=60496, episodic_reward_predictor_return=-3.258676290512085\n",
      "[2023-09-13 13:11:58][INFO] global_step=60496, episodic_env_return=-128.0\n",
      "[2023-09-13 13:11:58][INFO] global_step=60504, episodic_reward_predictor_return=-0.3876890242099762\n",
      "[2023-09-13 13:11:58][INFO] global_step=60504, episodic_env_return=50.0\n",
      "[2023-09-13 13:12:05][INFO] global_step=60904, episodic_reward_predictor_return=0.92108154296875\n",
      "[2023-09-13 13:12:05][INFO] global_step=60904, episodic_env_return=-28.0\n",
      "[2023-09-13 13:12:05][INFO] global_step=60904, episodic_reward_predictor_return=-0.09186204522848129\n",
      "[2023-09-13 13:12:05][INFO] global_step=60904, episodic_env_return=45.0\n",
      "[2023-09-13 13:12:06][INFO] global_step=60960, episodic_reward_predictor_return=-1.9051164388656616\n",
      "[2023-09-13 13:12:06][INFO] global_step=60960, episodic_env_return=-315.0\n",
      "[2023-09-13 13:12:11][INFO] global_step=61256, episodic_reward_predictor_return=0.03807077929377556\n",
      "[2023-09-13 13:12:11][INFO] global_step=61256, episodic_env_return=-107.0\n",
      "[2023-09-13 13:12:11][INFO] global_step=61264, episodic_reward_predictor_return=-2.272226572036743\n",
      "[2023-09-13 13:12:11][INFO] global_step=61264, episodic_env_return=-116.0\n",
      "[2023-09-13 13:12:14][INFO] global_step=61408, episodic_reward_predictor_return=-3.2871792316436768\n",
      "[2023-09-13 13:12:14][INFO] global_step=61408, episodic_env_return=-360.0\n",
      "[2023-09-13 13:12:14][INFO] Current Mean Episodic Return = -1.3168103694915771\n",
      "[2023-09-13 13:12:14][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_61440`...\n",
      "[2023-09-13 13:12:15][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_61440`!\n",
      "[2023-09-13 13:12:17][INFO] SPS: 24\n",
      "[2023-09-13 13:12:18][INFO] global_step=61472, episodic_reward_predictor_return=0.026992831379175186\n",
      "[2023-09-13 13:12:18][INFO] global_step=61472, episodic_env_return=30.0\n",
      "[2023-09-13 13:12:21][INFO] global_step=61648, episodic_reward_predictor_return=0.26568159461021423\n",
      "[2023-09-13 13:12:21][INFO] global_step=61648, episodic_env_return=79.0\n",
      "[2023-09-13 13:12:21][INFO] global_step=61664, episodic_reward_predictor_return=-0.1365056037902832\n",
      "[2023-09-13 13:12:21][INFO] global_step=61664, episodic_env_return=-104.0\n",
      "[2023-09-13 13:12:24][INFO] global_step=61872, episodic_reward_predictor_return=0.5845049023628235\n",
      "[2023-09-13 13:12:24][INFO] global_step=61872, episodic_env_return=24.0\n",
      "[2023-09-13 13:12:25][INFO] global_step=61904, episodic_reward_predictor_return=0.4769343137741089\n",
      "[2023-09-13 13:12:25][INFO] global_step=61904, episodic_env_return=39.0\n",
      "[2023-09-13 13:12:28][INFO] global_step=62072, episodic_reward_predictor_return=0.30995506048202515\n",
      "[2023-09-13 13:12:28][INFO] global_step=62072, episodic_env_return=76.0\n",
      "[2023-09-13 13:12:28][INFO] global_step=62072, episodic_reward_predictor_return=-3.6618669033050537\n",
      "[2023-09-13 13:12:28][INFO] global_step=62072, episodic_env_return=-80.0\n",
      "[2023-09-13 13:12:29][INFO] global_step=62160, episodic_reward_predictor_return=-0.12080477178096771\n",
      "[2023-09-13 13:12:29][INFO] global_step=62160, episodic_env_return=90.0\n",
      "[2023-09-13 13:12:33][INFO] global_step=62408, episodic_reward_predictor_return=-3.1834075450897217\n",
      "[2023-09-13 13:12:33][INFO] global_step=62408, episodic_env_return=-115.0\n",
      "[2023-09-13 13:12:35][INFO] global_step=62520, episodic_reward_predictor_return=0.1228165552020073\n",
      "[2023-09-13 13:12:35][INFO] global_step=62520, episodic_env_return=87.0\n",
      "[2023-09-13 13:12:36][INFO] global_step=62608, episodic_reward_predictor_return=-1.21140456199646\n",
      "[2023-09-13 13:12:36][INFO] global_step=62608, episodic_env_return=-82.0\n",
      "[2023-09-13 13:12:37][INFO] global_step=62648, episodic_reward_predictor_return=-2.452282667160034\n",
      "[2023-09-13 13:12:37][INFO] global_step=62648, episodic_env_return=-52.0\n",
      "[2023-09-13 13:12:40][INFO] global_step=62808, episodic_reward_predictor_return=0.6801323294639587\n",
      "[2023-09-13 13:12:40][INFO] global_step=62808, episodic_env_return=76.0\n",
      "[2023-09-13 13:12:42][INFO] global_step=62904, episodic_reward_predictor_return=-3.708515167236328\n",
      "[2023-09-13 13:12:42][INFO] global_step=62904, episodic_env_return=-375.0\n",
      "[2023-09-13 13:12:45][INFO] global_step=63080, episodic_reward_predictor_return=-1.4758021831512451\n",
      "[2023-09-13 13:12:45][INFO] global_step=63080, episodic_env_return=-29.0\n",
      "[2023-09-13 13:12:50][INFO] global_step=63392, episodic_reward_predictor_return=-2.9417521953582764\n",
      "[2023-09-13 13:12:50][INFO] global_step=63392, episodic_env_return=-99.0\n",
      "[2023-09-13 13:12:52][INFO] Current Mean Episodic Return = -1.0265827178955078\n",
      "[2023-09-13 13:12:52][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_63488`...\n",
      "[2023-09-13 13:12:52][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_63488`!\n",
      "[2023-09-13 13:12:54][INFO] SPS: 24\n",
      "[2023-09-13 13:12:55][INFO] global_step=63520, episodic_reward_predictor_return=0.6372089385986328\n",
      "[2023-09-13 13:12:55][INFO] global_step=63520, episodic_env_return=19.0\n",
      "[2023-09-13 13:12:55][INFO] global_step=63528, episodic_reward_predictor_return=-0.42572805285453796\n",
      "[2023-09-13 13:12:55][INFO] global_step=63528, episodic_env_return=40.0\n",
      "[2023-09-13 13:12:56][INFO] global_step=63608, episodic_reward_predictor_return=-4.393627643585205\n",
      "[2023-09-13 13:12:56][INFO] global_step=63608, episodic_env_return=-167.0\n",
      "[2023-09-13 13:12:58][INFO] global_step=63696, episodic_reward_predictor_return=-0.30063745379447937\n",
      "[2023-09-13 13:12:58][INFO] global_step=63696, episodic_env_return=79.0\n",
      "[2023-09-13 13:12:58][INFO] global_step=63712, episodic_reward_predictor_return=0.6562492251396179\n",
      "[2023-09-13 13:12:58][INFO] global_step=63712, episodic_env_return=-12.0\n",
      "[2023-09-13 13:13:02][INFO] global_step=63976, episodic_reward_predictor_return=-2.6271042823791504\n",
      "[2023-09-13 13:13:02][INFO] global_step=63976, episodic_env_return=-105.0\n",
      "[2023-09-13 13:13:03][INFO] global_step=64048, episodic_reward_predictor_return=0.9809922575950623\n",
      "[2023-09-13 13:13:03][INFO] global_step=64048, episodic_env_return=-315.0\n",
      "[2023-09-13 13:13:08][INFO] global_step=64304, episodic_reward_predictor_return=-1.3606855869293213\n",
      "[2023-09-13 13:13:08][INFO] global_step=64304, episodic_env_return=-48.0\n",
      "[2023-09-13 13:13:11][INFO] global_step=64520, episodic_reward_predictor_return=0.04349232465028763\n",
      "[2023-09-13 13:13:11][INFO] global_step=64520, episodic_env_return=-13.0\n",
      "[2023-09-13 13:13:18][INFO] global_step=64920, episodic_reward_predictor_return=-3.5744729042053223\n",
      "[2023-09-13 13:13:18][INFO] global_step=64920, episodic_env_return=-335.0\n",
      "[2023-09-13 13:13:24][INFO] global_step=65296, episodic_reward_predictor_return=0.3429742455482483\n",
      "[2023-09-13 13:13:24][INFO] global_step=65296, episodic_env_return=-23.0\n",
      "[2023-09-13 13:13:28][INFO] Current Mean Episodic Return = -0.9110307693481445\n",
      "[2023-09-13 13:13:28][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_65536`...\n",
      "[2023-09-13 13:13:28][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_65536`!\n",
      "[2023-09-13 13:13:31][INFO] SPS: 25\n",
      "[2023-09-13 13:13:32][INFO] global_step=65608, episodic_reward_predictor_return=-2.7759761810302734\n",
      "[2023-09-13 13:13:32][INFO] global_step=65608, episodic_env_return=-138.0\n",
      "[2023-09-13 13:13:36][INFO] global_step=65880, episodic_reward_predictor_return=0.43343204259872437\n",
      "[2023-09-13 13:13:36][INFO] global_step=65880, episodic_env_return=23.0\n",
      "[2023-09-13 13:13:37][INFO] global_step=65928, episodic_reward_predictor_return=-0.18236948549747467\n",
      "[2023-09-13 13:13:37][INFO] global_step=65928, episodic_env_return=-320.0\n",
      "[2023-09-13 13:13:40][INFO] global_step=66096, episodic_reward_predictor_return=-0.4970967471599579\n",
      "[2023-09-13 13:13:40][INFO] global_step=66096, episodic_env_return=-315.0\n",
      "[2023-09-13 13:13:40][INFO] global_step=66112, episodic_reward_predictor_return=-5.851631164550781\n",
      "[2023-09-13 13:13:40][INFO] global_step=66112, episodic_env_return=-380.0\n",
      "[2023-09-13 13:13:45][INFO] global_step=66440, episodic_reward_predictor_return=0.13029606640338898\n",
      "[2023-09-13 13:13:45][INFO] global_step=66440, episodic_env_return=31.0\n",
      "[2023-09-13 13:13:46][INFO] global_step=66448, episodic_reward_predictor_return=-6.463948726654053\n",
      "[2023-09-13 13:13:46][INFO] global_step=66448, episodic_env_return=-365.0\n",
      "[2023-09-13 13:13:48][INFO] global_step=66584, episodic_reward_predictor_return=0.030342381447553635\n",
      "[2023-09-13 13:13:48][INFO] global_step=66584, episodic_env_return=83.0\n",
      "[2023-09-13 13:13:53][INFO] global_step=66920, episodic_reward_predictor_return=-6.1617631912231445\n",
      "[2023-09-13 13:13:53][INFO] global_step=66920, episodic_env_return=-395.0\n",
      "[2023-09-13 13:13:56][INFO] global_step=67112, episodic_reward_predictor_return=-0.06373565644025803\n",
      "[2023-09-13 13:13:56][INFO] global_step=67112, episodic_env_return=35.0\n",
      "[2023-09-13 13:13:59][INFO] global_step=67288, episodic_reward_predictor_return=0.392881840467453\n",
      "[2023-09-13 13:13:59][INFO] global_step=67288, episodic_env_return=-4.0\n",
      "[2023-09-13 13:13:59][INFO] global_step=67320, episodic_reward_predictor_return=-4.884586334228516\n",
      "[2023-09-13 13:13:59][INFO] global_step=67320, episodic_env_return=-380.0\n",
      "[2023-09-13 13:14:00][INFO] global_step=67352, episodic_reward_predictor_return=-2.0360963344573975\n",
      "[2023-09-13 13:14:00][INFO] global_step=67352, episodic_env_return=-142.0\n",
      "[2023-09-13 13:14:00][INFO] global_step=67368, episodic_reward_predictor_return=-0.11359380185604095\n",
      "[2023-09-13 13:14:00][INFO] global_step=67368, episodic_env_return=30.0\n",
      "[2023-09-13 13:14:02][INFO] global_step=67512, episodic_reward_predictor_return=0.9255310297012329\n",
      "[2023-09-13 13:14:02][INFO] global_step=67512, episodic_env_return=-76.0\n",
      "[2023-09-13 13:14:04][INFO] Current Mean Episodic Return = -1.8078876733779907\n",
      "[2023-09-13 13:14:04][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_67584`...\n",
      "[2023-09-13 13:14:04][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_67584`!\n",
      "[2023-09-13 13:14:06][INFO] SPS: 25\n",
      "[2023-09-13 13:14:09][INFO] global_step=67792, episodic_reward_predictor_return=-0.31189653277397156\n",
      "[2023-09-13 13:14:09][INFO] global_step=67792, episodic_env_return=46.0\n",
      "[2023-09-13 13:14:14][INFO] global_step=68080, episodic_reward_predictor_return=-2.315645217895508\n",
      "[2023-09-13 13:14:14][INFO] global_step=68080, episodic_env_return=-55.0\n",
      "[2023-09-13 13:14:18][INFO] global_step=68328, episodic_reward_predictor_return=-10.391868591308594\n",
      "[2023-09-13 13:14:18][INFO] global_step=68328, episodic_env_return=-355.0\n",
      "[2023-09-13 13:14:19][INFO] global_step=68360, episodic_reward_predictor_return=-0.3300492465496063\n",
      "[2023-09-13 13:14:19][INFO] global_step=68360, episodic_env_return=-5.0\n",
      "[2023-09-13 13:14:19][INFO] global_step=68384, episodic_reward_predictor_return=-0.1408609300851822\n",
      "[2023-09-13 13:14:19][INFO] global_step=68384, episodic_env_return=-31.0\n",
      "[2023-09-13 13:14:19][INFO] global_step=68384, episodic_reward_predictor_return=-0.5260035991668701\n",
      "[2023-09-13 13:14:19][INFO] global_step=68384, episodic_env_return=17.0\n",
      "[2023-09-13 13:14:22][INFO] global_step=68512, episodic_reward_predictor_return=-2.6396939754486084\n",
      "[2023-09-13 13:14:22][INFO] global_step=68512, episodic_env_return=-355.0\n",
      "[2023-09-13 13:14:29][INFO] global_step=68968, episodic_reward_predictor_return=0.6008818745613098\n",
      "[2023-09-13 13:14:29][INFO] global_step=68968, episodic_env_return=28.0\n",
      "[2023-09-13 13:14:30][INFO] global_step=69008, episodic_reward_predictor_return=0.20527561008930206\n",
      "[2023-09-13 13:14:30][INFO] global_step=69008, episodic_env_return=15.0\n",
      "[2023-09-13 13:14:33][INFO] global_step=69176, episodic_reward_predictor_return=1.1086739301681519\n",
      "[2023-09-13 13:14:33][INFO] global_step=69176, episodic_env_return=-5.0\n",
      "[2023-09-13 13:14:40][INFO] Current Mean Episodic Return = -1.4741185903549194\n",
      "[2023-09-13 13:14:40][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_69632`...\n",
      "[2023-09-13 13:14:40][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_69632`!\n",
      "[2023-09-13 13:14:43][INFO] SPS: 26\n",
      "[2023-09-13 13:14:44][INFO] global_step=69688, episodic_reward_predictor_return=0.2540935277938843\n",
      "[2023-09-13 13:14:44][INFO] global_step=69688, episodic_env_return=-315.0\n",
      "[2023-09-13 13:14:44][INFO] global_step=69720, episodic_reward_predictor_return=-2.3920741081237793\n",
      "[2023-09-13 13:14:44][INFO] global_step=69720, episodic_env_return=-340.0\n",
      "[2023-09-13 13:14:47][INFO] global_step=69872, episodic_reward_predictor_return=0.501493513584137\n",
      "[2023-09-13 13:14:47][INFO] global_step=69872, episodic_env_return=-7.0\n",
      "[2023-09-13 13:14:55][INFO] global_step=70368, episodic_reward_predictor_return=0.40766003727912903\n",
      "[2023-09-13 13:14:55][INFO] global_step=70368, episodic_env_return=-147.0\n",
      "[2023-09-13 13:14:57][INFO] global_step=70480, episodic_reward_predictor_return=2.7676351070404053\n",
      "[2023-09-13 13:14:57][INFO] global_step=70480, episodic_env_return=-305.0\n",
      "[2023-09-13 13:15:04][INFO] global_step=70912, episodic_reward_predictor_return=-2.511864185333252\n",
      "[2023-09-13 13:15:04][INFO] global_step=70912, episodic_env_return=-365.0\n",
      "[2023-09-13 13:15:05][INFO] global_step=70944, episodic_reward_predictor_return=1.8823846578598022\n",
      "[2023-09-13 13:15:05][INFO] global_step=70944, episodic_env_return=-56.0\n",
      "[2023-09-13 13:15:06][INFO] global_step=71040, episodic_reward_predictor_return=-0.9414454102516174\n",
      "[2023-09-13 13:15:06][INFO] global_step=71040, episodic_env_return=26.0\n",
      "[2023-09-13 13:15:12][INFO] global_step=71344, episodic_reward_predictor_return=1.50290048122406\n",
      "[2023-09-13 13:15:12][INFO] global_step=71344, episodic_env_return=-175.0\n",
      "[2023-09-13 13:15:12][INFO] global_step=71368, episodic_reward_predictor_return=1.0821099281311035\n",
      "[2023-09-13 13:15:12][INFO] global_step=71368, episodic_env_return=-305.0\n",
      "[2023-09-13 13:15:12][INFO] global_step=71368, episodic_reward_predictor_return=0.5734620094299316\n",
      "[2023-09-13 13:15:12][INFO] global_step=71368, episodic_env_return=-86.0\n",
      "[2023-09-13 13:15:17][INFO] Current Mean Episodic Return = 0.2842141389846802\n",
      "[2023-09-13 13:15:17][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_71680`...\n",
      "[2023-09-13 13:15:17][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_71680`!\n",
      "[2023-09-13 13:15:20][INFO] SPS: 26\n",
      "[2023-09-13 13:16:13][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:16:13][INFO] reward_predictor_training_loss=1.2144291400909424\n",
      "[2023-09-13 13:16:26][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:16:27][INFO] reward_predictor_training_loss=0.6940354108810425\n",
      "[2023-09-13 13:16:45][INFO] user_preference = 0\n",
      "[2023-09-13 13:16:46][INFO] reward_predictor_training_loss=0.44853514432907104\n",
      "[2023-09-13 13:17:00][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:17:01][INFO] reward_predictor_training_loss=0.7130488157272339\n",
      "[2023-09-13 13:17:51][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:17:51][INFO] reward_predictor_training_loss=1.1517829895019531\n",
      "[2023-09-13 13:18:05][INFO] user_preference = 0\n",
      "[2023-09-13 13:18:05][INFO] reward_predictor_training_loss=1.6670013666152954\n",
      "[2023-09-13 13:18:16][INFO] user_preference = 0\n",
      "[2023-09-13 13:18:16][INFO] reward_predictor_training_loss=0.022475536912679672\n",
      "[2023-09-13 13:18:33][INFO] user_preference = 0\n",
      "[2023-09-13 13:18:33][INFO] reward_predictor_training_loss=0.3138815760612488\n",
      "[2023-09-13 13:18:56][INFO] user_preference = 0\n",
      "[2023-09-13 13:18:56][INFO] reward_predictor_training_loss=0.1268296092748642\n",
      "[2023-09-13 13:19:35][INFO] user_preference = 0\n",
      "[2023-09-13 13:19:35][INFO] reward_predictor_training_loss=0.40345579385757446\n",
      "[2023-09-13 13:19:44][INFO] user_preference = 1\n",
      "[2023-09-13 13:19:44][INFO] reward_predictor_training_loss=0.3788677155971527\n",
      "[2023-09-13 13:19:57][INFO] user_preference = 0\n",
      "[2023-09-13 13:19:57][INFO] reward_predictor_training_loss=0.02200089767575264\n",
      "[2023-09-13 13:20:08][INFO] user_preference = 0\n",
      "[2023-09-13 13:20:08][INFO] reward_predictor_training_loss=0.9438860416412354\n",
      "[2023-09-13 13:20:24][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:20:25][INFO] reward_predictor_training_loss=1.0156896114349365\n",
      "[2023-09-13 13:20:38][INFO] user_preference = 0\n",
      "[2023-09-13 13:20:38][INFO] reward_predictor_training_loss=0.028937283903360367\n",
      "[2023-09-13 13:20:49][INFO] user_preference = 0\n",
      "[2023-09-13 13:20:49][INFO] reward_predictor_training_loss=0.6007570028305054\n",
      "[2023-09-13 13:20:50][INFO] global_step=71712, episodic_reward_predictor_return=0.8032132387161255\n",
      "[2023-09-13 13:20:50][INFO] global_step=71712, episodic_env_return=55.0\n",
      "[2023-09-13 13:20:50][INFO] global_step=71744, episodic_reward_predictor_return=1.9249184131622314\n",
      "[2023-09-13 13:20:50][INFO] global_step=71744, episodic_env_return=-71.0\n",
      "[2023-09-13 13:20:52][INFO] global_step=71880, episodic_reward_predictor_return=-0.19690480828285217\n",
      "[2023-09-13 13:20:52][INFO] global_step=71880, episodic_env_return=-14.0\n",
      "[2023-09-13 13:20:56][INFO] global_step=72120, episodic_reward_predictor_return=-2.4709956645965576\n",
      "[2023-09-13 13:20:56][INFO] global_step=72120, episodic_env_return=-325.0\n",
      "[2023-09-13 13:20:58][INFO] global_step=72224, episodic_reward_predictor_return=-2.2578868865966797\n",
      "[2023-09-13 13:20:58][INFO] global_step=72224, episodic_env_return=-31.0\n",
      "[2023-09-13 13:21:04][INFO] global_step=72576, episodic_reward_predictor_return=-0.6117032170295715\n",
      "[2023-09-13 13:21:04][INFO] global_step=72576, episodic_env_return=57.0\n",
      "[2023-09-13 13:21:10][INFO] global_step=72936, episodic_reward_predictor_return=-1.7989158630371094\n",
      "[2023-09-13 13:21:10][INFO] global_step=72936, episodic_env_return=-153.0\n",
      "[2023-09-13 13:21:17][INFO] global_step=73312, episodic_reward_predictor_return=-1.5315346717834473\n",
      "[2023-09-13 13:21:17][INFO] global_step=73312, episodic_env_return=-300.0\n",
      "[2023-09-13 13:21:17][INFO] global_step=73328, episodic_reward_predictor_return=-1.1877260208129883\n",
      "[2023-09-13 13:21:17][INFO] global_step=73328, episodic_env_return=-106.0\n",
      "[2023-09-13 13:21:21][INFO] global_step=73544, episodic_reward_predictor_return=-0.8342121839523315\n",
      "[2023-09-13 13:21:21][INFO] global_step=73544, episodic_env_return=-20.0\n",
      "[2023-09-13 13:21:23][INFO] global_step=73680, episodic_reward_predictor_return=-0.6465165019035339\n",
      "[2023-09-13 13:21:23][INFO] global_step=73680, episodic_env_return=57.0\n",
      "[2023-09-13 13:21:24][INFO] Current Mean Episodic Return = -0.8007513284683228\n",
      "[2023-09-13 13:21:24][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_73728`...\n",
      "[2023-09-13 13:21:24][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_73728`!\n",
      "[2023-09-13 13:21:26][INFO] SPS: 24\n",
      "[2023-09-13 13:21:27][INFO] global_step=73736, episodic_reward_predictor_return=-2.162039041519165\n",
      "[2023-09-13 13:21:27][INFO] global_step=73736, episodic_env_return=-101.0\n",
      "[2023-09-13 13:21:27][INFO] global_step=73768, episodic_reward_predictor_return=-2.1306097507476807\n",
      "[2023-09-13 13:21:27][INFO] global_step=73768, episodic_env_return=-300.0\n",
      "[2023-09-13 13:21:30][INFO] global_step=73928, episodic_reward_predictor_return=-0.6538704037666321\n",
      "[2023-09-13 13:21:30][INFO] global_step=73928, episodic_env_return=38.0\n",
      "[2023-09-13 13:21:33][INFO] global_step=74144, episodic_reward_predictor_return=-2.3671979904174805\n",
      "[2023-09-13 13:21:33][INFO] global_step=74144, episodic_env_return=-300.0\n",
      "[2023-09-13 13:21:36][INFO] global_step=74280, episodic_reward_predictor_return=-11.65455150604248\n",
      "[2023-09-13 13:21:36][INFO] global_step=74280, episodic_env_return=-340.0\n",
      "[2023-09-13 13:21:40][INFO] global_step=74520, episodic_reward_predictor_return=-1.73886239528656\n",
      "[2023-09-13 13:21:40][INFO] global_step=74520, episodic_env_return=-14.0\n",
      "[2023-09-13 13:21:41][INFO] global_step=74576, episodic_reward_predictor_return=-0.8027064800262451\n",
      "[2023-09-13 13:21:41][INFO] global_step=74576, episodic_env_return=-4.0\n",
      "[2023-09-13 13:21:44][INFO] global_step=74752, episodic_reward_predictor_return=-1.0063837766647339\n",
      "[2023-09-13 13:21:44][INFO] global_step=74752, episodic_env_return=42.0\n",
      "[2023-09-13 13:21:46][INFO] global_step=74872, episodic_reward_predictor_return=-1.1124122142791748\n",
      "[2023-09-13 13:21:46][INFO] global_step=74872, episodic_env_return=-17.0\n",
      "[2023-09-13 13:21:53][INFO] global_step=75336, episodic_reward_predictor_return=-5.0658955574035645\n",
      "[2023-09-13 13:21:53][INFO] global_step=75336, episodic_env_return=-350.0\n",
      "[2023-09-13 13:21:58][INFO] global_step=75576, episodic_reward_predictor_return=-0.9212607741355896\n",
      "[2023-09-13 13:21:58][INFO] global_step=75576, episodic_env_return=-7.0\n",
      "[2023-09-13 13:22:00][INFO] global_step=75712, episodic_reward_predictor_return=-1.7593480348587036\n",
      "[2023-09-13 13:22:00][INFO] global_step=75712, episodic_env_return=-305.0\n",
      "[2023-09-13 13:22:01][INFO] Current Mean Episodic Return = -2.6145946979522705\n",
      "[2023-09-13 13:22:01][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_75776`...\n",
      "[2023-09-13 13:22:01][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_75776`!\n",
      "[2023-09-13 13:22:04][INFO] SPS: 24\n",
      "[2023-09-13 13:22:05][INFO] global_step=75856, episodic_reward_predictor_return=-2.452244997024536\n",
      "[2023-09-13 13:22:05][INFO] global_step=75856, episodic_env_return=-84.0\n",
      "[2023-09-13 13:22:10][INFO] global_step=76168, episodic_reward_predictor_return=-8.564727783203125\n",
      "[2023-09-13 13:22:10][INFO] global_step=76168, episodic_env_return=-390.0\n",
      "[2023-09-13 13:22:11][INFO] global_step=76232, episodic_reward_predictor_return=-2.7091875076293945\n",
      "[2023-09-13 13:22:11][INFO] global_step=76232, episodic_env_return=-165.0\n",
      "[2023-09-13 13:22:13][INFO] global_step=76328, episodic_reward_predictor_return=-4.849697113037109\n",
      "[2023-09-13 13:22:13][INFO] global_step=76328, episodic_env_return=-165.0\n",
      "[2023-09-13 13:22:15][INFO] global_step=76488, episodic_reward_predictor_return=-0.3642781972885132\n",
      "[2023-09-13 13:22:15][INFO] global_step=76488, episodic_env_return=61.0\n",
      "[2023-09-13 13:22:15][INFO] global_step=76488, episodic_reward_predictor_return=-0.5953469276428223\n",
      "[2023-09-13 13:22:15][INFO] global_step=76488, episodic_env_return=69.0\n",
      "[2023-09-13 13:22:22][INFO] global_step=76856, episodic_reward_predictor_return=-2.5699119567871094\n",
      "[2023-09-13 13:22:22][INFO] global_step=76856, episodic_env_return=-87.0\n",
      "[2023-09-13 13:22:22][INFO] global_step=76880, episodic_reward_predictor_return=-1.7001941204071045\n",
      "[2023-09-13 13:22:22][INFO] global_step=76880, episodic_env_return=17.0\n",
      "[2023-09-13 13:22:23][INFO] global_step=76928, episodic_reward_predictor_return=0.040350280702114105\n",
      "[2023-09-13 13:22:23][INFO] global_step=76928, episodic_env_return=95.0\n",
      "[2023-09-13 13:22:23][INFO] global_step=76936, episodic_reward_predictor_return=-0.2147192806005478\n",
      "[2023-09-13 13:22:23][INFO] global_step=76936, episodic_env_return=45.0\n",
      "[2023-09-13 13:22:25][INFO] global_step=77064, episodic_reward_predictor_return=-1.3048657178878784\n",
      "[2023-09-13 13:22:25][INFO] global_step=77064, episodic_env_return=-85.0\n",
      "[2023-09-13 13:22:27][INFO] global_step=77152, episodic_reward_predictor_return=-4.190179347991943\n",
      "[2023-09-13 13:22:27][INFO] global_step=77152, episodic_env_return=-350.0\n",
      "[2023-09-13 13:22:32][INFO] global_step=77448, episodic_reward_predictor_return=-0.48129189014434814\n",
      "[2023-09-13 13:22:32][INFO] global_step=77448, episodic_env_return=53.0\n",
      "[2023-09-13 13:22:33][INFO] global_step=77536, episodic_reward_predictor_return=-0.4198899269104004\n",
      "[2023-09-13 13:22:33][INFO] global_step=77536, episodic_env_return=53.0\n",
      "[2023-09-13 13:22:34][INFO] global_step=77552, episodic_reward_predictor_return=-0.12273088842630386\n",
      "[2023-09-13 13:22:34][INFO] global_step=77552, episodic_env_return=88.0\n",
      "[2023-09-13 13:22:37][INFO] global_step=77736, episodic_reward_predictor_return=-3.0821704864501953\n",
      "[2023-09-13 13:22:37][INFO] global_step=77736, episodic_env_return=-300.0\n",
      "[2023-09-13 13:22:38][INFO] Current Mean Episodic Return = -2.098817825317383\n",
      "[2023-09-13 13:22:38][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_77824`...\n",
      "[2023-09-13 13:22:38][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_77824`!\n",
      "[2023-09-13 13:22:41][INFO] SPS: 24\n",
      "[2023-09-13 13:22:43][INFO] global_step=77936, episodic_reward_predictor_return=-0.8889153599739075\n",
      "[2023-09-13 13:22:43][INFO] global_step=77936, episodic_env_return=-24.0\n",
      "[2023-09-13 13:22:48][INFO] global_step=78256, episodic_reward_predictor_return=-5.260869026184082\n",
      "[2023-09-13 13:22:48][INFO] global_step=78256, episodic_env_return=-350.0\n",
      "[2023-09-13 13:22:48][INFO] global_step=78288, episodic_reward_predictor_return=-1.8338642120361328\n",
      "[2023-09-13 13:22:48][INFO] global_step=78288, episodic_env_return=-69.0\n",
      "[2023-09-13 13:22:51][INFO] global_step=78464, episodic_reward_predictor_return=-1.3263996839523315\n",
      "[2023-09-13 13:22:51][INFO] global_step=78464, episodic_env_return=-110.0\n",
      "[2023-09-13 13:22:53][INFO] global_step=78584, episodic_reward_predictor_return=-2.1066763401031494\n",
      "[2023-09-13 13:22:53][INFO] global_step=78584, episodic_env_return=-176.0\n",
      "[2023-09-13 13:22:54][INFO] global_step=78616, episodic_reward_predictor_return=-0.5549482107162476\n",
      "[2023-09-13 13:22:54][INFO] global_step=78616, episodic_env_return=60.0\n",
      "[2023-09-13 13:22:56][INFO] global_step=78720, episodic_reward_predictor_return=-0.31688192486763\n",
      "[2023-09-13 13:22:56][INFO] global_step=78720, episodic_env_return=88.0\n",
      "[2023-09-13 13:22:58][INFO] global_step=78880, episodic_reward_predictor_return=-1.1146730184555054\n",
      "[2023-09-13 13:22:58][INFO] global_step=78880, episodic_env_return=39.0\n",
      "[2023-09-13 13:23:14][INFO] Current Mean Episodic Return = -1.6754035949707031\n",
      "[2023-09-13 13:23:14][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_79872`...\n",
      "[2023-09-13 13:23:14][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_79872`!\n",
      "[2023-09-13 13:23:17][INFO] SPS: 25\n",
      "[2023-09-13 13:23:18][INFO] global_step=79936, episodic_reward_predictor_return=-2.6882095336914062\n",
      "[2023-09-13 13:23:18][INFO] global_step=79936, episodic_env_return=-305.0\n",
      "[2023-09-13 13:23:18][INFO] global_step=79952, episodic_reward_predictor_return=-11.4274263381958\n",
      "[2023-09-13 13:23:18][INFO] global_step=79952, episodic_env_return=-355.0\n",
      "[2023-09-13 13:23:20][INFO] global_step=80080, episodic_reward_predictor_return=-7.108506679534912\n",
      "[2023-09-13 13:23:20][INFO] global_step=80080, episodic_env_return=-272.0\n",
      "[2023-09-13 13:23:20][INFO] global_step=80112, episodic_reward_predictor_return=-1.3628932237625122\n",
      "[2023-09-13 13:23:20][INFO] global_step=80112, episodic_env_return=-73.0\n",
      "[2023-09-13 13:23:23][INFO] global_step=80272, episodic_reward_predictor_return=-1.5851114988327026\n",
      "[2023-09-13 13:23:23][INFO] global_step=80272, episodic_env_return=-78.0\n",
      "[2023-09-13 13:23:24][INFO] global_step=80336, episodic_reward_predictor_return=-4.62734317779541\n",
      "[2023-09-13 13:23:24][INFO] global_step=80336, episodic_env_return=-335.0\n",
      "[2023-09-13 13:23:28][INFO] global_step=80600, episodic_reward_predictor_return=-2.936189651489258\n",
      "[2023-09-13 13:23:28][INFO] global_step=80600, episodic_env_return=-197.0\n",
      "[2023-09-13 13:23:34][INFO] global_step=80952, episodic_reward_predictor_return=-3.409543752670288\n",
      "[2023-09-13 13:23:34][INFO] global_step=80952, episodic_env_return=-61.0\n",
      "[2023-09-13 13:23:34][INFO] global_step=80984, episodic_reward_predictor_return=-1.504736065864563\n",
      "[2023-09-13 13:23:34][INFO] global_step=80984, episodic_env_return=-300.0\n",
      "[2023-09-13 13:23:38][INFO] global_step=81216, episodic_reward_predictor_return=-1.1637276411056519\n",
      "[2023-09-13 13:23:38][INFO] global_step=81216, episodic_env_return=-17.0\n",
      "[2023-09-13 13:23:42][INFO] global_step=81440, episodic_reward_predictor_return=-3.0807647705078125\n",
      "[2023-09-13 13:23:42][INFO] global_step=81440, episodic_env_return=-100.0\n",
      "[2023-09-13 13:23:44][INFO] global_step=81616, episodic_reward_predictor_return=-0.7399543523788452\n",
      "[2023-09-13 13:23:44][INFO] global_step=81616, episodic_env_return=-87.0\n",
      "[2023-09-13 13:23:49][INFO] Current Mean Episodic Return = -3.469534158706665\n",
      "[2023-09-13 13:23:49][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_81920`...\n",
      "[2023-09-13 13:23:49][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_81920`!\n",
      "[2023-09-13 13:23:52][INFO] SPS: 25\n",
      "[2023-09-13 13:23:53][INFO] global_step=81984, episodic_reward_predictor_return=-2.592740058898926\n",
      "[2023-09-13 13:23:53][INFO] global_step=81984, episodic_env_return=-137.0\n",
      "[2023-09-13 13:23:59][INFO] global_step=82392, episodic_reward_predictor_return=-1.0281955003738403\n",
      "[2023-09-13 13:23:59][INFO] global_step=82392, episodic_env_return=40.0\n",
      "[2023-09-13 13:24:01][INFO] global_step=82512, episodic_reward_predictor_return=-0.33264681696891785\n",
      "[2023-09-13 13:24:01][INFO] global_step=82512, episodic_env_return=-90.0\n",
      "[2023-09-13 13:24:04][INFO] global_step=82680, episodic_reward_predictor_return=-2.625568389892578\n",
      "[2023-09-13 13:24:04][INFO] global_step=82680, episodic_env_return=-159.0\n",
      "[2023-09-13 13:24:05][INFO] global_step=82736, episodic_reward_predictor_return=-0.7000535130500793\n",
      "[2023-09-13 13:24:05][INFO] global_step=82736, episodic_env_return=-300.0\n",
      "[2023-09-13 13:24:07][INFO] global_step=82872, episodic_reward_predictor_return=0.0253811776638031\n",
      "[2023-09-13 13:24:07][INFO] global_step=82872, episodic_env_return=56.0\n",
      "[2023-09-13 13:24:09][INFO] global_step=83024, episodic_reward_predictor_return=-0.44205203652381897\n",
      "[2023-09-13 13:24:09][INFO] global_step=83024, episodic_env_return=58.0\n",
      "[2023-09-13 13:24:14][INFO] global_step=83312, episodic_reward_predictor_return=-6.882784366607666\n",
      "[2023-09-13 13:24:14][INFO] global_step=83312, episodic_env_return=-216.0\n",
      "[2023-09-13 13:24:15][INFO] global_step=83352, episodic_reward_predictor_return=-3.8469526767730713\n",
      "[2023-09-13 13:24:15][INFO] global_step=83352, episodic_env_return=-310.0\n",
      "[2023-09-13 13:24:23][INFO] global_step=83840, episodic_reward_predictor_return=-4.83365535736084\n",
      "[2023-09-13 13:24:23][INFO] global_step=83840, episodic_env_return=-340.0\n",
      "[2023-09-13 13:24:25][INFO] Current Mean Episodic Return = -2.3259265422821045\n",
      "[2023-09-13 13:24:25][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_83968`...\n",
      "[2023-09-13 13:24:25][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_83968`!\n",
      "[2023-09-13 13:24:27][INFO] SPS: 25\n",
      "[2023-09-13 13:24:27][INFO] global_step=83992, episodic_reward_predictor_return=-2.595637321472168\n",
      "[2023-09-13 13:24:27][INFO] global_step=83992, episodic_env_return=-119.0\n",
      "[2023-09-13 13:24:28][INFO] global_step=84016, episodic_reward_predictor_return=-4.2226667404174805\n",
      "[2023-09-13 13:24:28][INFO] global_step=84016, episodic_env_return=-345.0\n",
      "[2023-09-13 13:24:31][INFO] global_step=84224, episodic_reward_predictor_return=-0.8177753686904907\n",
      "[2023-09-13 13:24:31][INFO] global_step=84224, episodic_env_return=48.0\n",
      "[2023-09-13 13:24:34][INFO] global_step=84400, episodic_reward_predictor_return=-0.8676720857620239\n",
      "[2023-09-13 13:24:34][INFO] global_step=84400, episodic_env_return=45.0\n",
      "[2023-09-13 13:24:38][INFO] global_step=84672, episodic_reward_predictor_return=-2.173328161239624\n",
      "[2023-09-13 13:24:38][INFO] global_step=84672, episodic_env_return=-84.0\n",
      "[2023-09-13 13:24:38][INFO] global_step=84672, episodic_reward_predictor_return=-0.8175085186958313\n",
      "[2023-09-13 13:24:38][INFO] global_step=84672, episodic_env_return=45.0\n",
      "[2023-09-13 13:24:40][INFO] global_step=84768, episodic_reward_predictor_return=-0.6771608591079712\n",
      "[2023-09-13 13:24:40][INFO] global_step=84768, episodic_env_return=-153.0\n",
      "[2023-09-13 13:24:42][INFO] global_step=84920, episodic_reward_predictor_return=-1.9486687183380127\n",
      "[2023-09-13 13:24:42][INFO] global_step=84920, episodic_env_return=-100.0\n",
      "[2023-09-13 13:24:45][INFO] global_step=85128, episodic_reward_predictor_return=-0.7873842120170593\n",
      "[2023-09-13 13:24:45][INFO] global_step=85128, episodic_env_return=56.0\n",
      "[2023-09-13 13:24:48][INFO] global_step=85272, episodic_reward_predictor_return=-0.4899936318397522\n",
      "[2023-09-13 13:24:48][INFO] global_step=85272, episodic_env_return=-300.0\n",
      "[2023-09-13 13:24:50][INFO] global_step=85424, episodic_reward_predictor_return=-5.708329677581787\n",
      "[2023-09-13 13:24:50][INFO] global_step=85424, episodic_env_return=-365.0\n",
      "[2023-09-13 13:24:53][INFO] global_step=85608, episodic_reward_predictor_return=-0.8337539434432983\n",
      "[2023-09-13 13:24:53][INFO] global_step=85608, episodic_env_return=-55.0\n",
      "[2023-09-13 13:24:54][INFO] global_step=85664, episodic_reward_predictor_return=-1.0145729780197144\n",
      "[2023-09-13 13:24:54][INFO] global_step=85664, episodic_env_return=-110.0\n",
      "[2023-09-13 13:24:57][INFO] global_step=85824, episodic_reward_predictor_return=-0.1845654547214508\n",
      "[2023-09-13 13:24:57][INFO] global_step=85824, episodic_env_return=81.0\n",
      "[2023-09-13 13:25:00][INFO] Current Mean Episodic Return = -1.6527869701385498\n",
      "[2023-09-13 13:25:00][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_86016`...\n",
      "[2023-09-13 13:25:00][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_86016`!\n",
      "[2023-09-13 13:25:02][INFO] SPS: 26\n",
      "[2023-09-13 13:27:19][INFO] user_preference = 1\n",
      "[2023-09-13 13:27:20][INFO] reward_predictor_training_loss=0.19587962329387665\n",
      "[2023-09-13 13:27:29][INFO] user_preference = 1\n",
      "[2023-09-13 13:27:29][INFO] reward_predictor_training_loss=0.931408166885376\n",
      "[2023-09-13 13:27:40][INFO] user_preference = 1\n",
      "[2023-09-13 13:27:40][INFO] reward_predictor_training_loss=1.360033392906189\n",
      "[2023-09-13 13:27:58][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:27:58][INFO] reward_predictor_training_loss=0.7210884094238281\n",
      "[2023-09-13 13:28:10][INFO] user_preference = 1\n",
      "[2023-09-13 13:28:10][INFO] reward_predictor_training_loss=0.19054873287677765\n",
      "[2023-09-13 13:28:19][INFO] user_preference = 1\n",
      "[2023-09-13 13:28:20][INFO] reward_predictor_training_loss=2.7388715744018555\n",
      "[2023-09-13 13:28:28][INFO] user_preference = 0\n",
      "[2023-09-13 13:28:29][INFO] reward_predictor_training_loss=1.179237723350525\n",
      "[2023-09-13 13:28:44][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:28:44][INFO] reward_predictor_training_loss=0.7140878438949585\n",
      "[2023-09-13 13:28:53][INFO] user_preference = 0\n",
      "[2023-09-13 13:28:53][INFO] reward_predictor_training_loss=0.10497225821018219\n",
      "[2023-09-13 13:29:01][INFO] user_preference = 0\n",
      "[2023-09-13 13:29:02][INFO] reward_predictor_training_loss=0.41289830207824707\n",
      "[2023-09-13 13:29:23][INFO] user_preference = 0\n",
      "[2023-09-13 13:29:23][INFO] reward_predictor_training_loss=1.0691602230072021\n",
      "[2023-09-13 13:29:34][INFO] user_preference = 1\n",
      "[2023-09-13 13:29:35][INFO] reward_predictor_training_loss=0.4046955704689026\n",
      "[2023-09-13 13:29:47][INFO] user_preference = 0\n",
      "[2023-09-13 13:29:48][INFO] reward_predictor_training_loss=0.4667327404022217\n",
      "[2023-09-13 13:30:00][INFO] user_preference = 1\n",
      "[2023-09-13 13:30:01][INFO] reward_predictor_training_loss=0.5706319808959961\n",
      "[2023-09-13 13:30:11][INFO] user_preference = 0\n",
      "[2023-09-13 13:30:11][INFO] reward_predictor_training_loss=0.01933842897415161\n",
      "[2023-09-13 13:30:19][INFO] user_preference = 0\n",
      "[2023-09-13 13:30:19][INFO] reward_predictor_training_loss=0.8342461585998535\n",
      "[2023-09-13 13:30:21][INFO] global_step=86136, episodic_reward_predictor_return=-1.7789146900177002\n",
      "[2023-09-13 13:30:21][INFO] global_step=86136, episodic_env_return=-22.0\n",
      "[2023-09-13 13:30:22][INFO] global_step=86176, episodic_reward_predictor_return=-1.1941258907318115\n",
      "[2023-09-13 13:30:22][INFO] global_step=86176, episodic_env_return=15.0\n",
      "[2023-09-13 13:30:22][INFO] global_step=86208, episodic_reward_predictor_return=-1.7774947881698608\n",
      "[2023-09-13 13:30:22][INFO] global_step=86208, episodic_env_return=-91.0\n",
      "[2023-09-13 13:30:26][INFO] global_step=86392, episodic_reward_predictor_return=-0.7229089140892029\n",
      "[2023-09-13 13:30:26][INFO] global_step=86392, episodic_env_return=74.0\n",
      "[2023-09-13 13:30:29][INFO] global_step=86592, episodic_reward_predictor_return=-2.151167631149292\n",
      "[2023-09-13 13:30:29][INFO] global_step=86592, episodic_env_return=44.0\n",
      "[2023-09-13 13:30:33][INFO] global_step=86864, episodic_reward_predictor_return=-4.4309492111206055\n",
      "[2023-09-13 13:30:33][INFO] global_step=86864, episodic_env_return=-79.0\n",
      "[2023-09-13 13:30:36][INFO] global_step=87072, episodic_reward_predictor_return=-6.175492286682129\n",
      "[2023-09-13 13:30:36][INFO] global_step=87072, episodic_env_return=-360.0\n",
      "[2023-09-13 13:30:37][INFO] global_step=87136, episodic_reward_predictor_return=-3.556598424911499\n",
      "[2023-09-13 13:30:37][INFO] global_step=87136, episodic_env_return=-93.0\n",
      "[2023-09-13 13:30:39][INFO] global_step=87256, episodic_reward_predictor_return=-4.803258895874023\n",
      "[2023-09-13 13:30:39][INFO] global_step=87256, episodic_env_return=-60.0\n",
      "[2023-09-13 13:30:40][INFO] global_step=87304, episodic_reward_predictor_return=-2.267927646636963\n",
      "[2023-09-13 13:30:40][INFO] global_step=87304, episodic_env_return=12.0\n",
      "[2023-09-13 13:30:40][INFO] global_step=87320, episodic_reward_predictor_return=-7.033918857574463\n",
      "[2023-09-13 13:30:40][INFO] global_step=87320, episodic_env_return=-300.0\n",
      "[2023-09-13 13:30:41][INFO] global_step=87384, episodic_reward_predictor_return=-2.1287999153137207\n",
      "[2023-09-13 13:30:41][INFO] global_step=87384, episodic_env_return=26.0\n",
      "[2023-09-13 13:30:41][INFO] global_step=87392, episodic_reward_predictor_return=-3.6500654220581055\n",
      "[2023-09-13 13:30:41][INFO] global_step=87392, episodic_env_return=-24.0\n",
      "[2023-09-13 13:30:44][INFO] global_step=87528, episodic_reward_predictor_return=-6.876086711883545\n",
      "[2023-09-13 13:30:44][INFO] global_step=87528, episodic_env_return=-370.0\n",
      "[2023-09-13 13:30:49][INFO] global_step=87824, episodic_reward_predictor_return=-1.4111181497573853\n",
      "[2023-09-13 13:30:49][INFO] global_step=87824, episodic_env_return=41.0\n",
      "[2023-09-13 13:30:49][INFO] global_step=87880, episodic_reward_predictor_return=-1.3246644735336304\n",
      "[2023-09-13 13:30:49][INFO] global_step=87880, episodic_env_return=57.0\n",
      "[2023-09-13 13:30:50][INFO] global_step=87928, episodic_reward_predictor_return=-2.0919291973114014\n",
      "[2023-09-13 13:30:50][INFO] global_step=87928, episodic_env_return=2.0\n",
      "[2023-09-13 13:30:51][INFO] global_step=87976, episodic_reward_predictor_return=-3.247990131378174\n",
      "[2023-09-13 13:30:51][INFO] global_step=87976, episodic_env_return=-12.0\n",
      "[2023-09-13 13:30:52][INFO] global_step=88032, episodic_reward_predictor_return=-2.7990610599517822\n",
      "[2023-09-13 13:30:52][INFO] global_step=88032, episodic_env_return=11.0\n",
      "[2023-09-13 13:30:52][INFO] Current Mean Episodic Return = -3.1274983882904053\n",
      "[2023-09-13 13:30:52][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_88064`...\n",
      "[2023-09-13 13:30:52][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_88064`!\n",
      "[2023-09-13 13:30:55][INFO] SPS: 24\n",
      "[2023-09-13 13:30:56][INFO] global_step=88128, episodic_reward_predictor_return=-0.5927529335021973\n",
      "[2023-09-13 13:30:56][INFO] global_step=88128, episodic_env_return=82.0\n",
      "[2023-09-13 13:30:58][INFO] global_step=88256, episodic_reward_predictor_return=-1.410029649734497\n",
      "[2023-09-13 13:30:58][INFO] global_step=88256, episodic_env_return=47.0\n",
      "[2023-09-13 13:30:59][INFO] global_step=88320, episodic_reward_predictor_return=-1.081028699874878\n",
      "[2023-09-13 13:30:59][INFO] global_step=88320, episodic_env_return=52.0\n",
      "[2023-09-13 13:31:00][INFO] global_step=88408, episodic_reward_predictor_return=-5.067286968231201\n",
      "[2023-09-13 13:31:00][INFO] global_step=88408, episodic_env_return=-58.0\n",
      "[2023-09-13 13:31:01][INFO] global_step=88440, episodic_reward_predictor_return=-0.6863517165184021\n",
      "[2023-09-13 13:31:01][INFO] global_step=88440, episodic_env_return=78.0\n",
      "[2023-09-13 13:31:04][INFO] global_step=88632, episodic_reward_predictor_return=-0.7103561758995056\n",
      "[2023-09-13 13:31:04][INFO] global_step=88632, episodic_env_return=57.0\n",
      "[2023-09-13 13:31:06][INFO] global_step=88728, episodic_reward_predictor_return=-0.4479566514492035\n",
      "[2023-09-13 13:31:06][INFO] global_step=88728, episodic_env_return=89.0\n",
      "[2023-09-13 13:31:07][INFO] global_step=88784, episodic_reward_predictor_return=-6.664686679840088\n",
      "[2023-09-13 13:31:07][INFO] global_step=88784, episodic_env_return=-134.0\n",
      "[2023-09-13 13:31:07][INFO] global_step=88800, episodic_reward_predictor_return=-2.3531877994537354\n",
      "[2023-09-13 13:31:07][INFO] global_step=88800, episodic_env_return=-3.0\n",
      "[2023-09-13 13:31:08][INFO] global_step=88840, episodic_reward_predictor_return=-1.4298524856567383\n",
      "[2023-09-13 13:31:08][INFO] global_step=88840, episodic_env_return=47.0\n",
      "[2023-09-13 13:31:12][INFO] global_step=89088, episodic_reward_predictor_return=-7.258883476257324\n",
      "[2023-09-13 13:31:12][INFO] global_step=89088, episodic_env_return=-125.0\n",
      "[2023-09-13 13:31:17][INFO] global_step=89368, episodic_reward_predictor_return=-4.1601738929748535\n",
      "[2023-09-13 13:31:17][INFO] global_step=89368, episodic_env_return=-15.0\n",
      "[2023-09-13 13:31:18][INFO] global_step=89432, episodic_reward_predictor_return=-2.1254029273986816\n",
      "[2023-09-13 13:31:18][INFO] global_step=89432, episodic_env_return=12.0\n",
      "[2023-09-13 13:31:19][INFO] global_step=89504, episodic_reward_predictor_return=-0.7210042476654053\n",
      "[2023-09-13 13:31:19][INFO] global_step=89504, episodic_env_return=84.0\n",
      "[2023-09-13 13:31:20][INFO] global_step=89536, episodic_reward_predictor_return=-2.502748966217041\n",
      "[2023-09-13 13:31:20][INFO] global_step=89536, episodic_env_return=-6.0\n",
      "[2023-09-13 13:31:20][INFO] global_step=89552, episodic_reward_predictor_return=-1.2861084938049316\n",
      "[2023-09-13 13:31:20][INFO] global_step=89552, episodic_env_return=43.0\n",
      "[2023-09-13 13:31:21][INFO] global_step=89600, episodic_reward_predictor_return=-3.24944806098938\n",
      "[2023-09-13 13:31:21][INFO] global_step=89600, episodic_env_return=-1.0\n",
      "[2023-09-13 13:31:21][INFO] global_step=89624, episodic_reward_predictor_return=-2.897171974182129\n",
      "[2023-09-13 13:31:21][INFO] global_step=89624, episodic_env_return=-16.0\n",
      "[2023-09-13 13:31:22][INFO] global_step=89640, episodic_reward_predictor_return=-0.5875004529953003\n",
      "[2023-09-13 13:31:22][INFO] global_step=89640, episodic_env_return=75.0\n",
      "[2023-09-13 13:31:23][INFO] global_step=89736, episodic_reward_predictor_return=-6.172013282775879\n",
      "[2023-09-13 13:31:23][INFO] global_step=89736, episodic_env_return=-151.0\n",
      "[2023-09-13 13:31:26][INFO] global_step=89912, episodic_reward_predictor_return=-0.7515254616737366\n",
      "[2023-09-13 13:31:26][INFO] global_step=89912, episodic_env_return=62.0\n",
      "[2023-09-13 13:31:28][INFO] global_step=89976, episodic_reward_predictor_return=-1.485091209411621\n",
      "[2023-09-13 13:31:28][INFO] global_step=89976, episodic_env_return=46.0\n",
      "[2023-09-13 13:31:30][INFO] Current Mean Episodic Return = -2.4382073879241943\n",
      "[2023-09-13 13:31:30][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_90112`...\n",
      "[2023-09-13 13:31:30][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_90112`!\n",
      "[2023-09-13 13:31:32][INFO] SPS: 24\n",
      "[2023-09-13 13:31:33][INFO] global_step=90128, episodic_reward_predictor_return=-1.3348712921142578\n",
      "[2023-09-13 13:31:33][INFO] global_step=90128, episodic_env_return=23.0\n",
      "[2023-09-13 13:31:33][INFO] global_step=90128, episodic_reward_predictor_return=-1.6295629739761353\n",
      "[2023-09-13 13:31:33][INFO] global_step=90128, episodic_env_return=40.0\n",
      "[2023-09-13 13:31:33][INFO] global_step=90160, episodic_reward_predictor_return=-1.4078937768936157\n",
      "[2023-09-13 13:31:33][INFO] global_step=90160, episodic_env_return=15.0\n",
      "[2023-09-13 13:31:34][INFO] global_step=90192, episodic_reward_predictor_return=-1.2694051265716553\n",
      "[2023-09-13 13:31:34][INFO] global_step=90192, episodic_env_return=66.0\n",
      "[2023-09-13 13:31:34][INFO] global_step=90200, episodic_reward_predictor_return=-2.5589520931243896\n",
      "[2023-09-13 13:31:34][INFO] global_step=90200, episodic_env_return=14.0\n",
      "[2023-09-13 13:31:35][INFO] global_step=90280, episodic_reward_predictor_return=-1.2235710620880127\n",
      "[2023-09-13 13:31:35][INFO] global_step=90280, episodic_env_return=63.0\n",
      "[2023-09-13 13:31:35][INFO] global_step=90288, episodic_reward_predictor_return=-0.7740839719772339\n",
      "[2023-09-13 13:31:35][INFO] global_step=90288, episodic_env_return=81.0\n",
      "[2023-09-13 13:31:37][INFO] global_step=90392, episodic_reward_predictor_return=-0.5849860310554504\n",
      "[2023-09-13 13:31:37][INFO] global_step=90392, episodic_env_return=76.0\n",
      "[2023-09-13 13:31:37][INFO] global_step=90432, episodic_reward_predictor_return=-10.927874565124512\n",
      "[2023-09-13 13:31:37][INFO] global_step=90432, episodic_env_return=-370.0\n",
      "[2023-09-13 13:31:38][INFO] global_step=90480, episodic_reward_predictor_return=-1.081557273864746\n",
      "[2023-09-13 13:31:38][INFO] global_step=90480, episodic_env_return=76.0\n",
      "[2023-09-13 13:31:38][INFO] global_step=90496, episodic_reward_predictor_return=-1.0527927875518799\n",
      "[2023-09-13 13:31:38][INFO] global_step=90496, episodic_env_return=64.0\n",
      "[2023-09-13 13:31:39][INFO] global_step=90528, episodic_reward_predictor_return=-0.07350872457027435\n",
      "[2023-09-13 13:31:39][INFO] global_step=90528, episodic_env_return=95.0\n",
      "[2023-09-13 13:31:41][INFO] global_step=90624, episodic_reward_predictor_return=-0.5120974779129028\n",
      "[2023-09-13 13:31:41][INFO] global_step=90624, episodic_env_return=85.0\n",
      "[2023-09-13 13:31:44][INFO] global_step=90792, episodic_reward_predictor_return=-0.8116726279258728\n",
      "[2023-09-13 13:31:44][INFO] global_step=90792, episodic_env_return=56.0\n",
      "[2023-09-13 13:31:45][INFO] global_step=90856, episodic_reward_predictor_return=-2.0806570053100586\n",
      "[2023-09-13 13:31:45][INFO] global_step=90856, episodic_env_return=20.0\n",
      "[2023-09-13 13:31:46][INFO] global_step=90904, episodic_reward_predictor_return=-2.257854461669922\n",
      "[2023-09-13 13:31:46][INFO] global_step=90904, episodic_env_return=-7.0\n",
      "[2023-09-13 13:31:48][INFO] global_step=91040, episodic_reward_predictor_return=-1.4554277658462524\n",
      "[2023-09-13 13:31:48][INFO] global_step=91040, episodic_env_return=49.0\n",
      "[2023-09-13 13:31:49][INFO] global_step=91072, episodic_reward_predictor_return=-3.3826279640197754\n",
      "[2023-09-13 13:31:49][INFO] global_step=91072, episodic_env_return=-42.0\n",
      "[2023-09-13 13:31:50][INFO] global_step=91168, episodic_reward_predictor_return=-0.8172994256019592\n",
      "[2023-09-13 13:31:50][INFO] global_step=91168, episodic_env_return=85.0\n",
      "[2023-09-13 13:31:52][INFO] global_step=91240, episodic_reward_predictor_return=-1.5724982023239136\n",
      "[2023-09-13 13:31:52][INFO] global_step=91240, episodic_env_return=40.0\n",
      "[2023-09-13 13:31:53][INFO] global_step=91304, episodic_reward_predictor_return=-1.699819564819336\n",
      "[2023-09-13 13:31:53][INFO] global_step=91304, episodic_env_return=40.0\n",
      "[2023-09-13 13:31:53][INFO] global_step=91304, episodic_reward_predictor_return=-0.23595045506954193\n",
      "[2023-09-13 13:31:53][INFO] global_step=91304, episodic_env_return=93.0\n",
      "[2023-09-13 13:31:53][INFO] global_step=91312, episodic_reward_predictor_return=-1.4470146894454956\n",
      "[2023-09-13 13:31:53][INFO] global_step=91312, episodic_env_return=50.0\n",
      "[2023-09-13 13:31:55][INFO] global_step=91456, episodic_reward_predictor_return=-3.80121111869812\n",
      "[2023-09-13 13:31:55][INFO] global_step=91456, episodic_env_return=-40.0\n",
      "[2023-09-13 13:31:56][INFO] global_step=91504, episodic_reward_predictor_return=-0.9382281303405762\n",
      "[2023-09-13 13:31:56][INFO] global_step=91504, episodic_env_return=59.0\n",
      "[2023-09-13 13:31:57][INFO] global_step=91560, episodic_reward_predictor_return=-1.160335898399353\n",
      "[2023-09-13 13:31:57][INFO] global_step=91560, episodic_env_return=30.0\n",
      "[2023-09-13 13:31:57][INFO] global_step=91568, episodic_reward_predictor_return=-5.402255058288574\n",
      "[2023-09-13 13:31:57][INFO] global_step=91568, episodic_env_return=-188.0\n",
      "[2023-09-13 13:31:59][INFO] global_step=91648, episodic_reward_predictor_return=-1.1776313781738281\n",
      "[2023-09-13 13:31:59][INFO] global_step=91648, episodic_env_return=58.0\n",
      "[2023-09-13 13:31:59][INFO] global_step=91672, episodic_reward_predictor_return=-0.8683072328567505\n",
      "[2023-09-13 13:31:59][INFO] global_step=91672, episodic_env_return=74.0\n",
      "[2023-09-13 13:31:59][INFO] global_step=91672, episodic_reward_predictor_return=-0.4305863678455353\n",
      "[2023-09-13 13:31:59][INFO] global_step=91672, episodic_env_return=80.0\n",
      "[2023-09-13 13:31:59][INFO] global_step=91688, episodic_reward_predictor_return=-1.0507982969284058\n",
      "[2023-09-13 13:31:59][INFO] global_step=91688, episodic_env_return=54.0\n",
      "[2023-09-13 13:32:00][INFO] global_step=91704, episodic_reward_predictor_return=-1.5416898727416992\n",
      "[2023-09-13 13:32:00][INFO] global_step=91704, episodic_env_return=51.0\n",
      "[2023-09-13 13:32:00][INFO] global_step=91728, episodic_reward_predictor_return=-0.2101636826992035\n",
      "[2023-09-13 13:32:00][INFO] global_step=91728, episodic_env_return=91.0\n",
      "[2023-09-13 13:32:01][INFO] global_step=91792, episodic_reward_predictor_return=-0.42434242367744446\n",
      "[2023-09-13 13:32:01][INFO] global_step=91792, episodic_env_return=90.0\n",
      "[2023-09-13 13:32:02][INFO] global_step=91864, episodic_reward_predictor_return=-0.9716534614562988\n",
      "[2023-09-13 13:32:02][INFO] global_step=91864, episodic_env_return=77.0\n",
      "[2023-09-13 13:32:03][INFO] global_step=91872, episodic_reward_predictor_return=-0.12377461045980453\n",
      "[2023-09-13 13:32:03][INFO] global_step=91872, episodic_env_return=91.0\n",
      "[2023-09-13 13:32:05][INFO] global_step=91984, episodic_reward_predictor_return=-1.3998738527297974\n",
      "[2023-09-13 13:32:05][INFO] global_step=91984, episodic_env_return=48.0\n",
      "[2023-09-13 13:32:05][INFO] global_step=91992, episodic_reward_predictor_return=-1.629805326461792\n",
      "[2023-09-13 13:32:05][INFO] global_step=91992, episodic_env_return=48.0\n",
      "[2023-09-13 13:32:05][INFO] global_step=92032, episodic_reward_predictor_return=-1.2479478120803833\n",
      "[2023-09-13 13:32:05][INFO] global_step=92032, episodic_env_return=51.0\n",
      "[2023-09-13 13:32:06][INFO] global_step=92080, episodic_reward_predictor_return=-1.241283893585205\n",
      "[2023-09-13 13:32:06][INFO] global_step=92080, episodic_env_return=47.0\n",
      "[2023-09-13 13:32:07][INFO] global_step=92152, episodic_reward_predictor_return=-1.1742277145385742\n",
      "[2023-09-13 13:32:07][INFO] global_step=92152, episodic_env_return=66.0\n",
      "[2023-09-13 13:32:07][INFO] global_step=92152, episodic_reward_predictor_return=-0.7527955174446106\n",
      "[2023-09-13 13:32:07][INFO] global_step=92152, episodic_env_return=81.0\n",
      "[2023-09-13 13:32:08][INFO] Current Mean Episodic Return = -1.565211534500122\n",
      "[2023-09-13 13:32:08][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_92160`...\n",
      "[2023-09-13 13:32:08][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_92160`!\n",
      "[2023-09-13 13:32:10][INFO] SPS: 24\n",
      "[2023-09-13 13:32:13][INFO] global_step=92344, episodic_reward_predictor_return=-1.5596415996551514\n",
      "[2023-09-13 13:32:13][INFO] global_step=92344, episodic_env_return=41.0\n",
      "[2023-09-13 13:32:14][INFO] global_step=92376, episodic_reward_predictor_return=-1.2894833087921143\n",
      "[2023-09-13 13:32:14][INFO] global_step=92376, episodic_env_return=52.0\n",
      "[2023-09-13 13:32:14][INFO] global_step=92416, episodic_reward_predictor_return=-0.32852470874786377\n",
      "[2023-09-13 13:32:14][INFO] global_step=92416, episodic_env_return=92.0\n",
      "[2023-09-13 13:32:16][INFO] global_step=92488, episodic_reward_predictor_return=-0.3918019235134125\n",
      "[2023-09-13 13:32:16][INFO] global_step=92488, episodic_env_return=92.0\n",
      "[2023-09-13 13:32:16][INFO] global_step=92512, episodic_reward_predictor_return=-0.9314141273498535\n",
      "[2023-09-13 13:32:16][INFO] global_step=92512, episodic_env_return=56.0\n",
      "[2023-09-13 13:32:17][INFO] global_step=92568, episodic_reward_predictor_return=-0.3846464455127716\n",
      "[2023-09-13 13:32:17][INFO] global_step=92568, episodic_env_return=91.0\n",
      "[2023-09-13 13:32:18][INFO] global_step=92616, episodic_reward_predictor_return=-0.4225092828273773\n",
      "[2023-09-13 13:32:18][INFO] global_step=92616, episodic_env_return=88.0\n",
      "[2023-09-13 13:32:19][INFO] global_step=92664, episodic_reward_predictor_return=-1.8274390697479248\n",
      "[2023-09-13 13:32:19][INFO] global_step=92664, episodic_env_return=2.0\n",
      "[2023-09-13 13:32:20][INFO] global_step=92760, episodic_reward_predictor_return=-2.37373948097229\n",
      "[2023-09-13 13:32:20][INFO] global_step=92760, episodic_env_return=10.0\n",
      "[2023-09-13 13:32:21][INFO] global_step=92792, episodic_reward_predictor_return=-2.7535600662231445\n",
      "[2023-09-13 13:32:21][INFO] global_step=92792, episodic_env_return=-375.0\n",
      "[2023-09-13 13:32:21][INFO] global_step=92808, episodic_reward_predictor_return=-1.7019288539886475\n",
      "[2023-09-13 13:32:21][INFO] global_step=92808, episodic_env_return=-10.0\n",
      "[2023-09-13 13:32:24][INFO] global_step=92976, episodic_reward_predictor_return=-2.023829460144043\n",
      "[2023-09-13 13:32:24][INFO] global_step=92976, episodic_env_return=50.0\n",
      "[2023-09-13 13:32:25][INFO] global_step=93024, episodic_reward_predictor_return=-1.5018336772918701\n",
      "[2023-09-13 13:32:25][INFO] global_step=93024, episodic_env_return=56.0\n",
      "[2023-09-13 13:32:26][INFO] global_step=93072, episodic_reward_predictor_return=-5.433553218841553\n",
      "[2023-09-13 13:32:26][INFO] global_step=93072, episodic_env_return=-97.0\n",
      "[2023-09-13 13:32:27][INFO] global_step=93144, episodic_reward_predictor_return=-1.3702831268310547\n",
      "[2023-09-13 13:32:27][INFO] global_step=93144, episodic_env_return=59.0\n",
      "[2023-09-13 13:32:28][INFO] global_step=93216, episodic_reward_predictor_return=-3.3623013496398926\n",
      "[2023-09-13 13:32:28][INFO] global_step=93216, episodic_env_return=-24.0\n",
      "[2023-09-13 13:32:31][INFO] global_step=93360, episodic_reward_predictor_return=-1.1586862802505493\n",
      "[2023-09-13 13:32:31][INFO] global_step=93360, episodic_env_return=59.0\n",
      "[2023-09-13 13:32:33][INFO] global_step=93464, episodic_reward_predictor_return=-0.42227184772491455\n",
      "[2023-09-13 13:32:33][INFO] global_step=93464, episodic_env_return=88.0\n",
      "[2023-09-13 13:32:34][INFO] global_step=93504, episodic_reward_predictor_return=-1.3772026300430298\n",
      "[2023-09-13 13:32:34][INFO] global_step=93504, episodic_env_return=56.0\n",
      "[2023-09-13 13:32:34][INFO] global_step=93528, episodic_reward_predictor_return=-2.205125331878662\n",
      "[2023-09-13 13:32:34][INFO] global_step=93528, episodic_env_return=32.0\n",
      "[2023-09-13 13:32:35][INFO] global_step=93568, episodic_reward_predictor_return=-0.6744352579116821\n",
      "[2023-09-13 13:32:35][INFO] global_step=93568, episodic_env_return=52.0\n",
      "[2023-09-13 13:32:36][INFO] global_step=93664, episodic_reward_predictor_return=-2.5692970752716064\n",
      "[2023-09-13 13:32:36][INFO] global_step=93664, episodic_env_return=-22.0\n",
      "[2023-09-13 13:32:38][INFO] global_step=93744, episodic_reward_predictor_return=0.009229827672243118\n",
      "[2023-09-13 13:32:38][INFO] global_step=93744, episodic_env_return=91.0\n",
      "[2023-09-13 13:32:40][INFO] global_step=93864, episodic_reward_predictor_return=-1.074411392211914\n",
      "[2023-09-13 13:32:40][INFO] global_step=93864, episodic_env_return=56.0\n",
      "[2023-09-13 13:32:40][INFO] global_step=93888, episodic_reward_predictor_return=-1.5547831058502197\n",
      "[2023-09-13 13:32:40][INFO] global_step=93888, episodic_env_return=38.0\n",
      "[2023-09-13 13:32:40][INFO] global_step=93896, episodic_reward_predictor_return=-2.077805280685425\n",
      "[2023-09-13 13:32:40][INFO] global_step=93896, episodic_env_return=-94.0\n",
      "[2023-09-13 13:32:41][INFO] global_step=93904, episodic_reward_predictor_return=-0.5541568994522095\n",
      "[2023-09-13 13:32:41][INFO] global_step=93904, episodic_env_return=81.0\n",
      "[2023-09-13 13:32:41][INFO] global_step=93912, episodic_reward_predictor_return=-1.6760592460632324\n",
      "[2023-09-13 13:32:41][INFO] global_step=93912, episodic_env_return=53.0\n",
      "[2023-09-13 13:32:41][INFO] global_step=93944, episodic_reward_predictor_return=-1.2146764993667603\n",
      "[2023-09-13 13:32:41][INFO] global_step=93944, episodic_env_return=54.0\n",
      "[2023-09-13 13:32:43][INFO] global_step=94064, episodic_reward_predictor_return=-0.6807036399841309\n",
      "[2023-09-13 13:32:43][INFO] global_step=94064, episodic_env_return=82.0\n",
      "[2023-09-13 13:32:46][INFO] Current Mean Episodic Return = -1.4962291717529297\n",
      "[2023-09-13 13:32:46][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_94208`...\n",
      "[2023-09-13 13:32:46][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_94208`!\n",
      "[2023-09-13 13:32:48][INFO] SPS: 25\n",
      "[2023-09-13 13:32:49][INFO] global_step=94256, episodic_reward_predictor_return=-2.7986700534820557\n",
      "[2023-09-13 13:32:49][INFO] global_step=94256, episodic_env_return=-112.0\n",
      "[2023-09-13 13:32:50][INFO] global_step=94320, episodic_reward_predictor_return=-1.67465341091156\n",
      "[2023-09-13 13:32:50][INFO] global_step=94320, episodic_env_return=49.0\n",
      "[2023-09-13 13:32:50][INFO] global_step=94320, episodic_reward_predictor_return=-2.319495439529419\n",
      "[2023-09-13 13:32:50][INFO] global_step=94320, episodic_env_return=48.0\n",
      "[2023-09-13 13:32:51][INFO] global_step=94344, episodic_reward_predictor_return=-1.0675091743469238\n",
      "[2023-09-13 13:32:51][INFO] global_step=94344, episodic_env_return=66.0\n",
      "[2023-09-13 13:32:51][INFO] global_step=94344, episodic_reward_predictor_return=-1.4066545963287354\n",
      "[2023-09-13 13:32:51][INFO] global_step=94344, episodic_env_return=31.0\n",
      "[2023-09-13 13:32:51][INFO] global_step=94360, episodic_reward_predictor_return=-1.2668111324310303\n",
      "[2023-09-13 13:32:51][INFO] global_step=94360, episodic_env_return=29.0\n",
      "[2023-09-13 13:32:51][INFO] global_step=94360, episodic_reward_predictor_return=-0.21385818719863892\n",
      "[2023-09-13 13:32:51][INFO] global_step=94360, episodic_env_return=88.0\n",
      "[2023-09-13 13:32:53][INFO] global_step=94480, episodic_reward_predictor_return=-0.39241671562194824\n",
      "[2023-09-13 13:32:53][INFO] global_step=94480, episodic_env_return=81.0\n",
      "[2023-09-13 13:32:53][INFO] global_step=94504, episodic_reward_predictor_return=-3.3365871906280518\n",
      "[2023-09-13 13:32:53][INFO] global_step=94504, episodic_env_return=4.0\n",
      "[2023-09-13 13:32:54][INFO] global_step=94560, episodic_reward_predictor_return=-1.1091958284378052\n",
      "[2023-09-13 13:32:54][INFO] global_step=94560, episodic_env_return=71.0\n",
      "[2023-09-13 13:32:55][INFO] global_step=94624, episodic_reward_predictor_return=-1.001938819885254\n",
      "[2023-09-13 13:32:55][INFO] global_step=94624, episodic_env_return=68.0\n",
      "[2023-09-13 13:32:57][INFO] global_step=94704, episodic_reward_predictor_return=-0.8056479096412659\n",
      "[2023-09-13 13:32:57][INFO] global_step=94704, episodic_env_return=83.0\n",
      "[2023-09-13 13:32:57][INFO] global_step=94744, episodic_reward_predictor_return=-5.01436185836792\n",
      "[2023-09-13 13:32:57][INFO] global_step=94744, episodic_env_return=-153.0\n",
      "[2023-09-13 13:32:58][INFO] global_step=94784, episodic_reward_predictor_return=-0.48182034492492676\n",
      "[2023-09-13 13:32:58][INFO] global_step=94784, episodic_env_return=91.0\n",
      "[2023-09-13 13:33:00][INFO] global_step=94888, episodic_reward_predictor_return=-0.984089195728302\n",
      "[2023-09-13 13:33:00][INFO] global_step=94888, episodic_env_return=50.0\n",
      "[2023-09-13 13:33:00][INFO] global_step=94896, episodic_reward_predictor_return=-1.253129005432129\n",
      "[2023-09-13 13:33:00][INFO] global_step=94896, episodic_env_return=67.0\n",
      "[2023-09-13 13:33:00][INFO] global_step=94912, episodic_reward_predictor_return=-1.817591667175293\n",
      "[2023-09-13 13:33:00][INFO] global_step=94912, episodic_env_return=20.0\n",
      "[2023-09-13 13:33:00][INFO] global_step=94912, episodic_reward_predictor_return=-0.9968968629837036\n",
      "[2023-09-13 13:33:00][INFO] global_step=94912, episodic_env_return=80.0\n",
      "[2023-09-13 13:33:01][INFO] global_step=94976, episodic_reward_predictor_return=-1.001508355140686\n",
      "[2023-09-13 13:33:01][INFO] global_step=94976, episodic_env_return=77.0\n",
      "[2023-09-13 13:33:03][INFO] global_step=95064, episodic_reward_predictor_return=-0.8962634801864624\n",
      "[2023-09-13 13:33:03][INFO] global_step=95064, episodic_env_return=79.0\n",
      "[2023-09-13 13:33:04][INFO] global_step=95112, episodic_reward_predictor_return=-0.46573406457901\n",
      "[2023-09-13 13:33:04][INFO] global_step=95112, episodic_env_return=76.0\n",
      "[2023-09-13 13:33:05][INFO] global_step=95208, episodic_reward_predictor_return=-0.36971813440322876\n",
      "[2023-09-13 13:33:05][INFO] global_step=95208, episodic_env_return=89.0\n",
      "[2023-09-13 13:33:07][INFO] global_step=95288, episodic_reward_predictor_return=-2.994230031967163\n",
      "[2023-09-13 13:33:07][INFO] global_step=95288, episodic_env_return=-47.0\n",
      "[2023-09-13 13:33:07][INFO] global_step=95304, episodic_reward_predictor_return=-2.0949172973632812\n",
      "[2023-09-13 13:33:07][INFO] global_step=95304, episodic_env_return=-24.0\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_reward_predictor_return=-2.1991961002349854\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_env_return=29.0\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_reward_predictor_return=-0.4028705358505249\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_env_return=86.0\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_reward_predictor_return=-3.3200571537017822\n",
      "[2023-09-13 13:33:09][INFO] global_step=95408, episodic_env_return=-50.0\n",
      "[2023-09-13 13:33:09][INFO] global_step=95416, episodic_reward_predictor_return=-1.158991813659668\n",
      "[2023-09-13 13:33:09][INFO] global_step=95416, episodic_env_return=41.0\n",
      "[2023-09-13 13:33:10][INFO] global_step=95472, episodic_reward_predictor_return=-0.32331788539886475\n",
      "[2023-09-13 13:33:10][INFO] global_step=95472, episodic_env_return=93.0\n",
      "[2023-09-13 13:33:11][INFO] global_step=95520, episodic_reward_predictor_return=-2.2113001346588135\n",
      "[2023-09-13 13:33:11][INFO] global_step=95520, episodic_env_return=18.0\n",
      "[2023-09-13 13:33:12][INFO] global_step=95568, episodic_reward_predictor_return=-0.8556572198867798\n",
      "[2023-09-13 13:33:12][INFO] global_step=95568, episodic_env_return=68.0\n",
      "[2023-09-13 13:33:13][INFO] global_step=95632, episodic_reward_predictor_return=-2.3510477542877197\n",
      "[2023-09-13 13:33:13][INFO] global_step=95632, episodic_env_return=48.0\n",
      "[2023-09-13 13:33:14][INFO] global_step=95688, episodic_reward_predictor_return=-0.7702628970146179\n",
      "[2023-09-13 13:33:14][INFO] global_step=95688, episodic_env_return=67.0\n",
      "[2023-09-13 13:33:15][INFO] global_step=95768, episodic_reward_predictor_return=-1.062862515449524\n",
      "[2023-09-13 13:33:15][INFO] global_step=95768, episodic_env_return=51.0\n",
      "[2023-09-13 13:33:15][INFO] global_step=95784, episodic_reward_predictor_return=-2.566845417022705\n",
      "[2023-09-13 13:33:15][INFO] global_step=95784, episodic_env_return=11.0\n",
      "[2023-09-13 13:33:16][INFO] global_step=95840, episodic_reward_predictor_return=-0.9863409996032715\n",
      "[2023-09-13 13:33:16][INFO] global_step=95840, episodic_env_return=55.0\n",
      "[2023-09-13 13:33:17][INFO] global_step=95848, episodic_reward_predictor_return=-0.7564830183982849\n",
      "[2023-09-13 13:33:17][INFO] global_step=95848, episodic_env_return=74.0\n",
      "[2023-09-13 13:33:18][INFO] global_step=95912, episodic_reward_predictor_return=-0.39483529329299927\n",
      "[2023-09-13 13:33:18][INFO] global_step=95912, episodic_env_return=92.0\n",
      "[2023-09-13 13:33:18][INFO] global_step=95912, episodic_reward_predictor_return=-0.5523990988731384\n",
      "[2023-09-13 13:33:18][INFO] global_step=95912, episodic_env_return=85.0\n",
      "[2023-09-13 13:33:18][INFO] global_step=95920, episodic_reward_predictor_return=-1.530653715133667\n",
      "[2023-09-13 13:33:18][INFO] global_step=95920, episodic_env_return=51.0\n",
      "[2023-09-13 13:33:18][INFO] global_step=95928, episodic_reward_predictor_return=-1.6168758869171143\n",
      "[2023-09-13 13:33:18][INFO] global_step=95928, episodic_env_return=51.0\n",
      "[2023-09-13 13:33:22][INFO] global_step=96160, episodic_reward_predictor_return=-0.6363200545310974\n",
      "[2023-09-13 13:33:22][INFO] global_step=96160, episodic_env_return=71.0\n",
      "[2023-09-13 13:33:22][INFO] global_step=96184, episodic_reward_predictor_return=-0.8428207039833069\n",
      "[2023-09-13 13:33:22][INFO] global_step=96184, episodic_env_return=49.0\n",
      "[2023-09-13 13:33:22][INFO] global_step=96184, episodic_reward_predictor_return=-2.2220325469970703\n",
      "[2023-09-13 13:33:22][INFO] global_step=96184, episodic_env_return=4.0\n",
      "[2023-09-13 13:33:24][INFO] global_step=96256, episodic_reward_predictor_return=-1.6486320495605469\n",
      "[2023-09-13 13:33:24][INFO] global_step=96256, episodic_env_return=15.0\n",
      "[2023-09-13 13:33:24][INFO] global_step=96256, episodic_reward_predictor_return=-0.4102908968925476\n",
      "[2023-09-13 13:33:24][INFO] global_step=96256, episodic_env_return=92.0\n",
      "[2023-09-13 13:33:24][INFO] Current Mean Episodic Return = -1.403995394706726\n",
      "[2023-09-13 13:33:24][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_96256`...\n",
      "[2023-09-13 13:33:24][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_96256`!\n",
      "[2023-09-13 13:33:26][INFO] SPS: 25\n",
      "[2023-09-13 13:33:28][INFO] global_step=96328, episodic_reward_predictor_return=-0.0792689174413681\n",
      "[2023-09-13 13:33:28][INFO] global_step=96328, episodic_env_return=92.0\n",
      "[2023-09-13 13:33:28][INFO] global_step=96352, episodic_reward_predictor_return=-0.9507004022598267\n",
      "[2023-09-13 13:33:28][INFO] global_step=96352, episodic_env_return=28.0\n",
      "[2023-09-13 13:33:28][INFO] global_step=96360, episodic_reward_predictor_return=-0.4643750786781311\n",
      "[2023-09-13 13:33:28][INFO] global_step=96360, episodic_env_return=79.0\n",
      "[2023-09-13 13:33:28][INFO] global_step=96376, episodic_reward_predictor_return=-0.7318902611732483\n",
      "[2023-09-13 13:33:28][INFO] global_step=96376, episodic_env_return=74.0\n",
      "[2023-09-13 13:33:30][INFO] global_step=96472, episodic_reward_predictor_return=-1.0142189264297485\n",
      "[2023-09-13 13:33:30][INFO] global_step=96472, episodic_env_return=74.0\n",
      "[2023-09-13 13:33:30][INFO] global_step=96488, episodic_reward_predictor_return=-0.3277861475944519\n",
      "[2023-09-13 13:33:30][INFO] global_step=96488, episodic_env_return=85.0\n",
      "[2023-09-13 13:33:31][INFO] global_step=96504, episodic_reward_predictor_return=-0.8669133186340332\n",
      "[2023-09-13 13:33:31][INFO] global_step=96504, episodic_env_return=79.0\n",
      "[2023-09-13 13:33:31][INFO] global_step=96528, episodic_reward_predictor_return=-0.6270002126693726\n",
      "[2023-09-13 13:33:31][INFO] global_step=96528, episodic_env_return=79.0\n",
      "[2023-09-13 13:33:33][INFO] global_step=96632, episodic_reward_predictor_return=-2.3557348251342773\n",
      "[2023-09-13 13:33:33][INFO] global_step=96632, episodic_env_return=-2.0\n",
      "[2023-09-13 13:33:33][INFO] global_step=96680, episodic_reward_predictor_return=-0.8518750667572021\n",
      "[2023-09-13 13:33:33][INFO] global_step=96680, episodic_env_return=63.0\n",
      "[2023-09-13 13:33:35][INFO] global_step=96784, episodic_reward_predictor_return=-2.0959906578063965\n",
      "[2023-09-13 13:33:35][INFO] global_step=96784, episodic_env_return=-28.0\n",
      "[2023-09-13 13:33:36][INFO] global_step=96824, episodic_reward_predictor_return=-3.587702751159668\n",
      "[2023-09-13 13:33:36][INFO] global_step=96824, episodic_env_return=-33.0\n",
      "[2023-09-13 13:33:36][INFO] global_step=96824, episodic_reward_predictor_return=-0.6074979305267334\n",
      "[2023-09-13 13:33:36][INFO] global_step=96824, episodic_env_return=59.0\n",
      "[2023-09-13 13:33:37][INFO] global_step=96880, episodic_reward_predictor_return=-0.3660723567008972\n",
      "[2023-09-13 13:33:37][INFO] global_step=96880, episodic_env_return=71.0\n",
      "[2023-09-13 13:33:38][INFO] global_step=96920, episodic_reward_predictor_return=-0.24631626904010773\n",
      "[2023-09-13 13:33:38][INFO] global_step=96920, episodic_env_return=89.0\n",
      "[2023-09-13 13:33:38][INFO] global_step=96952, episodic_reward_predictor_return=-0.6500605940818787\n",
      "[2023-09-13 13:33:38][INFO] global_step=96952, episodic_env_return=85.0\n",
      "[2023-09-13 13:33:38][INFO] global_step=96968, episodic_reward_predictor_return=-0.4820724427700043\n",
      "[2023-09-13 13:33:38][INFO] global_step=96968, episodic_env_return=73.0\n",
      "[2023-09-13 13:33:40][INFO] global_step=97072, episodic_reward_predictor_return=-0.6799951791763306\n",
      "[2023-09-13 13:33:40][INFO] global_step=97072, episodic_env_return=82.0\n",
      "[2023-09-13 13:33:42][INFO] global_step=97176, episodic_reward_predictor_return=-0.5474157333374023\n",
      "[2023-09-13 13:33:42][INFO] global_step=97176, episodic_env_return=88.0\n",
      "[2023-09-13 13:33:42][INFO] global_step=97184, episodic_reward_predictor_return=-0.6906112432479858\n",
      "[2023-09-13 13:33:42][INFO] global_step=97184, episodic_env_return=74.0\n",
      "[2023-09-13 13:33:43][INFO] global_step=97248, episodic_reward_predictor_return=-1.0762051343917847\n",
      "[2023-09-13 13:33:43][INFO] global_step=97248, episodic_env_return=64.0\n",
      "[2023-09-13 13:33:44][INFO] global_step=97288, episodic_reward_predictor_return=-0.9988214373588562\n",
      "[2023-09-13 13:33:44][INFO] global_step=97288, episodic_env_return=40.0\n",
      "[2023-09-13 13:33:45][INFO] global_step=97328, episodic_reward_predictor_return=-2.6468513011932373\n",
      "[2023-09-13 13:33:45][INFO] global_step=97328, episodic_env_return=-6.0\n",
      "[2023-09-13 13:33:45][INFO] global_step=97336, episodic_reward_predictor_return=-3.1813056468963623\n",
      "[2023-09-13 13:33:45][INFO] global_step=97336, episodic_env_return=-25.0\n",
      "[2023-09-13 13:33:46][INFO] global_step=97392, episodic_reward_predictor_return=-0.3324527442455292\n",
      "[2023-09-13 13:33:46][INFO] global_step=97392, episodic_env_return=75.0\n",
      "[2023-09-13 13:33:46][INFO] global_step=97400, episodic_reward_predictor_return=-0.41794613003730774\n",
      "[2023-09-13 13:33:46][INFO] global_step=97400, episodic_env_return=68.0\n",
      "[2023-09-13 13:33:46][INFO] global_step=97416, episodic_reward_predictor_return=-0.36701154708862305\n",
      "[2023-09-13 13:33:46][INFO] global_step=97416, episodic_env_return=85.0\n",
      "[2023-09-13 13:33:47][INFO] global_step=97456, episodic_reward_predictor_return=-0.373224139213562\n",
      "[2023-09-13 13:33:47][INFO] global_step=97456, episodic_env_return=86.0\n",
      "[2023-09-13 13:33:48][INFO] global_step=97504, episodic_reward_predictor_return=-0.6207032799720764\n",
      "[2023-09-13 13:33:48][INFO] global_step=97504, episodic_env_return=69.0\n",
      "[2023-09-13 13:33:49][INFO] global_step=97544, episodic_reward_predictor_return=-0.36004242300987244\n",
      "[2023-09-13 13:33:49][INFO] global_step=97544, episodic_env_return=83.0\n",
      "[2023-09-13 13:33:49][INFO] global_step=97552, episodic_reward_predictor_return=-0.3687002658843994\n",
      "[2023-09-13 13:33:49][INFO] global_step=97552, episodic_env_return=84.0\n",
      "[2023-09-13 13:33:49][INFO] global_step=97568, episodic_reward_predictor_return=-0.4767071306705475\n",
      "[2023-09-13 13:33:49][INFO] global_step=97568, episodic_env_return=74.0\n",
      "[2023-09-13 13:33:50][INFO] global_step=97640, episodic_reward_predictor_return=-0.23525097966194153\n",
      "[2023-09-13 13:33:50][INFO] global_step=97640, episodic_env_return=90.0\n",
      "[2023-09-13 13:33:52][INFO] global_step=97736, episodic_reward_predictor_return=-0.38968756794929504\n",
      "[2023-09-13 13:33:52][INFO] global_step=97736, episodic_env_return=89.0\n",
      "[2023-09-13 13:33:52][INFO] global_step=97752, episodic_reward_predictor_return=-1.670392632484436\n",
      "[2023-09-13 13:33:52][INFO] global_step=97752, episodic_env_return=-79.0\n",
      "[2023-09-13 13:33:53][INFO] global_step=97760, episodic_reward_predictor_return=-0.9646361470222473\n",
      "[2023-09-13 13:33:53][INFO] global_step=97760, episodic_env_return=77.0\n",
      "[2023-09-13 13:33:53][INFO] global_step=97784, episodic_reward_predictor_return=-1.2757796049118042\n",
      "[2023-09-13 13:33:53][INFO] global_step=97784, episodic_env_return=66.0\n",
      "[2023-09-13 13:33:56][INFO] global_step=97936, episodic_reward_predictor_return=-1.2274343967437744\n",
      "[2023-09-13 13:33:56][INFO] global_step=97936, episodic_env_return=26.0\n",
      "[2023-09-13 13:33:57][INFO] global_step=98016, episodic_reward_predictor_return=-0.1443297564983368\n",
      "[2023-09-13 13:33:57][INFO] global_step=98016, episodic_env_return=91.0\n",
      "[2023-09-13 13:33:58][INFO] global_step=98072, episodic_reward_predictor_return=-1.2421956062316895\n",
      "[2023-09-13 13:33:58][INFO] global_step=98072, episodic_env_return=59.0\n",
      "[2023-09-13 13:34:00][INFO] global_step=98200, episodic_reward_predictor_return=-0.8366411328315735\n",
      "[2023-09-13 13:34:00][INFO] global_step=98200, episodic_env_return=30.0\n",
      "[2023-09-13 13:34:01][INFO] global_step=98240, episodic_reward_predictor_return=-0.7082446813583374\n",
      "[2023-09-13 13:34:01][INFO] global_step=98240, episodic_env_return=68.0\n",
      "[2023-09-13 13:34:02][INFO] Current Mean Episodic Return = -0.9080491065979004\n",
      "[2023-09-13 13:34:02][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_98304`...\n",
      "[2023-09-13 13:34:02][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_98304`!\n",
      "[2023-09-13 13:34:05][INFO] SPS: 25\n",
      "[2023-09-13 13:34:06][INFO] global_step=98376, episodic_reward_predictor_return=-2.2834603786468506\n",
      "[2023-09-13 13:34:06][INFO] global_step=98376, episodic_env_return=-50.0\n",
      "[2023-09-13 13:34:06][INFO] global_step=98400, episodic_reward_predictor_return=-1.2475146055221558\n",
      "[2023-09-13 13:34:06][INFO] global_step=98400, episodic_env_return=76.0\n",
      "[2023-09-13 13:34:07][INFO] global_step=98424, episodic_reward_predictor_return=-3.228928327560425\n",
      "[2023-09-13 13:34:07][INFO] global_step=98424, episodic_env_return=-24.0\n",
      "[2023-09-13 13:34:08][INFO] global_step=98528, episodic_reward_predictor_return=-0.9810905456542969\n",
      "[2023-09-13 13:34:08][INFO] global_step=98528, episodic_env_return=65.0\n",
      "[2023-09-13 13:34:11][INFO] global_step=98688, episodic_reward_predictor_return=-2.2770020961761475\n",
      "[2023-09-13 13:34:11][INFO] global_step=98688, episodic_env_return=14.0\n",
      "[2023-09-13 13:34:11][INFO] global_step=98712, episodic_reward_predictor_return=-0.5318344831466675\n",
      "[2023-09-13 13:34:11][INFO] global_step=98712, episodic_env_return=73.0\n",
      "[2023-09-13 13:34:12][INFO] global_step=98752, episodic_reward_predictor_return=-1.4474313259124756\n",
      "[2023-09-13 13:34:12][INFO] global_step=98752, episodic_env_return=-43.0\n",
      "[2023-09-13 13:34:13][INFO] global_step=98824, episodic_reward_predictor_return=-0.2603086233139038\n",
      "[2023-09-13 13:34:13][INFO] global_step=98824, episodic_env_return=92.0\n",
      "[2023-09-13 13:34:14][INFO] global_step=98840, episodic_reward_predictor_return=-0.9077096581459045\n",
      "[2023-09-13 13:34:14][INFO] global_step=98840, episodic_env_return=44.0\n",
      "[2023-09-13 13:34:14][INFO] global_step=98856, episodic_reward_predictor_return=-0.7228939533233643\n",
      "[2023-09-13 13:34:14][INFO] global_step=98856, episodic_env_return=80.0\n",
      "[2023-09-13 13:34:15][INFO] global_step=98904, episodic_reward_predictor_return=-7.6775431632995605\n",
      "[2023-09-13 13:34:15][INFO] global_step=98904, episodic_env_return=-385.0\n",
      "[2023-09-13 13:34:15][INFO] global_step=98944, episodic_reward_predictor_return=-1.5890930891036987\n",
      "[2023-09-13 13:34:15][INFO] global_step=98944, episodic_env_return=15.0\n",
      "[2023-09-13 13:34:17][INFO] global_step=99040, episodic_reward_predictor_return=-0.9187609553337097\n",
      "[2023-09-13 13:34:17][INFO] global_step=99040, episodic_env_return=78.0\n",
      "[2023-09-13 13:34:18][INFO] global_step=99072, episodic_reward_predictor_return=-0.5095719695091248\n",
      "[2023-09-13 13:34:18][INFO] global_step=99072, episodic_env_return=85.0\n",
      "[2023-09-13 13:34:19][INFO] global_step=99144, episodic_reward_predictor_return=-0.7428147792816162\n",
      "[2023-09-13 13:34:19][INFO] global_step=99144, episodic_env_return=58.0\n",
      "[2023-09-13 13:34:20][INFO] global_step=99216, episodic_reward_predictor_return=-0.8280729055404663\n",
      "[2023-09-13 13:34:20][INFO] global_step=99216, episodic_env_return=79.0\n",
      "[2023-09-13 13:34:21][INFO] global_step=99256, episodic_reward_predictor_return=-1.081937313079834\n",
      "[2023-09-13 13:34:21][INFO] global_step=99256, episodic_env_return=57.0\n",
      "[2023-09-13 13:34:21][INFO] global_step=99288, episodic_reward_predictor_return=-2.2179229259490967\n",
      "[2023-09-13 13:34:21][INFO] global_step=99288, episodic_env_return=14.0\n",
      "[2023-09-13 13:34:22][INFO] global_step=99336, episodic_reward_predictor_return=-0.31090763211250305\n",
      "[2023-09-13 13:34:22][INFO] global_step=99336, episodic_env_return=91.0\n",
      "[2023-09-13 13:34:22][INFO] global_step=99360, episodic_reward_predictor_return=-0.5580725073814392\n",
      "[2023-09-13 13:34:22][INFO] global_step=99360, episodic_env_return=83.0\n",
      "[2023-09-13 13:34:23][INFO] global_step=99384, episodic_reward_predictor_return=-1.8387107849121094\n",
      "[2023-09-13 13:34:23][INFO] global_step=99384, episodic_env_return=16.0\n",
      "[2023-09-13 13:34:23][INFO] global_step=99416, episodic_reward_predictor_return=-2.7968719005584717\n",
      "[2023-09-13 13:34:23][INFO] global_step=99416, episodic_env_return=-56.0\n",
      "[2023-09-13 13:34:24][INFO] global_step=99464, episodic_reward_predictor_return=-1.151444435119629\n",
      "[2023-09-13 13:34:24][INFO] global_step=99464, episodic_env_return=37.0\n",
      "[2023-09-13 13:34:25][INFO] global_step=99504, episodic_reward_predictor_return=-0.37616005539894104\n",
      "[2023-09-13 13:34:25][INFO] global_step=99504, episodic_env_return=90.0\n",
      "[2023-09-13 13:34:25][INFO] global_step=99512, episodic_reward_predictor_return=-0.6601144671440125\n",
      "[2023-09-13 13:34:25][INFO] global_step=99512, episodic_env_return=82.0\n",
      "[2023-09-13 13:34:25][INFO] global_step=99512, episodic_reward_predictor_return=-0.2942856550216675\n",
      "[2023-09-13 13:34:25][INFO] global_step=99512, episodic_env_return=73.0\n",
      "[2023-09-13 13:34:26][INFO] global_step=99568, episodic_reward_predictor_return=-0.6489401459693909\n",
      "[2023-09-13 13:34:26][INFO] global_step=99568, episodic_env_return=73.0\n",
      "[2023-09-13 13:34:28][INFO] global_step=99720, episodic_reward_predictor_return=-1.2509386539459229\n",
      "[2023-09-13 13:34:28][INFO] global_step=99720, episodic_env_return=19.0\n",
      "[2023-09-13 13:34:29][INFO] global_step=99728, episodic_reward_predictor_return=-0.7176360487937927\n",
      "[2023-09-13 13:34:29][INFO] global_step=99728, episodic_env_return=69.0\n",
      "[2023-09-13 13:34:29][INFO] global_step=99760, episodic_reward_predictor_return=-0.5893056392669678\n",
      "[2023-09-13 13:34:29][INFO] global_step=99760, episodic_env_return=64.0\n",
      "[2023-09-13 13:34:30][INFO] global_step=99776, episodic_reward_predictor_return=-0.6580089330673218\n",
      "[2023-09-13 13:34:30][INFO] global_step=99776, episodic_env_return=70.0\n",
      "[2023-09-13 13:34:30][INFO] global_step=99808, episodic_reward_predictor_return=-1.0022081136703491\n",
      "[2023-09-13 13:34:30][INFO] global_step=99808, episodic_env_return=58.0\n",
      "[2023-09-13 13:34:31][INFO] global_step=99864, episodic_reward_predictor_return=-0.290252685546875\n",
      "[2023-09-13 13:34:31][INFO] global_step=99864, episodic_env_return=94.0\n",
      "[2023-09-13 13:34:31][INFO] global_step=99864, episodic_reward_predictor_return=-0.5198284983634949\n",
      "[2023-09-13 13:34:31][INFO] global_step=99864, episodic_env_return=84.0\n",
      "[2023-09-13 13:34:33][INFO] global_step=99984, episodic_reward_predictor_return=-0.46521201729774475\n",
      "[2023-09-13 13:34:33][INFO] global_step=99984, episodic_env_return=86.0\n",
      "[2023-09-13 13:34:34][INFO] global_step=100048, episodic_reward_predictor_return=-1.1709080934524536\n",
      "[2023-09-13 13:34:34][INFO] global_step=100048, episodic_env_return=60.0\n",
      "[2023-09-13 13:34:34][INFO] global_step=100056, episodic_reward_predictor_return=-0.6870279908180237\n",
      "[2023-09-13 13:34:34][INFO] global_step=100056, episodic_env_return=49.0\n",
      "[2023-09-13 13:34:34][INFO] global_step=100064, episodic_reward_predictor_return=-1.6804026365280151\n",
      "[2023-09-13 13:34:34][INFO] global_step=100064, episodic_env_return=17.0\n",
      "[2023-09-13 13:34:36][INFO] global_step=100184, episodic_reward_predictor_return=-6.943363189697266\n",
      "[2023-09-13 13:34:36][INFO] global_step=100184, episodic_env_return=-375.0\n",
      "[2023-09-13 13:34:36][INFO] global_step=100184, episodic_reward_predictor_return=-1.2150800228118896\n",
      "[2023-09-13 13:34:36][INFO] global_step=100184, episodic_env_return=61.0\n",
      "[2023-09-13 13:34:37][INFO] global_step=100208, episodic_reward_predictor_return=-0.4724397659301758\n",
      "[2023-09-13 13:34:37][INFO] global_step=100208, episodic_env_return=76.0\n",
      "[2023-09-13 13:34:38][INFO] global_step=100280, episodic_reward_predictor_return=-0.2880861163139343\n",
      "[2023-09-13 13:34:38][INFO] global_step=100280, episodic_env_return=89.0\n",
      "[2023-09-13 13:34:38][INFO] global_step=100304, episodic_reward_predictor_return=-2.103541374206543\n",
      "[2023-09-13 13:34:38][INFO] global_step=100304, episodic_env_return=30.0\n",
      "[2023-09-13 13:34:39][INFO] global_step=100344, episodic_reward_predictor_return=-0.8735466599464417\n",
      "[2023-09-13 13:34:39][INFO] global_step=100344, episodic_env_return=65.0\n",
      "[2023-09-13 13:34:39][INFO] Current Mean Episodic Return = -1.3412996530532837\n",
      "[2023-09-13 13:34:39][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_100352`...\n",
      "[2023-09-13 13:34:39][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_100352`!\n",
      "[2023-09-13 13:34:42][INFO] SPS: 26\n",
      "[2023-09-13 13:36:16][INFO] user_preference = 1\n",
      "[2023-09-13 13:36:16][INFO] reward_predictor_training_loss=0.9082666039466858\n",
      "[2023-09-13 13:36:22][INFO] user_preference = 1\n",
      "[2023-09-13 13:36:22][INFO] reward_predictor_training_loss=0.5008223056793213\n",
      "[2023-09-13 13:36:36][INFO] user_preference = 1\n",
      "[2023-09-13 13:36:37][INFO] reward_predictor_training_loss=1.4382401704788208\n",
      "[2023-09-13 13:36:52][INFO] user_preference = 1\n",
      "[2023-09-13 13:36:52][INFO] reward_predictor_training_loss=1.941273808479309\n",
      "[2023-09-13 13:37:02][INFO] user_preference = 0\n",
      "[2023-09-13 13:37:02][INFO] reward_predictor_training_loss=0.11540934443473816\n",
      "[2023-09-13 13:37:15][INFO] user_preference = 1\n",
      "[2023-09-13 13:37:16][INFO] reward_predictor_training_loss=0.20987477898597717\n",
      "[2023-09-13 13:37:33][INFO] user_preference = 0\n",
      "[2023-09-13 13:37:33][INFO] reward_predictor_training_loss=0.4108721613883972\n",
      "[2023-09-13 13:38:15][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:38:15][INFO] reward_predictor_training_loss=0.9533214569091797\n",
      "[2023-09-13 13:38:24][INFO] user_preference = 1\n",
      "[2023-09-13 13:38:24][INFO] reward_predictor_training_loss=0.2990550100803375\n",
      "[2023-09-13 13:38:44][INFO] user_preference = 1\n",
      "[2023-09-13 13:38:44][INFO] reward_predictor_training_loss=0.534862756729126\n",
      "[2023-09-13 13:39:11][INFO] user_preference = 0\n",
      "[2023-09-13 13:39:11][INFO] reward_predictor_training_loss=0.2111189067363739\n",
      "[2023-09-13 13:39:54][INFO] user_preference = 1\n",
      "[2023-09-13 13:39:54][INFO] reward_predictor_training_loss=0.3001510500907898\n",
      "[2023-09-13 13:40:11][INFO] user_preference = 0\n",
      "[2023-09-13 13:40:11][INFO] reward_predictor_training_loss=0.509996235370636\n",
      "[2023-09-13 13:40:27][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:40:27][INFO] reward_predictor_training_loss=0.826492428779602\n",
      "[2023-09-13 13:40:40][INFO] user_preference = 0\n",
      "[2023-09-13 13:40:40][INFO] reward_predictor_training_loss=1.2802400588989258\n",
      "[2023-09-13 13:40:51][INFO] user_preference = 1\n",
      "[2023-09-13 13:40:51][INFO] reward_predictor_training_loss=0.24217988550662994\n",
      "[2023-09-13 13:40:51][INFO] global_step=100368, episodic_reward_predictor_return=-0.9883303642272949\n",
      "[2023-09-13 13:40:51][INFO] global_step=100368, episodic_env_return=43.0\n",
      "[2023-09-13 13:40:52][INFO] global_step=100416, episodic_reward_predictor_return=-0.32044216990470886\n",
      "[2023-09-13 13:40:52][INFO] global_step=100416, episodic_env_return=84.0\n",
      "[2023-09-13 13:40:52][INFO] global_step=100440, episodic_reward_predictor_return=-0.27196353673934937\n",
      "[2023-09-13 13:40:52][INFO] global_step=100440, episodic_env_return=84.0\n",
      "[2023-09-13 13:40:53][INFO] global_step=100472, episodic_reward_predictor_return=-0.5638654828071594\n",
      "[2023-09-13 13:40:53][INFO] global_step=100472, episodic_env_return=65.0\n",
      "[2023-09-13 13:40:53][INFO] global_step=100496, episodic_reward_predictor_return=-0.4956807494163513\n",
      "[2023-09-13 13:40:53][INFO] global_step=100496, episodic_env_return=65.0\n",
      "[2023-09-13 13:40:55][INFO] global_step=100584, episodic_reward_predictor_return=-0.5512454509735107\n",
      "[2023-09-13 13:40:55][INFO] global_step=100584, episodic_env_return=71.0\n",
      "[2023-09-13 13:40:55][INFO] global_step=100592, episodic_reward_predictor_return=-0.6396167278289795\n",
      "[2023-09-13 13:40:55][INFO] global_step=100592, episodic_env_return=73.0\n",
      "[2023-09-13 13:40:56][INFO] global_step=100648, episodic_reward_predictor_return=-0.45026805996894836\n",
      "[2023-09-13 13:40:56][INFO] global_step=100648, episodic_env_return=75.0\n",
      "[2023-09-13 13:40:56][INFO] global_step=100664, episodic_reward_predictor_return=-0.3379706144332886\n",
      "[2023-09-13 13:40:56][INFO] global_step=100664, episodic_env_return=80.0\n",
      "[2023-09-13 13:40:59][INFO] global_step=100808, episodic_reward_predictor_return=-0.5708135366439819\n",
      "[2023-09-13 13:40:59][INFO] global_step=100808, episodic_env_return=83.0\n",
      "[2023-09-13 13:41:00][INFO] global_step=100920, episodic_reward_predictor_return=-0.31473174691200256\n",
      "[2023-09-13 13:41:00][INFO] global_step=100920, episodic_env_return=87.0\n",
      "[2023-09-13 13:41:00][INFO] global_step=100920, episodic_reward_predictor_return=-0.8633438348770142\n",
      "[2023-09-13 13:41:00][INFO] global_step=100920, episodic_env_return=-41.0\n",
      "[2023-09-13 13:41:01][INFO] global_step=100928, episodic_reward_predictor_return=-0.944457471370697\n",
      "[2023-09-13 13:41:01][INFO] global_step=100928, episodic_env_return=39.0\n",
      "[2023-09-13 13:41:01][INFO] global_step=100968, episodic_reward_predictor_return=-1.3663091659545898\n",
      "[2023-09-13 13:41:01][INFO] global_step=100968, episodic_env_return=17.0\n",
      "[2023-09-13 13:41:03][INFO] global_step=101056, episodic_reward_predictor_return=-0.44253599643707275\n",
      "[2023-09-13 13:41:03][INFO] global_step=101056, episodic_env_return=35.0\n",
      "[2023-09-13 13:41:03][INFO] global_step=101072, episodic_reward_predictor_return=-0.24258044362068176\n",
      "[2023-09-13 13:41:03][INFO] global_step=101072, episodic_env_return=82.0\n",
      "[2023-09-13 13:41:04][INFO] global_step=101104, episodic_reward_predictor_return=-0.4605819880962372\n",
      "[2023-09-13 13:41:04][INFO] global_step=101104, episodic_env_return=73.0\n",
      "[2023-09-13 13:41:07][INFO] global_step=101296, episodic_reward_predictor_return=-0.369081974029541\n",
      "[2023-09-13 13:41:07][INFO] global_step=101296, episodic_env_return=68.0\n",
      "[2023-09-13 13:41:07][INFO] global_step=101328, episodic_reward_predictor_return=-0.6145523190498352\n",
      "[2023-09-13 13:41:07][INFO] global_step=101328, episodic_env_return=41.0\n",
      "[2023-09-13 13:41:08][INFO] global_step=101336, episodic_reward_predictor_return=-0.22923888266086578\n",
      "[2023-09-13 13:41:08][INFO] global_step=101336, episodic_env_return=-7.0\n",
      "[2023-09-13 13:41:09][INFO] global_step=101408, episodic_reward_predictor_return=-0.044071607291698456\n",
      "[2023-09-13 13:41:09][INFO] global_step=101408, episodic_env_return=92.0\n",
      "[2023-09-13 13:41:10][INFO] global_step=101488, episodic_reward_predictor_return=-0.16064292192459106\n",
      "[2023-09-13 13:41:10][INFO] global_step=101488, episodic_env_return=91.0\n",
      "[2023-09-13 13:41:10][INFO] global_step=101496, episodic_reward_predictor_return=-0.9319851994514465\n",
      "[2023-09-13 13:41:10][INFO] global_step=101496, episodic_env_return=47.0\n",
      "[2023-09-13 13:41:11][INFO] global_step=101512, episodic_reward_predictor_return=-0.4933287501335144\n",
      "[2023-09-13 13:41:11][INFO] global_step=101512, episodic_env_return=39.0\n",
      "[2023-09-13 13:41:13][INFO] global_step=101632, episodic_reward_predictor_return=-0.28872907161712646\n",
      "[2023-09-13 13:41:13][INFO] global_step=101632, episodic_env_return=86.0\n",
      "[2023-09-13 13:41:13][INFO] global_step=101672, episodic_reward_predictor_return=-0.15350234508514404\n",
      "[2023-09-13 13:41:13][INFO] global_step=101672, episodic_env_return=79.0\n",
      "[2023-09-13 13:41:14][INFO] global_step=101728, episodic_reward_predictor_return=-1.984769582748413\n",
      "[2023-09-13 13:41:14][INFO] global_step=101728, episodic_env_return=-72.0\n",
      "[2023-09-13 13:41:14][INFO] global_step=101736, episodic_reward_predictor_return=-1.0324428081512451\n",
      "[2023-09-13 13:41:14][INFO] global_step=101736, episodic_env_return=45.0\n",
      "[2023-09-13 13:41:14][INFO] global_step=101736, episodic_reward_predictor_return=-6.671022891998291\n",
      "[2023-09-13 13:41:14][INFO] global_step=101736, episodic_env_return=-375.0\n",
      "[2023-09-13 13:41:15][INFO] global_step=101760, episodic_reward_predictor_return=-0.781783401966095\n",
      "[2023-09-13 13:41:15][INFO] global_step=101760, episodic_env_return=33.0\n",
      "[2023-09-13 13:41:16][INFO] global_step=101824, episodic_reward_predictor_return=-0.35507842898368835\n",
      "[2023-09-13 13:41:16][INFO] global_step=101824, episodic_env_return=77.0\n",
      "[2023-09-13 13:41:16][INFO] global_step=101832, episodic_reward_predictor_return=-1.332066535949707\n",
      "[2023-09-13 13:41:16][INFO] global_step=101832, episodic_env_return=-32.0\n",
      "[2023-09-13 13:41:17][INFO] global_step=101872, episodic_reward_predictor_return=0.024701757356524467\n",
      "[2023-09-13 13:41:17][INFO] global_step=101872, episodic_env_return=87.0\n",
      "[2023-09-13 13:41:18][INFO] global_step=101928, episodic_reward_predictor_return=-0.3541700541973114\n",
      "[2023-09-13 13:41:18][INFO] global_step=101928, episodic_env_return=41.0\n",
      "[2023-09-13 13:41:20][INFO] global_step=102048, episodic_reward_predictor_return=-0.2292974591255188\n",
      "[2023-09-13 13:41:20][INFO] global_step=102048, episodic_env_return=86.0\n",
      "[2023-09-13 13:41:21][INFO] global_step=102128, episodic_reward_predictor_return=-0.43887248635292053\n",
      "[2023-09-13 13:41:21][INFO] global_step=102128, episodic_env_return=69.0\n",
      "[2023-09-13 13:41:23][INFO] global_step=102240, episodic_reward_predictor_return=-0.5320358276367188\n",
      "[2023-09-13 13:41:23][INFO] global_step=102240, episodic_env_return=23.0\n",
      "[2023-09-13 13:41:23][INFO] global_step=102264, episodic_reward_predictor_return=-0.6223587393760681\n",
      "[2023-09-13 13:41:23][INFO] global_step=102264, episodic_env_return=32.0\n",
      "[2023-09-13 13:41:25][INFO] Current Mean Episodic Return = -0.7215543985366821\n",
      "[2023-09-13 13:41:25][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_102400`...\n",
      "[2023-09-13 13:41:25][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_102400`!\n",
      "[2023-09-13 13:41:28][INFO] SPS: 24\n",
      "[2023-09-13 13:41:30][INFO] global_step=102504, episodic_reward_predictor_return=-2.2308943271636963\n",
      "[2023-09-13 13:41:30][INFO] global_step=102504, episodic_env_return=-23.0\n",
      "[2023-09-13 13:41:31][INFO] global_step=102544, episodic_reward_predictor_return=-0.8986480832099915\n",
      "[2023-09-13 13:41:31][INFO] global_step=102544, episodic_env_return=-16.0\n",
      "[2023-09-13 13:41:31][INFO] global_step=102560, episodic_reward_predictor_return=-0.3738808333873749\n",
      "[2023-09-13 13:41:31][INFO] global_step=102560, episodic_env_return=56.0\n",
      "[2023-09-13 13:41:32][INFO] global_step=102616, episodic_reward_predictor_return=-1.7226738929748535\n",
      "[2023-09-13 13:41:32][INFO] global_step=102616, episodic_env_return=-18.0\n",
      "[2023-09-13 13:41:33][INFO] global_step=102712, episodic_reward_predictor_return=-0.6822838187217712\n",
      "[2023-09-13 13:41:33][INFO] global_step=102712, episodic_env_return=35.0\n",
      "[2023-09-13 13:41:34][INFO] global_step=102720, episodic_reward_predictor_return=-1.6224875450134277\n",
      "[2023-09-13 13:41:34][INFO] global_step=102720, episodic_env_return=17.0\n",
      "[2023-09-13 13:41:34][INFO] global_step=102720, episodic_reward_predictor_return=-0.14774279296398163\n",
      "[2023-09-13 13:41:34][INFO] global_step=102720, episodic_env_return=81.0\n",
      "[2023-09-13 13:41:34][INFO] global_step=102744, episodic_reward_predictor_return=-0.3608679175376892\n",
      "[2023-09-13 13:41:34][INFO] global_step=102744, episodic_env_return=76.0\n",
      "[2023-09-13 13:41:34][INFO] global_step=102760, episodic_reward_predictor_return=-1.9024189710617065\n",
      "[2023-09-13 13:41:34][INFO] global_step=102760, episodic_env_return=-57.0\n",
      "[2023-09-13 13:41:35][INFO] global_step=102832, episodic_reward_predictor_return=0.011137495748698711\n",
      "[2023-09-13 13:41:35][INFO] global_step=102832, episodic_env_return=92.0\n",
      "[2023-09-13 13:41:37][INFO] global_step=102896, episodic_reward_predictor_return=-0.2850997745990753\n",
      "[2023-09-13 13:41:37][INFO] global_step=102896, episodic_env_return=42.0\n",
      "[2023-09-13 13:41:37][INFO] global_step=102928, episodic_reward_predictor_return=-0.4248168468475342\n",
      "[2023-09-13 13:41:37][INFO] global_step=102928, episodic_env_return=75.0\n",
      "[2023-09-13 13:41:38][INFO] global_step=102968, episodic_reward_predictor_return=0.032001037150621414\n",
      "[2023-09-13 13:41:38][INFO] global_step=102968, episodic_env_return=92.0\n",
      "[2023-09-13 13:41:40][INFO] global_step=103088, episodic_reward_predictor_return=-0.4817264974117279\n",
      "[2023-09-13 13:41:40][INFO] global_step=103088, episodic_env_return=55.0\n",
      "[2023-09-13 13:41:42][INFO] global_step=103248, episodic_reward_predictor_return=-0.4108322262763977\n",
      "[2023-09-13 13:41:42][INFO] global_step=103248, episodic_env_return=66.0\n",
      "[2023-09-13 13:41:43][INFO] global_step=103264, episodic_reward_predictor_return=-0.0596373975276947\n",
      "[2023-09-13 13:41:43][INFO] global_step=103264, episodic_env_return=79.0\n",
      "[2023-09-13 13:41:45][INFO] global_step=103392, episodic_reward_predictor_return=-0.2801205515861511\n",
      "[2023-09-13 13:41:45][INFO] global_step=103392, episodic_env_return=28.0\n",
      "[2023-09-13 13:41:45][INFO] global_step=103400, episodic_reward_predictor_return=-0.2790406048297882\n",
      "[2023-09-13 13:41:45][INFO] global_step=103400, episodic_env_return=82.0\n",
      "[2023-09-13 13:41:46][INFO] global_step=103424, episodic_reward_predictor_return=-0.21797090768814087\n",
      "[2023-09-13 13:41:46][INFO] global_step=103424, episodic_env_return=81.0\n",
      "[2023-09-13 13:41:46][INFO] global_step=103432, episodic_reward_predictor_return=-1.5139241218566895\n",
      "[2023-09-13 13:41:46][INFO] global_step=103432, episodic_env_return=11.0\n",
      "[2023-09-13 13:41:46][INFO] global_step=103472, episodic_reward_predictor_return=-1.4162949323654175\n",
      "[2023-09-13 13:41:46][INFO] global_step=103472, episodic_env_return=-10.0\n",
      "[2023-09-13 13:41:47][INFO] global_step=103480, episodic_reward_predictor_return=-0.029940946027636528\n",
      "[2023-09-13 13:41:47][INFO] global_step=103480, episodic_env_return=95.0\n",
      "[2023-09-13 13:41:47][INFO] global_step=103496, episodic_reward_predictor_return=0.04349032789468765\n",
      "[2023-09-13 13:41:47][INFO] global_step=103496, episodic_env_return=88.0\n",
      "[2023-09-13 13:41:47][INFO] global_step=103520, episodic_reward_predictor_return=-0.1417076736688614\n",
      "[2023-09-13 13:41:47][INFO] global_step=103520, episodic_env_return=86.0\n",
      "[2023-09-13 13:41:47][INFO] global_step=103528, episodic_reward_predictor_return=-0.5553504824638367\n",
      "[2023-09-13 13:41:47][INFO] global_step=103528, episodic_env_return=-38.0\n",
      "[2023-09-13 13:41:48][INFO] global_step=103544, episodic_reward_predictor_return=-0.016307231038808823\n",
      "[2023-09-13 13:41:48][INFO] global_step=103544, episodic_env_return=92.0\n",
      "[2023-09-13 13:41:48][INFO] global_step=103560, episodic_reward_predictor_return=-0.2647065222263336\n",
      "[2023-09-13 13:41:48][INFO] global_step=103560, episodic_env_return=91.0\n",
      "[2023-09-13 13:41:50][INFO] global_step=103696, episodic_reward_predictor_return=-0.48693546652793884\n",
      "[2023-09-13 13:41:50][INFO] global_step=103696, episodic_env_return=62.0\n",
      "[2023-09-13 13:41:51][INFO] global_step=103744, episodic_reward_predictor_return=-0.24121031165122986\n",
      "[2023-09-13 13:41:51][INFO] global_step=103744, episodic_env_return=73.0\n",
      "[2023-09-13 13:41:51][INFO] global_step=103744, episodic_reward_predictor_return=-0.26744717359542847\n",
      "[2023-09-13 13:41:51][INFO] global_step=103744, episodic_env_return=76.0\n",
      "[2023-09-13 13:41:52][INFO] global_step=103768, episodic_reward_predictor_return=-0.3600471615791321\n",
      "[2023-09-13 13:41:52][INFO] global_step=103768, episodic_env_return=62.0\n",
      "[2023-09-13 13:41:56][INFO] global_step=104016, episodic_reward_predictor_return=-1.1408286094665527\n",
      "[2023-09-13 13:41:56][INFO] global_step=104016, episodic_env_return=29.0\n",
      "[2023-09-13 13:41:56][INFO] global_step=104032, episodic_reward_predictor_return=-0.43176642060279846\n",
      "[2023-09-13 13:41:56][INFO] global_step=104032, episodic_env_return=54.0\n",
      "[2023-09-13 13:41:56][INFO] global_step=104032, episodic_reward_predictor_return=-0.43852826952934265\n",
      "[2023-09-13 13:41:56][INFO] global_step=104032, episodic_env_return=63.0\n",
      "[2023-09-13 13:41:56][INFO] global_step=104040, episodic_reward_predictor_return=-0.43638452887535095\n",
      "[2023-09-13 13:41:56][INFO] global_step=104040, episodic_env_return=64.0\n",
      "[2023-09-13 13:41:58][INFO] global_step=104136, episodic_reward_predictor_return=-0.3300926089286804\n",
      "[2023-09-13 13:41:58][INFO] global_step=104136, episodic_env_return=88.0\n",
      "[2023-09-13 13:41:59][INFO] global_step=104192, episodic_reward_predictor_return=-2.464317798614502\n",
      "[2023-09-13 13:41:59][INFO] global_step=104192, episodic_env_return=-124.0\n",
      "[2023-09-13 13:41:59][INFO] global_step=104200, episodic_reward_predictor_return=-0.8292414546012878\n",
      "[2023-09-13 13:41:59][INFO] global_step=104200, episodic_env_return=2.0\n",
      "[2023-09-13 13:42:01][INFO] global_step=104336, episodic_reward_predictor_return=-0.859323263168335\n",
      "[2023-09-13 13:42:01][INFO] global_step=104336, episodic_env_return=7.0\n",
      "[2023-09-13 13:42:02][INFO] global_step=104360, episodic_reward_predictor_return=-0.0787048265337944\n",
      "[2023-09-13 13:42:02][INFO] global_step=104360, episodic_env_return=73.0\n",
      "[2023-09-13 13:42:02][INFO] global_step=104400, episodic_reward_predictor_return=-0.559613823890686\n",
      "[2023-09-13 13:42:02][INFO] global_step=104400, episodic_env_return=56.0\n",
      "[2023-09-13 13:42:03][INFO] global_step=104432, episodic_reward_predictor_return=-0.042140331119298935\n",
      "[2023-09-13 13:42:03][INFO] global_step=104432, episodic_env_return=92.0\n",
      "[2023-09-13 13:42:03][INFO] global_step=104448, episodic_reward_predictor_return=-5.548707008361816\n",
      "[2023-09-13 13:42:03][INFO] global_step=104448, episodic_env_return=-395.0\n",
      "[2023-09-13 13:42:03][INFO] Current Mean Episodic Return = -0.7150706052780151\n",
      "[2023-09-13 13:42:03][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_104448`...\n",
      "[2023-09-13 13:42:03][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_104448`!\n",
      "[2023-09-13 13:42:06][INFO] SPS: 24\n",
      "[2023-09-13 13:42:07][INFO] global_step=104504, episodic_reward_predictor_return=-0.15523281693458557\n",
      "[2023-09-13 13:42:07][INFO] global_step=104504, episodic_env_return=88.0\n",
      "[2023-09-13 13:42:08][INFO] global_step=104568, episodic_reward_predictor_return=-1.3800781965255737\n",
      "[2023-09-13 13:42:08][INFO] global_step=104568, episodic_env_return=22.0\n",
      "[2023-09-13 13:42:10][INFO] global_step=104672, episodic_reward_predictor_return=-1.8459556102752686\n",
      "[2023-09-13 13:42:10][INFO] global_step=104672, episodic_env_return=1.0\n",
      "[2023-09-13 13:42:10][INFO] global_step=104688, episodic_reward_predictor_return=-0.5949670076370239\n",
      "[2023-09-13 13:42:10][INFO] global_step=104688, episodic_env_return=69.0\n",
      "[2023-09-13 13:42:10][INFO] global_step=104720, episodic_reward_predictor_return=-0.43398892879486084\n",
      "[2023-09-13 13:42:10][INFO] global_step=104720, episodic_env_return=74.0\n",
      "[2023-09-13 13:42:11][INFO] global_step=104768, episodic_reward_predictor_return=-1.1467496156692505\n",
      "[2023-09-13 13:42:11][INFO] global_step=104768, episodic_env_return=15.0\n",
      "[2023-09-13 13:42:11][INFO] global_step=104776, episodic_reward_predictor_return=-0.18462882936000824\n",
      "[2023-09-13 13:42:11][INFO] global_step=104776, episodic_env_return=90.0\n",
      "[2023-09-13 13:42:12][INFO] global_step=104800, episodic_reward_predictor_return=-0.29410916566848755\n",
      "[2023-09-13 13:42:12][INFO] global_step=104800, episodic_env_return=52.0\n",
      "[2023-09-13 13:42:12][INFO] global_step=104840, episodic_reward_predictor_return=-1.350443720817566\n",
      "[2023-09-13 13:42:12][INFO] global_step=104840, episodic_env_return=28.0\n",
      "[2023-09-13 13:42:13][INFO] global_step=104848, episodic_reward_predictor_return=-0.7179383635520935\n",
      "[2023-09-13 13:42:13][INFO] global_step=104848, episodic_env_return=66.0\n",
      "[2023-09-13 13:42:14][INFO] global_step=104912, episodic_reward_predictor_return=-0.11907145380973816\n",
      "[2023-09-13 13:42:14][INFO] global_step=104912, episodic_env_return=77.0\n",
      "[2023-09-13 13:42:14][INFO] global_step=104936, episodic_reward_predictor_return=-0.21357515454292297\n",
      "[2023-09-13 13:42:14][INFO] global_step=104936, episodic_env_return=89.0\n",
      "[2023-09-13 13:42:15][INFO] global_step=104968, episodic_reward_predictor_return=-0.5722203254699707\n",
      "[2023-09-13 13:42:15][INFO] global_step=104968, episodic_env_return=80.0\n",
      "[2023-09-13 13:42:15][INFO] global_step=104976, episodic_reward_predictor_return=-0.272154837846756\n",
      "[2023-09-13 13:42:15][INFO] global_step=104976, episodic_env_return=75.0\n",
      "[2023-09-13 13:42:18][INFO] global_step=105144, episodic_reward_predictor_return=-0.9096365571022034\n",
      "[2023-09-13 13:42:18][INFO] global_step=105144, episodic_env_return=-48.0\n",
      "[2023-09-13 13:42:18][INFO] global_step=105160, episodic_reward_predictor_return=-0.10052046924829483\n",
      "[2023-09-13 13:42:18][INFO] global_step=105160, episodic_env_return=72.0\n",
      "[2023-09-13 13:42:18][INFO] global_step=105168, episodic_reward_predictor_return=-0.36666131019592285\n",
      "[2023-09-13 13:42:18][INFO] global_step=105168, episodic_env_return=77.0\n",
      "[2023-09-13 13:42:19][INFO] global_step=105240, episodic_reward_predictor_return=-0.1511792242527008\n",
      "[2023-09-13 13:42:19][INFO] global_step=105240, episodic_env_return=47.0\n",
      "[2023-09-13 13:42:19][INFO] global_step=105240, episodic_reward_predictor_return=-0.3385670483112335\n",
      "[2023-09-13 13:42:19][INFO] global_step=105240, episodic_env_return=63.0\n",
      "[2023-09-13 13:42:19][INFO] global_step=105248, episodic_reward_predictor_return=-0.30402907729148865\n",
      "[2023-09-13 13:42:19][INFO] global_step=105248, episodic_env_return=27.0\n",
      "[2023-09-13 13:42:19][INFO] global_step=105256, episodic_reward_predictor_return=-0.10059937834739685\n",
      "[2023-09-13 13:42:19][INFO] global_step=105256, episodic_env_return=90.0\n",
      "[2023-09-13 13:42:20][INFO] global_step=105296, episodic_reward_predictor_return=-0.46769025921821594\n",
      "[2023-09-13 13:42:20][INFO] global_step=105296, episodic_env_return=8.0\n",
      "[2023-09-13 13:42:21][INFO] global_step=105344, episodic_reward_predictor_return=-0.030004598200321198\n",
      "[2023-09-13 13:42:21][INFO] global_step=105344, episodic_env_return=76.0\n",
      "[2023-09-13 13:42:21][INFO] global_step=105344, episodic_reward_predictor_return=0.045149728655815125\n",
      "[2023-09-13 13:42:21][INFO] global_step=105344, episodic_env_return=89.0\n",
      "[2023-09-13 13:42:22][INFO] global_step=105416, episodic_reward_predictor_return=-0.27226027846336365\n",
      "[2023-09-13 13:42:22][INFO] global_step=105416, episodic_env_return=92.0\n",
      "[2023-09-13 13:42:22][INFO] global_step=105416, episodic_reward_predictor_return=-0.30203622579574585\n",
      "[2023-09-13 13:42:22][INFO] global_step=105416, episodic_env_return=79.0\n",
      "[2023-09-13 13:42:22][INFO] global_step=105432, episodic_reward_predictor_return=-0.09609042853116989\n",
      "[2023-09-13 13:42:22][INFO] global_step=105432, episodic_env_return=67.0\n",
      "[2023-09-13 13:42:24][INFO] global_step=105536, episodic_reward_predictor_return=-0.11614830791950226\n",
      "[2023-09-13 13:42:24][INFO] global_step=105536, episodic_env_return=66.0\n",
      "[2023-09-13 13:42:24][INFO] global_step=105544, episodic_reward_predictor_return=-0.32411399483680725\n",
      "[2023-09-13 13:42:24][INFO] global_step=105544, episodic_env_return=65.0\n",
      "[2023-09-13 13:42:25][INFO] global_step=105584, episodic_reward_predictor_return=-0.2046406865119934\n",
      "[2023-09-13 13:42:25][INFO] global_step=105584, episodic_env_return=82.0\n",
      "[2023-09-13 13:42:25][INFO] global_step=105584, episodic_reward_predictor_return=0.11138760298490524\n",
      "[2023-09-13 13:42:25][INFO] global_step=105584, episodic_env_return=95.0\n",
      "[2023-09-13 13:42:25][INFO] global_step=105592, episodic_reward_predictor_return=-0.1489483118057251\n",
      "[2023-09-13 13:42:25][INFO] global_step=105592, episodic_env_return=79.0\n",
      "[2023-09-13 13:42:27][INFO] global_step=105672, episodic_reward_predictor_return=-0.028649110347032547\n",
      "[2023-09-13 13:42:27][INFO] global_step=105672, episodic_env_return=90.0\n",
      "[2023-09-13 13:42:27][INFO] global_step=105680, episodic_reward_predictor_return=-0.20990687608718872\n",
      "[2023-09-13 13:42:27][INFO] global_step=105680, episodic_env_return=84.0\n",
      "[2023-09-13 13:42:27][INFO] global_step=105688, episodic_reward_predictor_return=-0.254332035779953\n",
      "[2023-09-13 13:42:27][INFO] global_step=105688, episodic_env_return=67.0\n",
      "[2023-09-13 13:42:27][INFO] global_step=105720, episodic_reward_predictor_return=-0.2155170440673828\n",
      "[2023-09-13 13:42:27][INFO] global_step=105720, episodic_env_return=54.0\n",
      "[2023-09-13 13:42:28][INFO] global_step=105752, episodic_reward_predictor_return=-0.7687830924987793\n",
      "[2023-09-13 13:42:28][INFO] global_step=105752, episodic_env_return=32.0\n",
      "[2023-09-13 13:42:28][INFO] global_step=105768, episodic_reward_predictor_return=-0.12739253044128418\n",
      "[2023-09-13 13:42:28][INFO] global_step=105768, episodic_env_return=78.0\n",
      "[2023-09-13 13:42:29][INFO] global_step=105784, episodic_reward_predictor_return=-0.20542269945144653\n",
      "[2023-09-13 13:42:29][INFO] global_step=105784, episodic_env_return=88.0\n",
      "[2023-09-13 13:42:30][INFO] global_step=105872, episodic_reward_predictor_return=-0.25591111183166504\n",
      "[2023-09-13 13:42:30][INFO] global_step=105872, episodic_env_return=82.0\n",
      "[2023-09-13 13:42:31][INFO] global_step=105944, episodic_reward_predictor_return=-0.25247421860694885\n",
      "[2023-09-13 13:42:31][INFO] global_step=105944, episodic_env_return=57.0\n",
      "[2023-09-13 13:42:32][INFO] global_step=105984, episodic_reward_predictor_return=-0.26714053750038147\n",
      "[2023-09-13 13:42:32][INFO] global_step=105984, episodic_env_return=64.0\n",
      "[2023-09-13 13:42:32][INFO] global_step=106000, episodic_reward_predictor_return=-0.6177471280097961\n",
      "[2023-09-13 13:42:32][INFO] global_step=106000, episodic_env_return=60.0\n",
      "[2023-09-13 13:42:34][INFO] global_step=106088, episodic_reward_predictor_return=-0.12289921194314957\n",
      "[2023-09-13 13:42:34][INFO] global_step=106088, episodic_env_return=90.0\n",
      "[2023-09-13 13:42:34][INFO] global_step=106112, episodic_reward_predictor_return=-0.5636520981788635\n",
      "[2023-09-13 13:42:34][INFO] global_step=106112, episodic_env_return=46.0\n",
      "[2023-09-13 13:42:35][INFO] global_step=106184, episodic_reward_predictor_return=-0.323289155960083\n",
      "[2023-09-13 13:42:35][INFO] global_step=106184, episodic_env_return=89.0\n",
      "[2023-09-13 13:42:36][INFO] global_step=106240, episodic_reward_predictor_return=-0.10243609547615051\n",
      "[2023-09-13 13:42:36][INFO] global_step=106240, episodic_env_return=94.0\n",
      "[2023-09-13 13:42:37][INFO] global_step=106304, episodic_reward_predictor_return=-0.22263453900814056\n",
      "[2023-09-13 13:42:37][INFO] global_step=106304, episodic_env_return=24.0\n",
      "[2023-09-13 13:42:37][INFO] global_step=106304, episodic_reward_predictor_return=-0.033222395926713943\n",
      "[2023-09-13 13:42:37][INFO] global_step=106304, episodic_env_return=37.0\n",
      "[2023-09-13 13:42:38][INFO] global_step=106344, episodic_reward_predictor_return=-0.237702414393425\n",
      "[2023-09-13 13:42:38][INFO] global_step=106344, episodic_env_return=88.0\n",
      "[2023-09-13 13:42:38][INFO] global_step=106352, episodic_reward_predictor_return=0.01417949702590704\n",
      "[2023-09-13 13:42:38][INFO] global_step=106352, episodic_env_return=20.0\n",
      "[2023-09-13 13:42:39][INFO] global_step=106424, episodic_reward_predictor_return=-0.6501484513282776\n",
      "[2023-09-13 13:42:39][INFO] global_step=106424, episodic_env_return=57.0\n",
      "[2023-09-13 13:42:40][INFO] global_step=106488, episodic_reward_predictor_return=-1.9111300706863403\n",
      "[2023-09-13 13:42:40][INFO] global_step=106488, episodic_env_return=-131.0\n",
      "[2023-09-13 13:42:41][INFO] global_step=106496, episodic_reward_predictor_return=-0.5759948492050171\n",
      "[2023-09-13 13:42:41][INFO] global_step=106496, episodic_env_return=82.0\n",
      "[2023-09-13 13:42:41][INFO] Current Mean Episodic Return = -0.3942575752735138\n",
      "[2023-09-13 13:42:41][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_106496`...\n",
      "[2023-09-13 13:42:41][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_106496`!\n",
      "[2023-09-13 13:42:43][INFO] SPS: 24\n",
      "[2023-09-13 13:42:44][INFO] global_step=106504, episodic_reward_predictor_return=-0.08040539920330048\n",
      "[2023-09-13 13:42:44][INFO] global_step=106504, episodic_env_return=71.0\n",
      "[2023-09-13 13:42:45][INFO] global_step=106576, episodic_reward_predictor_return=0.038960039615631104\n",
      "[2023-09-13 13:42:45][INFO] global_step=106576, episodic_env_return=91.0\n",
      "[2023-09-13 13:42:45][INFO] global_step=106600, episodic_reward_predictor_return=-0.741569459438324\n",
      "[2023-09-13 13:42:45][INFO] global_step=106600, episodic_env_return=59.0\n",
      "[2023-09-13 13:42:46][INFO] global_step=106648, episodic_reward_predictor_return=0.22966018319129944\n",
      "[2023-09-13 13:42:46][INFO] global_step=106648, episodic_env_return=92.0\n",
      "[2023-09-13 13:42:46][INFO] global_step=106680, episodic_reward_predictor_return=-0.7579459547996521\n",
      "[2023-09-13 13:42:46][INFO] global_step=106680, episodic_env_return=-6.0\n",
      "[2023-09-13 13:42:47][INFO] global_step=106712, episodic_reward_predictor_return=-0.21858267486095428\n",
      "[2023-09-13 13:42:47][INFO] global_step=106712, episodic_env_return=68.0\n",
      "[2023-09-13 13:42:49][INFO] global_step=106832, episodic_reward_predictor_return=-0.5904973149299622\n",
      "[2023-09-13 13:42:49][INFO] global_step=106832, episodic_env_return=31.0\n",
      "[2023-09-13 13:42:49][INFO] global_step=106840, episodic_reward_predictor_return=0.17462289333343506\n",
      "[2023-09-13 13:42:49][INFO] global_step=106840, episodic_env_return=85.0\n",
      "[2023-09-13 13:42:49][INFO] global_step=106856, episodic_reward_predictor_return=-0.08310253173112869\n",
      "[2023-09-13 13:42:49][INFO] global_step=106856, episodic_env_return=64.0\n",
      "[2023-09-13 13:42:50][INFO] global_step=106880, episodic_reward_predictor_return=-2.2991397380828857\n",
      "[2023-09-13 13:42:50][INFO] global_step=106880, episodic_env_return=-36.0\n",
      "[2023-09-13 13:42:50][INFO] global_step=106896, episodic_reward_predictor_return=-0.8042519092559814\n",
      "[2023-09-13 13:42:50][INFO] global_step=106896, episodic_env_return=32.0\n",
      "[2023-09-13 13:42:50][INFO] global_step=106904, episodic_reward_predictor_return=-0.08151955157518387\n",
      "[2023-09-13 13:42:50][INFO] global_step=106904, episodic_env_return=73.0\n",
      "[2023-09-13 13:42:50][INFO] global_step=106920, episodic_reward_predictor_return=0.11970039457082748\n",
      "[2023-09-13 13:42:50][INFO] global_step=106920, episodic_env_return=90.0\n",
      "[2023-09-13 13:42:50][INFO] global_step=106920, episodic_reward_predictor_return=-0.9711785912513733\n",
      "[2023-09-13 13:42:50][INFO] global_step=106920, episodic_env_return=39.0\n",
      "[2023-09-13 13:42:51][INFO] global_step=106960, episodic_reward_predictor_return=0.041948456317186356\n",
      "[2023-09-13 13:42:51][INFO] global_step=106960, episodic_env_return=86.0\n",
      "[2023-09-13 13:42:51][INFO] global_step=106968, episodic_reward_predictor_return=0.13057056069374084\n",
      "[2023-09-13 13:42:51][INFO] global_step=106968, episodic_env_return=56.0\n",
      "[2023-09-13 13:42:52][INFO] global_step=107000, episodic_reward_predictor_return=-0.10163678228855133\n",
      "[2023-09-13 13:42:52][INFO] global_step=107000, episodic_env_return=91.0\n",
      "[2023-09-13 13:42:52][INFO] global_step=107000, episodic_reward_predictor_return=-0.32529741525650024\n",
      "[2023-09-13 13:42:52][INFO] global_step=107000, episodic_env_return=86.0\n",
      "[2023-09-13 13:42:52][INFO] global_step=107032, episodic_reward_predictor_return=-0.21464505791664124\n",
      "[2023-09-13 13:42:52][INFO] global_step=107032, episodic_env_return=87.0\n",
      "[2023-09-13 13:42:53][INFO] global_step=107080, episodic_reward_predictor_return=-0.0689350888133049\n",
      "[2023-09-13 13:42:53][INFO] global_step=107080, episodic_env_return=73.0\n",
      "[2023-09-13 13:42:53][INFO] global_step=107096, episodic_reward_predictor_return=-0.07957307994365692\n",
      "[2023-09-13 13:42:53][INFO] global_step=107096, episodic_env_return=76.0\n",
      "[2023-09-13 13:42:54][INFO] global_step=107112, episodic_reward_predictor_return=0.024940527975559235\n",
      "[2023-09-13 13:42:54][INFO] global_step=107112, episodic_env_return=91.0\n",
      "[2023-09-13 13:42:54][INFO] global_step=107112, episodic_reward_predictor_return=0.3518487811088562\n",
      "[2023-09-13 13:42:54][INFO] global_step=107112, episodic_env_return=82.0\n",
      "[2023-09-13 13:42:54][INFO] global_step=107128, episodic_reward_predictor_return=-0.5496076345443726\n",
      "[2023-09-13 13:42:54][INFO] global_step=107128, episodic_env_return=81.0\n",
      "[2023-09-13 13:42:55][INFO] global_step=107192, episodic_reward_predictor_return=0.023540286347270012\n",
      "[2023-09-13 13:42:55][INFO] global_step=107192, episodic_env_return=87.0\n",
      "[2023-09-13 13:42:55][INFO] global_step=107208, episodic_reward_predictor_return=-0.36886468529701233\n",
      "[2023-09-13 13:42:55][INFO] global_step=107208, episodic_env_return=89.0\n",
      "[2023-09-13 13:42:56][INFO] global_step=107256, episodic_reward_predictor_return=0.002473672851920128\n",
      "[2023-09-13 13:42:56][INFO] global_step=107256, episodic_env_return=69.0\n",
      "[2023-09-13 13:42:57][INFO] global_step=107296, episodic_reward_predictor_return=-0.7284120917320251\n",
      "[2023-09-13 13:42:57][INFO] global_step=107296, episodic_env_return=42.0\n",
      "[2023-09-13 13:42:57][INFO] global_step=107296, episodic_reward_predictor_return=-0.24582728743553162\n",
      "[2023-09-13 13:42:57][INFO] global_step=107296, episodic_env_return=73.0\n",
      "[2023-09-13 13:42:57][INFO] global_step=107320, episodic_reward_predictor_return=-0.3526029586791992\n",
      "[2023-09-13 13:42:57][INFO] global_step=107320, episodic_env_return=85.0\n",
      "[2023-09-13 13:42:58][INFO] global_step=107352, episodic_reward_predictor_return=-0.054045047610998154\n",
      "[2023-09-13 13:42:58][INFO] global_step=107352, episodic_env_return=89.0\n",
      "[2023-09-13 13:42:58][INFO] global_step=107384, episodic_reward_predictor_return=-0.2793865501880646\n",
      "[2023-09-13 13:42:58][INFO] global_step=107384, episodic_env_return=65.0\n",
      "[2023-09-13 13:42:58][INFO] global_step=107384, episodic_reward_predictor_return=-0.4230705499649048\n",
      "[2023-09-13 13:42:58][INFO] global_step=107384, episodic_env_return=79.0\n",
      "[2023-09-13 13:42:59][INFO] global_step=107424, episodic_reward_predictor_return=-0.24359282851219177\n",
      "[2023-09-13 13:42:59][INFO] global_step=107424, episodic_env_return=48.0\n",
      "[2023-09-13 13:42:59][INFO] global_step=107456, episodic_reward_predictor_return=-0.11218708753585815\n",
      "[2023-09-13 13:42:59][INFO] global_step=107456, episodic_env_return=76.0\n",
      "[2023-09-13 13:43:00][INFO] global_step=107480, episodic_reward_predictor_return=-0.28423482179641724\n",
      "[2023-09-13 13:43:00][INFO] global_step=107480, episodic_env_return=47.0\n",
      "[2023-09-13 13:43:00][INFO] global_step=107496, episodic_reward_predictor_return=0.1549665331840515\n",
      "[2023-09-13 13:43:00][INFO] global_step=107496, episodic_env_return=76.0\n",
      "[2023-09-13 13:43:01][INFO] global_step=107560, episodic_reward_predictor_return=-0.39882758259773254\n",
      "[2023-09-13 13:43:01][INFO] global_step=107560, episodic_env_return=75.0\n",
      "[2023-09-13 13:43:02][INFO] global_step=107584, episodic_reward_predictor_return=-0.007509202696382999\n",
      "[2023-09-13 13:43:02][INFO] global_step=107584, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:02][INFO] global_step=107616, episodic_reward_predictor_return=-0.46113210916519165\n",
      "[2023-09-13 13:43:02][INFO] global_step=107616, episodic_env_return=77.0\n",
      "[2023-09-13 13:43:03][INFO] global_step=107688, episodic_reward_predictor_return=-0.35917484760284424\n",
      "[2023-09-13 13:43:03][INFO] global_step=107688, episodic_env_return=85.0\n",
      "[2023-09-13 13:43:03][INFO] global_step=107696, episodic_reward_predictor_return=-0.4266259968280792\n",
      "[2023-09-13 13:43:03][INFO] global_step=107696, episodic_env_return=44.0\n",
      "[2023-09-13 13:43:04][INFO] global_step=107752, episodic_reward_predictor_return=-0.5246365070343018\n",
      "[2023-09-13 13:43:04][INFO] global_step=107752, episodic_env_return=62.0\n",
      "[2023-09-13 13:43:05][INFO] global_step=107776, episodic_reward_predictor_return=-0.10529657453298569\n",
      "[2023-09-13 13:43:05][INFO] global_step=107776, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:06][INFO] global_step=107816, episodic_reward_predictor_return=-0.5402706265449524\n",
      "[2023-09-13 13:43:06][INFO] global_step=107816, episodic_env_return=32.0\n",
      "[2023-09-13 13:43:07][INFO] global_step=107872, episodic_reward_predictor_return=-0.17809121310710907\n",
      "[2023-09-13 13:43:07][INFO] global_step=107872, episodic_env_return=86.0\n",
      "[2023-09-13 13:43:07][INFO] global_step=107872, episodic_reward_predictor_return=-0.4093033969402313\n",
      "[2023-09-13 13:43:07][INFO] global_step=107872, episodic_env_return=64.0\n",
      "[2023-09-13 13:43:08][INFO] global_step=107952, episodic_reward_predictor_return=-0.12552030384540558\n",
      "[2023-09-13 13:43:08][INFO] global_step=107952, episodic_env_return=79.0\n",
      "[2023-09-13 13:43:08][INFO] global_step=107960, episodic_reward_predictor_return=-0.5088788866996765\n",
      "[2023-09-13 13:43:08][INFO] global_step=107960, episodic_env_return=9.0\n",
      "[2023-09-13 13:43:08][INFO] global_step=107960, episodic_reward_predictor_return=-0.5619038939476013\n",
      "[2023-09-13 13:43:08][INFO] global_step=107960, episodic_env_return=54.0\n",
      "[2023-09-13 13:43:08][INFO] global_step=107976, episodic_reward_predictor_return=-0.6420376896858215\n",
      "[2023-09-13 13:43:08][INFO] global_step=107976, episodic_env_return=66.0\n",
      "[2023-09-13 13:43:09][INFO] global_step=108008, episodic_reward_predictor_return=-0.06689918041229248\n",
      "[2023-09-13 13:43:09][INFO] global_step=108008, episodic_env_return=95.0\n",
      "[2023-09-13 13:43:09][INFO] global_step=108032, episodic_reward_predictor_return=-0.8340569734573364\n",
      "[2023-09-13 13:43:09][INFO] global_step=108032, episodic_env_return=19.0\n",
      "[2023-09-13 13:43:11][INFO] global_step=108128, episodic_reward_predictor_return=-0.37017250061035156\n",
      "[2023-09-13 13:43:11][INFO] global_step=108128, episodic_env_return=64.0\n",
      "[2023-09-13 13:43:12][INFO] global_step=108168, episodic_reward_predictor_return=-0.4580896496772766\n",
      "[2023-09-13 13:43:12][INFO] global_step=108168, episodic_env_return=52.0\n",
      "[2023-09-13 13:43:13][INFO] global_step=108216, episodic_reward_predictor_return=-0.1643427610397339\n",
      "[2023-09-13 13:43:13][INFO] global_step=108216, episodic_env_return=69.0\n",
      "[2023-09-13 13:43:13][INFO] global_step=108232, episodic_reward_predictor_return=-0.2325677126646042\n",
      "[2023-09-13 13:43:13][INFO] global_step=108232, episodic_env_return=88.0\n",
      "[2023-09-13 13:43:13][INFO] global_step=108264, episodic_reward_predictor_return=-0.8189939856529236\n",
      "[2023-09-13 13:43:13][INFO] global_step=108264, episodic_env_return=42.0\n",
      "[2023-09-13 13:43:13][INFO] global_step=108272, episodic_reward_predictor_return=0.17078617215156555\n",
      "[2023-09-13 13:43:13][INFO] global_step=108272, episodic_env_return=61.0\n",
      "[2023-09-13 13:43:15][INFO] global_step=108360, episodic_reward_predictor_return=-0.2292497456073761\n",
      "[2023-09-13 13:43:15][INFO] global_step=108360, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:16][INFO] global_step=108408, episodic_reward_predictor_return=-0.17633461952209473\n",
      "[2023-09-13 13:43:16][INFO] global_step=108408, episodic_env_return=74.0\n",
      "[2023-09-13 13:43:16][INFO] global_step=108432, episodic_reward_predictor_return=-0.16225981712341309\n",
      "[2023-09-13 13:43:16][INFO] global_step=108432, episodic_env_return=80.0\n",
      "[2023-09-13 13:43:16][INFO] global_step=108432, episodic_reward_predictor_return=0.0319630391895771\n",
      "[2023-09-13 13:43:16][INFO] global_step=108432, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:16][INFO] global_step=108440, episodic_reward_predictor_return=-0.4720724821090698\n",
      "[2023-09-13 13:43:16][INFO] global_step=108440, episodic_env_return=40.0\n",
      "[2023-09-13 13:43:18][INFO] global_step=108520, episodic_reward_predictor_return=0.021992478519678116\n",
      "[2023-09-13 13:43:18][INFO] global_step=108520, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:18][INFO] global_step=108528, episodic_reward_predictor_return=-0.21396498382091522\n",
      "[2023-09-13 13:43:18][INFO] global_step=108528, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:18][INFO] Current Mean Episodic Return = -0.2877326011657715\n",
      "[2023-09-13 13:43:18][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_108544`...\n",
      "[2023-09-13 13:43:18][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_108544`!\n",
      "[2023-09-13 13:43:21][INFO] SPS: 24\n",
      "[2023-09-13 13:43:21][INFO] global_step=108584, episodic_reward_predictor_return=-0.18207448720932007\n",
      "[2023-09-13 13:43:21][INFO] global_step=108584, episodic_env_return=82.0\n",
      "[2023-09-13 13:43:22][INFO] global_step=108592, episodic_reward_predictor_return=0.11272107809782028\n",
      "[2023-09-13 13:43:22][INFO] global_step=108592, episodic_env_return=73.0\n",
      "[2023-09-13 13:43:22][INFO] global_step=108600, episodic_reward_predictor_return=-1.2833787202835083\n",
      "[2023-09-13 13:43:22][INFO] global_step=108600, episodic_env_return=3.0\n",
      "[2023-09-13 13:43:22][INFO] global_step=108624, episodic_reward_predictor_return=-1.015545129776001\n",
      "[2023-09-13 13:43:22][INFO] global_step=108624, episodic_env_return=39.0\n",
      "[2023-09-13 13:43:22][INFO] global_step=108632, episodic_reward_predictor_return=0.043806593865156174\n",
      "[2023-09-13 13:43:22][INFO] global_step=108632, episodic_env_return=8.0\n",
      "[2023-09-13 13:43:22][INFO] global_step=108632, episodic_reward_predictor_return=-0.5094498991966248\n",
      "[2023-09-13 13:43:22][INFO] global_step=108632, episodic_env_return=39.0\n",
      "[2023-09-13 13:43:24][INFO] global_step=108736, episodic_reward_predictor_return=-0.2026943564414978\n",
      "[2023-09-13 13:43:24][INFO] global_step=108736, episodic_env_return=84.0\n",
      "[2023-09-13 13:43:24][INFO] global_step=108768, episodic_reward_predictor_return=-0.2794138193130493\n",
      "[2023-09-13 13:43:24][INFO] global_step=108768, episodic_env_return=73.0\n",
      "[2023-09-13 13:43:25][INFO] global_step=108776, episodic_reward_predictor_return=-0.33673352003097534\n",
      "[2023-09-13 13:43:25][INFO] global_step=108776, episodic_env_return=70.0\n",
      "[2023-09-13 13:43:25][INFO] global_step=108824, episodic_reward_predictor_return=-0.5254058837890625\n",
      "[2023-09-13 13:43:25][INFO] global_step=108824, episodic_env_return=76.0\n",
      "[2023-09-13 13:43:26][INFO] global_step=108848, episodic_reward_predictor_return=-0.3059522807598114\n",
      "[2023-09-13 13:43:26][INFO] global_step=108848, episodic_env_return=69.0\n",
      "[2023-09-13 13:43:27][INFO] global_step=108896, episodic_reward_predictor_return=-0.007280886173248291\n",
      "[2023-09-13 13:43:27][INFO] global_step=108896, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:27][INFO] global_step=108944, episodic_reward_predictor_return=-0.04774300009012222\n",
      "[2023-09-13 13:43:27][INFO] global_step=108944, episodic_env_return=89.0\n",
      "[2023-09-13 13:43:27][INFO] global_step=108944, episodic_reward_predictor_return=-0.06078827753663063\n",
      "[2023-09-13 13:43:27][INFO] global_step=108944, episodic_env_return=95.0\n",
      "[2023-09-13 13:43:28][INFO] global_step=108968, episodic_reward_predictor_return=-0.038669977337121964\n",
      "[2023-09-13 13:43:28][INFO] global_step=108968, episodic_env_return=44.0\n",
      "[2023-09-13 13:43:29][INFO] global_step=109016, episodic_reward_predictor_return=-0.2852952778339386\n",
      "[2023-09-13 13:43:29][INFO] global_step=109016, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:29][INFO] global_step=109040, episodic_reward_predictor_return=0.16837140917778015\n",
      "[2023-09-13 13:43:29][INFO] global_step=109040, episodic_env_return=31.0\n",
      "[2023-09-13 13:43:29][INFO] global_step=109048, episodic_reward_predictor_return=-0.1334465593099594\n",
      "[2023-09-13 13:43:29][INFO] global_step=109048, episodic_env_return=88.0\n",
      "[2023-09-13 13:43:30][INFO] global_step=109088, episodic_reward_predictor_return=-0.10874117165803909\n",
      "[2023-09-13 13:43:30][INFO] global_step=109088, episodic_env_return=57.0\n",
      "[2023-09-13 13:43:30][INFO] global_step=109112, episodic_reward_predictor_return=0.017546534538269043\n",
      "[2023-09-13 13:43:30][INFO] global_step=109112, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:31][INFO] global_step=109152, episodic_reward_predictor_return=-0.26025229692459106\n",
      "[2023-09-13 13:43:31][INFO] global_step=109152, episodic_env_return=44.0\n",
      "[2023-09-13 13:43:31][INFO] global_step=109160, episodic_reward_predictor_return=-1.4950933456420898\n",
      "[2023-09-13 13:43:31][INFO] global_step=109160, episodic_env_return=20.0\n",
      "[2023-09-13 13:43:32][INFO] global_step=109200, episodic_reward_predictor_return=0.08407972753047943\n",
      "[2023-09-13 13:43:32][INFO] global_step=109200, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:32][INFO] global_step=109208, episodic_reward_predictor_return=-0.05724012851715088\n",
      "[2023-09-13 13:43:32][INFO] global_step=109208, episodic_env_return=95.0\n",
      "[2023-09-13 13:43:33][INFO] global_step=109280, episodic_reward_predictor_return=-0.361549973487854\n",
      "[2023-09-13 13:43:33][INFO] global_step=109280, episodic_env_return=72.0\n",
      "[2023-09-13 13:43:33][INFO] global_step=109288, episodic_reward_predictor_return=-0.15856069326400757\n",
      "[2023-09-13 13:43:33][INFO] global_step=109288, episodic_env_return=56.0\n",
      "[2023-09-13 13:43:34][INFO] global_step=109352, episodic_reward_predictor_return=-0.21509888768196106\n",
      "[2023-09-13 13:43:34][INFO] global_step=109352, episodic_env_return=93.0\n",
      "[2023-09-13 13:43:35][INFO] global_step=109392, episodic_reward_predictor_return=-0.4174562990665436\n",
      "[2023-09-13 13:43:35][INFO] global_step=109392, episodic_env_return=71.0\n",
      "[2023-09-13 13:43:36][INFO] global_step=109464, episodic_reward_predictor_return=-0.38765451312065125\n",
      "[2023-09-13 13:43:36][INFO] global_step=109464, episodic_env_return=64.0\n",
      "[2023-09-13 13:43:37][INFO] global_step=109496, episodic_reward_predictor_return=-0.5433033108711243\n",
      "[2023-09-13 13:43:37][INFO] global_step=109496, episodic_env_return=26.0\n",
      "[2023-09-13 13:43:37][INFO] global_step=109496, episodic_reward_predictor_return=-0.15250134468078613\n",
      "[2023-09-13 13:43:37][INFO] global_step=109496, episodic_env_return=88.0\n",
      "[2023-09-13 13:43:37][INFO] global_step=109520, episodic_reward_predictor_return=-0.632960855960846\n",
      "[2023-09-13 13:43:37][INFO] global_step=109520, episodic_env_return=32.0\n",
      "[2023-09-13 13:43:38][INFO] global_step=109568, episodic_reward_predictor_return=-0.1694210320711136\n",
      "[2023-09-13 13:43:38][INFO] global_step=109568, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:38][INFO] global_step=109568, episodic_reward_predictor_return=-0.6289833188056946\n",
      "[2023-09-13 13:43:38][INFO] global_step=109568, episodic_env_return=45.0\n",
      "[2023-09-13 13:43:39][INFO] global_step=109656, episodic_reward_predictor_return=-0.25064271688461304\n",
      "[2023-09-13 13:43:39][INFO] global_step=109656, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:41][INFO] global_step=109768, episodic_reward_predictor_return=-0.04011388123035431\n",
      "[2023-09-13 13:43:41][INFO] global_step=109768, episodic_env_return=39.0\n",
      "[2023-09-13 13:43:42][INFO] global_step=109808, episodic_reward_predictor_return=0.03691119700670242\n",
      "[2023-09-13 13:43:42][INFO] global_step=109808, episodic_env_return=82.0\n",
      "[2023-09-13 13:43:43][INFO] global_step=109856, episodic_reward_predictor_return=-0.0010402121115475893\n",
      "[2023-09-13 13:43:43][INFO] global_step=109856, episodic_env_return=95.0\n",
      "[2023-09-13 13:43:44][INFO] global_step=109944, episodic_reward_predictor_return=-1.0221058130264282\n",
      "[2023-09-13 13:43:44][INFO] global_step=109944, episodic_env_return=40.0\n",
      "[2023-09-13 13:43:45][INFO] global_step=109968, episodic_reward_predictor_return=-0.41552403569221497\n",
      "[2023-09-13 13:43:45][INFO] global_step=109968, episodic_env_return=30.0\n",
      "[2023-09-13 13:43:46][INFO] global_step=110048, episodic_reward_predictor_return=-0.152086541056633\n",
      "[2023-09-13 13:43:46][INFO] global_step=110048, episodic_env_return=77.0\n",
      "[2023-09-13 13:43:46][INFO] global_step=110064, episodic_reward_predictor_return=-0.15693041682243347\n",
      "[2023-09-13 13:43:46][INFO] global_step=110064, episodic_env_return=11.0\n",
      "[2023-09-13 13:43:47][INFO] global_step=110104, episodic_reward_predictor_return=-0.31358078122138977\n",
      "[2023-09-13 13:43:47][INFO] global_step=110104, episodic_env_return=54.0\n",
      "[2023-09-13 13:43:48][INFO] global_step=110136, episodic_reward_predictor_return=-1.904428243637085\n",
      "[2023-09-13 13:43:48][INFO] global_step=110136, episodic_env_return=-31.0\n",
      "[2023-09-13 13:43:48][INFO] global_step=110176, episodic_reward_predictor_return=-0.22292464971542358\n",
      "[2023-09-13 13:43:48][INFO] global_step=110176, episodic_env_return=87.0\n",
      "[2023-09-13 13:43:49][INFO] global_step=110192, episodic_reward_predictor_return=-0.09001874923706055\n",
      "[2023-09-13 13:43:49][INFO] global_step=110192, episodic_env_return=90.0\n",
      "[2023-09-13 13:43:50][INFO] global_step=110296, episodic_reward_predictor_return=-0.13306458294391632\n",
      "[2023-09-13 13:43:50][INFO] global_step=110296, episodic_env_return=52.0\n",
      "[2023-09-13 13:43:51][INFO] global_step=110352, episodic_reward_predictor_return=-1.0976483821868896\n",
      "[2023-09-13 13:43:51][INFO] global_step=110352, episodic_env_return=-22.0\n",
      "[2023-09-13 13:43:52][INFO] global_step=110376, episodic_reward_predictor_return=-0.500873327255249\n",
      "[2023-09-13 13:43:52][INFO] global_step=110376, episodic_env_return=71.0\n",
      "[2023-09-13 13:43:52][INFO] global_step=110384, episodic_reward_predictor_return=-0.18107551336288452\n",
      "[2023-09-13 13:43:52][INFO] global_step=110384, episodic_env_return=75.0\n",
      "[2023-09-13 13:43:52][INFO] global_step=110392, episodic_reward_predictor_return=-0.06621123850345612\n",
      "[2023-09-13 13:43:52][INFO] global_step=110392, episodic_env_return=89.0\n",
      "[2023-09-13 13:43:52][INFO] global_step=110392, episodic_reward_predictor_return=-0.17559349536895752\n",
      "[2023-09-13 13:43:52][INFO] global_step=110392, episodic_env_return=71.0\n",
      "[2023-09-13 13:43:53][INFO] global_step=110464, episodic_reward_predictor_return=-1.1040053367614746\n",
      "[2023-09-13 13:43:53][INFO] global_step=110464, episodic_env_return=29.0\n",
      "[2023-09-13 13:43:54][INFO] global_step=110488, episodic_reward_predictor_return=0.19756540656089783\n",
      "[2023-09-13 13:43:54][INFO] global_step=110488, episodic_env_return=89.0\n",
      "[2023-09-13 13:43:54][INFO] global_step=110520, episodic_reward_predictor_return=-0.6115715503692627\n",
      "[2023-09-13 13:43:54][INFO] global_step=110520, episodic_env_return=27.0\n",
      "[2023-09-13 13:43:54][INFO] global_step=110528, episodic_reward_predictor_return=-0.5013387203216553\n",
      "[2023-09-13 13:43:54][INFO] global_step=110528, episodic_env_return=82.0\n",
      "[2023-09-13 13:43:55][INFO] global_step=110544, episodic_reward_predictor_return=-0.38072723150253296\n",
      "[2023-09-13 13:43:55][INFO] global_step=110544, episodic_env_return=81.0\n",
      "[2023-09-13 13:43:55][INFO] global_step=110560, episodic_reward_predictor_return=-0.10579562187194824\n",
      "[2023-09-13 13:43:55][INFO] global_step=110560, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:55][INFO] Current Mean Episodic Return = -0.3373963534832001\n",
      "[2023-09-13 13:43:55][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_110592`...\n",
      "[2023-09-13 13:43:55][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_110592`!\n",
      "[2023-09-13 13:43:58][INFO] SPS: 25\n",
      "[2023-09-13 13:43:58][INFO] global_step=110600, episodic_reward_predictor_return=0.06148334965109825\n",
      "[2023-09-13 13:43:58][INFO] global_step=110600, episodic_env_return=75.0\n",
      "[2023-09-13 13:43:58][INFO] global_step=110616, episodic_reward_predictor_return=-0.10846821963787079\n",
      "[2023-09-13 13:43:58][INFO] global_step=110616, episodic_env_return=92.0\n",
      "[2023-09-13 13:43:59][INFO] global_step=110632, episodic_reward_predictor_return=-0.9685230255126953\n",
      "[2023-09-13 13:43:59][INFO] global_step=110632, episodic_env_return=61.0\n",
      "[2023-09-13 13:43:59][INFO] global_step=110664, episodic_reward_predictor_return=-0.15777239203453064\n",
      "[2023-09-13 13:43:59][INFO] global_step=110664, episodic_env_return=71.0\n",
      "[2023-09-13 13:43:59][INFO] global_step=110672, episodic_reward_predictor_return=-0.17091643810272217\n",
      "[2023-09-13 13:43:59][INFO] global_step=110672, episodic_env_return=87.0\n",
      "[2023-09-13 13:44:00][INFO] global_step=110696, episodic_reward_predictor_return=-0.11020154505968094\n",
      "[2023-09-13 13:44:00][INFO] global_step=110696, episodic_env_return=75.0\n",
      "[2023-09-13 13:44:01][INFO] global_step=110768, episodic_reward_predictor_return=-0.17124800384044647\n",
      "[2023-09-13 13:44:01][INFO] global_step=110768, episodic_env_return=88.0\n",
      "[2023-09-13 13:44:02][INFO] global_step=110848, episodic_reward_predictor_return=-0.5044416189193726\n",
      "[2023-09-13 13:44:02][INFO] global_step=110848, episodic_env_return=79.0\n",
      "[2023-09-13 13:44:03][INFO] global_step=110912, episodic_reward_predictor_return=-0.5828388929367065\n",
      "[2023-09-13 13:44:03][INFO] global_step=110912, episodic_env_return=37.0\n",
      "[2023-09-13 13:44:03][INFO] global_step=110944, episodic_reward_predictor_return=-0.5479264259338379\n",
      "[2023-09-13 13:44:03][INFO] global_step=110944, episodic_env_return=52.0\n",
      "[2023-09-13 13:44:04][INFO] global_step=110976, episodic_reward_predictor_return=-0.5360032916069031\n",
      "[2023-09-13 13:44:04][INFO] global_step=110976, episodic_env_return=70.0\n",
      "[2023-09-13 13:44:05][INFO] global_step=111008, episodic_reward_predictor_return=-0.11959148943424225\n",
      "[2023-09-13 13:44:05][INFO] global_step=111008, episodic_env_return=40.0\n",
      "[2023-09-13 13:44:05][INFO] global_step=111040, episodic_reward_predictor_return=-0.1294786036014557\n",
      "[2023-09-13 13:44:05][INFO] global_step=111040, episodic_env_return=72.0\n",
      "[2023-09-13 13:44:06][INFO] global_step=111088, episodic_reward_predictor_return=-0.07063227891921997\n",
      "[2023-09-13 13:44:06][INFO] global_step=111088, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:06][INFO] global_step=111104, episodic_reward_predictor_return=-0.0859231948852539\n",
      "[2023-09-13 13:44:06][INFO] global_step=111104, episodic_env_return=93.0\n",
      "[2023-09-13 13:44:06][INFO] global_step=111112, episodic_reward_predictor_return=-0.21570223569869995\n",
      "[2023-09-13 13:44:06][INFO] global_step=111112, episodic_env_return=71.0\n",
      "[2023-09-13 13:44:07][INFO] global_step=111168, episodic_reward_predictor_return=-4.6233320236206055\n",
      "[2023-09-13 13:44:07][INFO] global_step=111168, episodic_env_return=-385.0\n",
      "[2023-09-13 13:44:08][INFO] global_step=111192, episodic_reward_predictor_return=0.02445940114557743\n",
      "[2023-09-13 13:44:08][INFO] global_step=111192, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:09][INFO] global_step=111264, episodic_reward_predictor_return=-0.5126503705978394\n",
      "[2023-09-13 13:44:09][INFO] global_step=111264, episodic_env_return=61.0\n",
      "[2023-09-13 13:44:09][INFO] global_step=111264, episodic_reward_predictor_return=-0.14507326483726501\n",
      "[2023-09-13 13:44:09][INFO] global_step=111264, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:10][INFO] global_step=111320, episodic_reward_predictor_return=-0.12972231209278107\n",
      "[2023-09-13 13:44:10][INFO] global_step=111320, episodic_env_return=72.0\n",
      "[2023-09-13 13:44:10][INFO] global_step=111344, episodic_reward_predictor_return=-1.2078468799591064\n",
      "[2023-09-13 13:44:10][INFO] global_step=111344, episodic_env_return=45.0\n",
      "[2023-09-13 13:44:11][INFO] global_step=111400, episodic_reward_predictor_return=-1.225520133972168\n",
      "[2023-09-13 13:44:11][INFO] global_step=111400, episodic_env_return=-17.0\n",
      "[2023-09-13 13:44:11][INFO] global_step=111416, episodic_reward_predictor_return=-0.1163763701915741\n",
      "[2023-09-13 13:44:11][INFO] global_step=111416, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:13][INFO] global_step=111480, episodic_reward_predictor_return=-0.019637640565633774\n",
      "[2023-09-13 13:44:13][INFO] global_step=111480, episodic_env_return=44.0\n",
      "[2023-09-13 13:44:13][INFO] global_step=111488, episodic_reward_predictor_return=-0.49323534965515137\n",
      "[2023-09-13 13:44:13][INFO] global_step=111488, episodic_env_return=-28.0\n",
      "[2023-09-13 13:44:13][INFO] global_step=111496, episodic_reward_predictor_return=-0.09316806495189667\n",
      "[2023-09-13 13:44:13][INFO] global_step=111496, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:13][INFO] global_step=111504, episodic_reward_predictor_return=-0.14212362468242645\n",
      "[2023-09-13 13:44:13][INFO] global_step=111504, episodic_env_return=88.0\n",
      "[2023-09-13 13:44:14][INFO] global_step=111560, episodic_reward_predictor_return=-0.7755520343780518\n",
      "[2023-09-13 13:44:14][INFO] global_step=111560, episodic_env_return=45.0\n",
      "[2023-09-13 13:44:15][INFO] global_step=111600, episodic_reward_predictor_return=-0.2426554262638092\n",
      "[2023-09-13 13:44:15][INFO] global_step=111600, episodic_env_return=86.0\n",
      "[2023-09-13 13:44:15][INFO] global_step=111608, episodic_reward_predictor_return=-0.2878589630126953\n",
      "[2023-09-13 13:44:15][INFO] global_step=111608, episodic_env_return=88.0\n",
      "[2023-09-13 13:44:15][INFO] global_step=111616, episodic_reward_predictor_return=-0.14024782180786133\n",
      "[2023-09-13 13:44:15][INFO] global_step=111616, episodic_env_return=85.0\n",
      "[2023-09-13 13:44:15][INFO] global_step=111648, episodic_reward_predictor_return=-0.15913702547550201\n",
      "[2023-09-13 13:44:15][INFO] global_step=111648, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:16][INFO] global_step=111680, episodic_reward_predictor_return=-0.7999606132507324\n",
      "[2023-09-13 13:44:16][INFO] global_step=111680, episodic_env_return=34.0\n",
      "[2023-09-13 13:44:16][INFO] global_step=111704, episodic_reward_predictor_return=-0.9359246492385864\n",
      "[2023-09-13 13:44:16][INFO] global_step=111704, episodic_env_return=46.0\n",
      "[2023-09-13 13:44:16][INFO] global_step=111704, episodic_reward_predictor_return=-0.25817054510116577\n",
      "[2023-09-13 13:44:16][INFO] global_step=111704, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:17][INFO] global_step=111712, episodic_reward_predictor_return=0.22489169239997864\n",
      "[2023-09-13 13:44:17][INFO] global_step=111712, episodic_env_return=87.0\n",
      "[2023-09-13 13:44:17][INFO] global_step=111752, episodic_reward_predictor_return=-0.048091065138578415\n",
      "[2023-09-13 13:44:17][INFO] global_step=111752, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:17][INFO] global_step=111752, episodic_reward_predictor_return=-1.0388799905776978\n",
      "[2023-09-13 13:44:17][INFO] global_step=111752, episodic_env_return=25.0\n",
      "[2023-09-13 13:44:18][INFO] global_step=111784, episodic_reward_predictor_return=-0.16890746355056763\n",
      "[2023-09-13 13:44:18][INFO] global_step=111784, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:18][INFO] global_step=111824, episodic_reward_predictor_return=0.11394872516393661\n",
      "[2023-09-13 13:44:18][INFO] global_step=111824, episodic_env_return=70.0\n",
      "[2023-09-13 13:44:19][INFO] global_step=111840, episodic_reward_predictor_return=-0.30383241176605225\n",
      "[2023-09-13 13:44:19][INFO] global_step=111840, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:19][INFO] global_step=111856, episodic_reward_predictor_return=-0.2492792010307312\n",
      "[2023-09-13 13:44:19][INFO] global_step=111856, episodic_env_return=88.0\n",
      "[2023-09-13 13:44:21][INFO] global_step=111952, episodic_reward_predictor_return=-0.4444400370121002\n",
      "[2023-09-13 13:44:21][INFO] global_step=111952, episodic_env_return=58.0\n",
      "[2023-09-13 13:44:21][INFO] global_step=111984, episodic_reward_predictor_return=-0.054510753601789474\n",
      "[2023-09-13 13:44:21][INFO] global_step=111984, episodic_env_return=81.0\n",
      "[2023-09-13 13:44:22][INFO] global_step=112032, episodic_reward_predictor_return=0.08300583064556122\n",
      "[2023-09-13 13:44:22][INFO] global_step=112032, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:22][INFO] global_step=112032, episodic_reward_predictor_return=-0.27795761823654175\n",
      "[2023-09-13 13:44:22][INFO] global_step=112032, episodic_env_return=77.0\n",
      "[2023-09-13 13:44:23][INFO] global_step=112064, episodic_reward_predictor_return=-1.0942895412445068\n",
      "[2023-09-13 13:44:23][INFO] global_step=112064, episodic_env_return=51.0\n",
      "[2023-09-13 13:44:23][INFO] global_step=112088, episodic_reward_predictor_return=-1.4509968757629395\n",
      "[2023-09-13 13:44:23][INFO] global_step=112088, episodic_env_return=7.0\n",
      "[2023-09-13 13:44:24][INFO] global_step=112168, episodic_reward_predictor_return=-0.1777791827917099\n",
      "[2023-09-13 13:44:24][INFO] global_step=112168, episodic_env_return=84.0\n",
      "[2023-09-13 13:44:25][INFO] global_step=112224, episodic_reward_predictor_return=-0.411957710981369\n",
      "[2023-09-13 13:44:25][INFO] global_step=112224, episodic_env_return=16.0\n",
      "[2023-09-13 13:44:26][INFO] global_step=112248, episodic_reward_predictor_return=-0.1943160742521286\n",
      "[2023-09-13 13:44:26][INFO] global_step=112248, episodic_env_return=52.0\n",
      "[2023-09-13 13:44:26][INFO] global_step=112288, episodic_reward_predictor_return=-0.5198647379875183\n",
      "[2023-09-13 13:44:26][INFO] global_step=112288, episodic_env_return=23.0\n",
      "[2023-09-13 13:44:27][INFO] global_step=112304, episodic_reward_predictor_return=-0.005931228399276733\n",
      "[2023-09-13 13:44:27][INFO] global_step=112304, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:28][INFO] global_step=112352, episodic_reward_predictor_return=-0.595030665397644\n",
      "[2023-09-13 13:44:28][INFO] global_step=112352, episodic_env_return=55.0\n",
      "[2023-09-13 13:44:28][INFO] global_step=112392, episodic_reward_predictor_return=-0.08088703453540802\n",
      "[2023-09-13 13:44:28][INFO] global_step=112392, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:28][INFO] global_step=112400, episodic_reward_predictor_return=-0.32472139596939087\n",
      "[2023-09-13 13:44:28][INFO] global_step=112400, episodic_env_return=50.0\n",
      "[2023-09-13 13:44:28][INFO] global_step=112400, episodic_reward_predictor_return=-0.6013884544372559\n",
      "[2023-09-13 13:44:28][INFO] global_step=112400, episodic_env_return=62.0\n",
      "[2023-09-13 13:44:29][INFO] global_step=112448, episodic_reward_predictor_return=-0.1209959089756012\n",
      "[2023-09-13 13:44:29][INFO] global_step=112448, episodic_env_return=95.0\n",
      "[2023-09-13 13:44:29][INFO] global_step=112448, episodic_reward_predictor_return=-0.2707318663597107\n",
      "[2023-09-13 13:44:29][INFO] global_step=112448, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:30][INFO] global_step=112464, episodic_reward_predictor_return=0.009335906244814396\n",
      "[2023-09-13 13:44:30][INFO] global_step=112464, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:30][INFO] global_step=112472, episodic_reward_predictor_return=0.01539842039346695\n",
      "[2023-09-13 13:44:30][INFO] global_step=112472, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:30][INFO] global_step=112496, episodic_reward_predictor_return=-1.0410505533218384\n",
      "[2023-09-13 13:44:30][INFO] global_step=112496, episodic_env_return=55.0\n",
      "[2023-09-13 13:44:31][INFO] global_step=112552, episodic_reward_predictor_return=-0.2987915575504303\n",
      "[2023-09-13 13:44:31][INFO] global_step=112552, episodic_env_return=63.0\n",
      "[2023-09-13 13:44:31][INFO] global_step=112568, episodic_reward_predictor_return=-0.22919119894504547\n",
      "[2023-09-13 13:44:31][INFO] global_step=112568, episodic_env_return=86.0\n",
      "[2023-09-13 13:44:31][INFO] global_step=112584, episodic_reward_predictor_return=-0.17831043899059296\n",
      "[2023-09-13 13:44:31][INFO] global_step=112584, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:32][INFO] global_step=112600, episodic_reward_predictor_return=-0.6576929688453674\n",
      "[2023-09-13 13:44:32][INFO] global_step=112600, episodic_env_return=47.0\n",
      "[2023-09-13 13:44:32][INFO] global_step=112632, episodic_reward_predictor_return=-0.11983805894851685\n",
      "[2023-09-13 13:44:32][INFO] global_step=112632, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:32][INFO] global_step=112640, episodic_reward_predictor_return=-0.5512171387672424\n",
      "[2023-09-13 13:44:32][INFO] global_step=112640, episodic_env_return=77.0\n",
      "[2023-09-13 13:44:32][INFO] Current Mean Episodic Return = -0.40240898728370667\n",
      "[2023-09-13 13:44:32][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_112640`...\n",
      "[2023-09-13 13:44:32][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_112640`!\n",
      "[2023-09-13 13:44:35][INFO] SPS: 25\n",
      "[2023-09-13 13:44:36][INFO] global_step=112712, episodic_reward_predictor_return=-0.42548972368240356\n",
      "[2023-09-13 13:44:36][INFO] global_step=112712, episodic_env_return=70.0\n",
      "[2023-09-13 13:44:37][INFO] global_step=112736, episodic_reward_predictor_return=-0.1731594353914261\n",
      "[2023-09-13 13:44:37][INFO] global_step=112736, episodic_env_return=63.0\n",
      "[2023-09-13 13:44:37][INFO] global_step=112744, episodic_reward_predictor_return=-0.15256987512111664\n",
      "[2023-09-13 13:44:37][INFO] global_step=112744, episodic_env_return=87.0\n",
      "[2023-09-13 13:44:37][INFO] global_step=112768, episodic_reward_predictor_return=-1.8505479097366333\n",
      "[2023-09-13 13:44:37][INFO] global_step=112768, episodic_env_return=-12.0\n",
      "[2023-09-13 13:44:37][INFO] global_step=112768, episodic_reward_predictor_return=-0.29429200291633606\n",
      "[2023-09-13 13:44:37][INFO] global_step=112768, episodic_env_return=85.0\n",
      "[2023-09-13 13:44:37][INFO] global_step=112784, episodic_reward_predictor_return=-0.23500829935073853\n",
      "[2023-09-13 13:44:37][INFO] global_step=112784, episodic_env_return=71.0\n",
      "[2023-09-13 13:44:38][INFO] global_step=112800, episodic_reward_predictor_return=-0.14076794683933258\n",
      "[2023-09-13 13:44:38][INFO] global_step=112800, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:38][INFO] global_step=112816, episodic_reward_predictor_return=-0.2653794288635254\n",
      "[2023-09-13 13:44:38][INFO] global_step=112816, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:38][INFO] global_step=112824, episodic_reward_predictor_return=-0.04046886786818504\n",
      "[2023-09-13 13:44:38][INFO] global_step=112824, episodic_env_return=94.0\n",
      "[2023-09-13 13:44:38][INFO] global_step=112840, episodic_reward_predictor_return=0.09292592853307724\n",
      "[2023-09-13 13:44:38][INFO] global_step=112840, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:38][INFO] global_step=112848, episodic_reward_predictor_return=0.041585810482501984\n",
      "[2023-09-13 13:44:38][INFO] global_step=112848, episodic_env_return=65.0\n",
      "[2023-09-13 13:44:39][INFO] global_step=112872, episodic_reward_predictor_return=-0.15470492839813232\n",
      "[2023-09-13 13:44:39][INFO] global_step=112872, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:40][INFO] global_step=112928, episodic_reward_predictor_return=-0.045589566230773926\n",
      "[2023-09-13 13:44:40][INFO] global_step=112928, episodic_env_return=85.0\n",
      "[2023-09-13 13:44:41][INFO] global_step=112984, episodic_reward_predictor_return=-0.6657751202583313\n",
      "[2023-09-13 13:44:41][INFO] global_step=112984, episodic_env_return=44.0\n",
      "[2023-09-13 13:44:41][INFO] global_step=112984, episodic_reward_predictor_return=-0.2693650424480438\n",
      "[2023-09-13 13:44:41][INFO] global_step=112984, episodic_env_return=80.0\n",
      "[2023-09-13 13:44:41][INFO] global_step=113032, episodic_reward_predictor_return=-0.061576660722494125\n",
      "[2023-09-13 13:44:41][INFO] global_step=113032, episodic_env_return=95.0\n",
      "[2023-09-13 13:44:42][INFO] global_step=113096, episodic_reward_predictor_return=-0.366855651140213\n",
      "[2023-09-13 13:44:42][INFO] global_step=113096, episodic_env_return=70.0\n",
      "[2023-09-13 13:44:43][INFO] global_step=113112, episodic_reward_predictor_return=-0.12083631753921509\n",
      "[2023-09-13 13:44:43][INFO] global_step=113112, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:44][INFO] global_step=113152, episodic_reward_predictor_return=-0.03284837305545807\n",
      "[2023-09-13 13:44:44][INFO] global_step=113152, episodic_env_return=35.0\n",
      "[2023-09-13 13:44:44][INFO] global_step=113168, episodic_reward_predictor_return=-0.21829672157764435\n",
      "[2023-09-13 13:44:44][INFO] global_step=113168, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:44][INFO] global_step=113168, episodic_reward_predictor_return=-0.024318423122167587\n",
      "[2023-09-13 13:44:44][INFO] global_step=113168, episodic_env_return=71.0\n",
      "[2023-09-13 13:44:45][INFO] global_step=113216, episodic_reward_predictor_return=-0.43370354175567627\n",
      "[2023-09-13 13:44:45][INFO] global_step=113216, episodic_env_return=53.0\n",
      "[2023-09-13 13:44:45][INFO] global_step=113248, episodic_reward_predictor_return=-0.14674526453018188\n",
      "[2023-09-13 13:44:45][INFO] global_step=113248, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:46][INFO] global_step=113304, episodic_reward_predictor_return=-0.2154732048511505\n",
      "[2023-09-13 13:44:46][INFO] global_step=113304, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:47][INFO] global_step=113320, episodic_reward_predictor_return=-0.2788069248199463\n",
      "[2023-09-13 13:44:47][INFO] global_step=113320, episodic_env_return=70.0\n",
      "[2023-09-13 13:44:47][INFO] global_step=113328, episodic_reward_predictor_return=-1.452148675918579\n",
      "[2023-09-13 13:44:47][INFO] global_step=113328, episodic_env_return=25.0\n",
      "[2023-09-13 13:44:47][INFO] global_step=113344, episodic_reward_predictor_return=-0.07670649886131287\n",
      "[2023-09-13 13:44:47][INFO] global_step=113344, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:48][INFO] global_step=113376, episodic_reward_predictor_return=-0.061912231147289276\n",
      "[2023-09-13 13:44:48][INFO] global_step=113376, episodic_env_return=68.0\n",
      "[2023-09-13 13:44:49][INFO] global_step=113432, episodic_reward_predictor_return=0.010816178284585476\n",
      "[2023-09-13 13:44:49][INFO] global_step=113432, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:49][INFO] global_step=113448, episodic_reward_predictor_return=-0.6977213621139526\n",
      "[2023-09-13 13:44:49][INFO] global_step=113448, episodic_env_return=28.0\n",
      "[2023-09-13 13:44:49][INFO] global_step=113464, episodic_reward_predictor_return=-0.7189074158668518\n",
      "[2023-09-13 13:44:49][INFO] global_step=113464, episodic_env_return=54.0\n",
      "[2023-09-13 13:44:49][INFO] global_step=113472, episodic_reward_predictor_return=-0.04833417013287544\n",
      "[2023-09-13 13:44:49][INFO] global_step=113472, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:50][INFO] global_step=113496, episodic_reward_predictor_return=-0.3405005633831024\n",
      "[2023-09-13 13:44:50][INFO] global_step=113496, episodic_env_return=72.0\n",
      "[2023-09-13 13:44:50][INFO] global_step=113528, episodic_reward_predictor_return=-0.14555610716342926\n",
      "[2023-09-13 13:44:50][INFO] global_step=113528, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:50][INFO] global_step=113536, episodic_reward_predictor_return=0.14974302053451538\n",
      "[2023-09-13 13:44:50][INFO] global_step=113536, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:51][INFO] global_step=113600, episodic_reward_predictor_return=-0.1781819760799408\n",
      "[2023-09-13 13:44:51][INFO] global_step=113600, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:52][INFO] global_step=113616, episodic_reward_predictor_return=-1.0688958168029785\n",
      "[2023-09-13 13:44:52][INFO] global_step=113616, episodic_env_return=54.0\n",
      "[2023-09-13 13:44:52][INFO] global_step=113656, episodic_reward_predictor_return=-0.18082740902900696\n",
      "[2023-09-13 13:44:52][INFO] global_step=113656, episodic_env_return=73.0\n",
      "[2023-09-13 13:44:53][INFO] global_step=113688, episodic_reward_predictor_return=-0.1248893216252327\n",
      "[2023-09-13 13:44:53][INFO] global_step=113688, episodic_env_return=82.0\n",
      "[2023-09-13 13:44:53][INFO] global_step=113704, episodic_reward_predictor_return=-0.13340692222118378\n",
      "[2023-09-13 13:44:53][INFO] global_step=113704, episodic_env_return=49.0\n",
      "[2023-09-13 13:44:53][INFO] global_step=113712, episodic_reward_predictor_return=-0.03628317639231682\n",
      "[2023-09-13 13:44:53][INFO] global_step=113712, episodic_env_return=63.0\n",
      "[2023-09-13 13:44:54][INFO] global_step=113776, episodic_reward_predictor_return=-0.10279631614685059\n",
      "[2023-09-13 13:44:54][INFO] global_step=113776, episodic_env_return=92.0\n",
      "[2023-09-13 13:44:55][INFO] global_step=113792, episodic_reward_predictor_return=0.17226019501686096\n",
      "[2023-09-13 13:44:55][INFO] global_step=113792, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:56][INFO] global_step=113848, episodic_reward_predictor_return=-0.678834080696106\n",
      "[2023-09-13 13:44:56][INFO] global_step=113848, episodic_env_return=77.0\n",
      "[2023-09-13 13:44:56][INFO] global_step=113856, episodic_reward_predictor_return=-0.3166787326335907\n",
      "[2023-09-13 13:44:56][INFO] global_step=113856, episodic_env_return=80.0\n",
      "[2023-09-13 13:44:56][INFO] global_step=113888, episodic_reward_predictor_return=0.4596230685710907\n",
      "[2023-09-13 13:44:56][INFO] global_step=113888, episodic_env_return=-67.0\n",
      "[2023-09-13 13:44:56][INFO] global_step=113888, episodic_reward_predictor_return=-0.16355383396148682\n",
      "[2023-09-13 13:44:56][INFO] global_step=113888, episodic_env_return=89.0\n",
      "[2023-09-13 13:44:57][INFO] global_step=113912, episodic_reward_predictor_return=-0.054303985089063644\n",
      "[2023-09-13 13:44:57][INFO] global_step=113912, episodic_env_return=34.0\n",
      "[2023-09-13 13:44:57][INFO] global_step=113944, episodic_reward_predictor_return=-0.11070474982261658\n",
      "[2023-09-13 13:44:57][INFO] global_step=113944, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:58][INFO] global_step=113976, episodic_reward_predictor_return=-0.21735884249210358\n",
      "[2023-09-13 13:44:58][INFO] global_step=113976, episodic_env_return=90.0\n",
      "[2023-09-13 13:44:58][INFO] global_step=113992, episodic_reward_predictor_return=-0.04800313711166382\n",
      "[2023-09-13 13:44:58][INFO] global_step=113992, episodic_env_return=91.0\n",
      "[2023-09-13 13:44:59][INFO] global_step=114040, episodic_reward_predictor_return=-0.5809673070907593\n",
      "[2023-09-13 13:44:59][INFO] global_step=114040, episodic_env_return=38.0\n",
      "[2023-09-13 13:44:59][INFO] global_step=114048, episodic_reward_predictor_return=-0.17376668751239777\n",
      "[2023-09-13 13:44:59][INFO] global_step=114048, episodic_env_return=92.0\n",
      "[2023-09-13 13:45:00][INFO] global_step=114136, episodic_reward_predictor_return=-0.10681292414665222\n",
      "[2023-09-13 13:45:00][INFO] global_step=114136, episodic_env_return=70.0\n",
      "[2023-09-13 13:45:01][INFO] global_step=114144, episodic_reward_predictor_return=-0.06459690630435944\n",
      "[2023-09-13 13:45:01][INFO] global_step=114144, episodic_env_return=88.0\n",
      "[2023-09-13 13:45:01][INFO] global_step=114160, episodic_reward_predictor_return=-0.29061004519462585\n",
      "[2023-09-13 13:45:01][INFO] global_step=114160, episodic_env_return=57.0\n",
      "[2023-09-13 13:45:02][INFO] global_step=114200, episodic_reward_predictor_return=-0.3395068347454071\n",
      "[2023-09-13 13:45:02][INFO] global_step=114200, episodic_env_return=70.0\n",
      "[2023-09-13 13:45:02][INFO] global_step=114208, episodic_reward_predictor_return=0.1328643411397934\n",
      "[2023-09-13 13:45:02][INFO] global_step=114208, episodic_env_return=92.0\n",
      "[2023-09-13 13:45:02][INFO] global_step=114224, episodic_reward_predictor_return=-0.19014917314052582\n",
      "[2023-09-13 13:45:02][INFO] global_step=114224, episodic_env_return=91.0\n",
      "[2023-09-13 13:45:02][INFO] global_step=114248, episodic_reward_predictor_return=-1.318739891052246\n",
      "[2023-09-13 13:45:02][INFO] global_step=114248, episodic_env_return=27.0\n",
      "[2023-09-13 13:45:03][INFO] global_step=114272, episodic_reward_predictor_return=-0.30278050899505615\n",
      "[2023-09-13 13:45:03][INFO] global_step=114272, episodic_env_return=92.0\n",
      "[2023-09-13 13:45:03][INFO] global_step=114280, episodic_reward_predictor_return=-0.4112018346786499\n",
      "[2023-09-13 13:45:03][INFO] global_step=114280, episodic_env_return=67.0\n",
      "[2023-09-13 13:45:03][INFO] global_step=114288, episodic_reward_predictor_return=-0.26226407289505005\n",
      "[2023-09-13 13:45:03][INFO] global_step=114288, episodic_env_return=91.0\n",
      "[2023-09-13 13:45:04][INFO] global_step=114344, episodic_reward_predictor_return=-0.18562531471252441\n",
      "[2023-09-13 13:45:04][INFO] global_step=114344, episodic_env_return=94.0\n",
      "[2023-09-13 13:45:04][INFO] global_step=114344, episodic_reward_predictor_return=-0.11670775711536407\n",
      "[2023-09-13 13:45:04][INFO] global_step=114344, episodic_env_return=92.0\n",
      "[2023-09-13 13:45:04][INFO] global_step=114352, episodic_reward_predictor_return=0.010638546198606491\n",
      "[2023-09-13 13:45:04][INFO] global_step=114352, episodic_env_return=92.0\n",
      "[2023-09-13 13:45:05][INFO] global_step=114376, episodic_reward_predictor_return=-0.54976487159729\n",
      "[2023-09-13 13:45:05][INFO] global_step=114376, episodic_env_return=82.0\n",
      "[2023-09-13 13:45:06][INFO] global_step=114440, episodic_reward_predictor_return=-0.25711098313331604\n",
      "[2023-09-13 13:45:06][INFO] global_step=114440, episodic_env_return=89.0\n",
      "[2023-09-13 13:45:06][INFO] global_step=114440, episodic_reward_predictor_return=-0.08007953315973282\n",
      "[2023-09-13 13:45:06][INFO] global_step=114440, episodic_env_return=93.0\n",
      "[2023-09-13 13:45:06][INFO] global_step=114448, episodic_reward_predictor_return=-0.18880730867385864\n",
      "[2023-09-13 13:45:06][INFO] global_step=114448, episodic_env_return=88.0\n",
      "[2023-09-13 13:45:08][INFO] global_step=114560, episodic_reward_predictor_return=-1.4142866134643555\n",
      "[2023-09-13 13:45:08][INFO] global_step=114560, episodic_env_return=14.0\n",
      "[2023-09-13 13:45:08][INFO] global_step=114576, episodic_reward_predictor_return=-0.5228145122528076\n",
      "[2023-09-13 13:45:08][INFO] global_step=114576, episodic_env_return=55.0\n",
      "[2023-09-13 13:45:09][INFO] global_step=114640, episodic_reward_predictor_return=-0.5523226857185364\n",
      "[2023-09-13 13:45:09][INFO] global_step=114640, episodic_env_return=72.0\n",
      "[2023-09-13 13:45:09][INFO] global_step=114656, episodic_reward_predictor_return=-0.17119386792182922\n",
      "[2023-09-13 13:45:09][INFO] global_step=114656, episodic_env_return=91.0\n",
      "[2023-09-13 13:45:10][INFO] global_step=114664, episodic_reward_predictor_return=-1.17613685131073\n",
      "[2023-09-13 13:45:10][INFO] global_step=114664, episodic_env_return=23.0\n",
      "[2023-09-13 13:45:10][INFO] global_step=114680, episodic_reward_predictor_return=-0.13940875232219696\n",
      "[2023-09-13 13:45:10][INFO] global_step=114680, episodic_env_return=86.0\n",
      "[2023-09-13 13:45:10][INFO] global_step=114688, episodic_reward_predictor_return=-0.9183692336082458\n",
      "[2023-09-13 13:45:10][INFO] global_step=114688, episodic_env_return=54.0\n",
      "[2023-09-13 13:45:10][INFO] Current Mean Episodic Return = -0.29626819491386414\n",
      "[2023-09-13 13:45:10][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_114688`...\n",
      "[2023-09-13 13:45:10][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_114688`!\n",
      "[2023-09-13 13:45:13][INFO] SPS: 25\n",
      "[2023-09-13 13:45:58][INFO] user_preference = 1\n",
      "[2023-09-13 13:45:58][INFO] reward_predictor_training_loss=1.073022723197937\n",
      "[2023-09-13 13:46:27][INFO] user_preference = 0\n",
      "[2023-09-13 13:46:27][INFO] reward_predictor_training_loss=0.02056542970240116\n",
      "[2023-09-13 13:47:08][INFO] user_preference = 0\n",
      "[2023-09-13 13:47:08][INFO] reward_predictor_training_loss=0.6191099882125854\n",
      "[2023-09-13 13:47:17][INFO] user_preference = 1\n",
      "[2023-09-13 13:47:17][INFO] reward_predictor_training_loss=1.3071833848953247\n",
      "[2023-09-13 13:47:53][INFO] user_preference = 0\n",
      "[2023-09-13 13:47:53][INFO] reward_predictor_training_loss=0.09866141527891159\n",
      "[2023-09-13 13:48:52][INFO] user_preference = 1\n",
      "[2023-09-13 13:48:53][INFO] reward_predictor_training_loss=0.13917677104473114\n",
      "[2023-09-13 13:49:33][INFO] user_preference = 1\n",
      "[2023-09-13 13:49:33][INFO] reward_predictor_training_loss=2.0799551010131836\n",
      "[2023-09-13 13:50:09][INFO] user_preference = 0\n",
      "[2023-09-13 13:50:09][INFO] reward_predictor_training_loss=0.054139867424964905\n",
      "[2023-09-13 13:50:24][INFO] user_preference = 0\n",
      "[2023-09-13 13:50:24][INFO] reward_predictor_training_loss=1.4039493799209595\n",
      "[2023-09-13 13:51:30][INFO] user_preference = 1\n",
      "[2023-09-13 13:51:30][INFO] reward_predictor_training_loss=4.320195198059082\n",
      "[2023-09-13 13:52:17][INFO] user_preference = 1\n",
      "[2023-09-13 13:52:18][INFO] reward_predictor_training_loss=0.16936878859996796\n",
      "[2023-09-13 13:53:08][INFO] user_preference = 1\n",
      "[2023-09-13 13:53:08][INFO] reward_predictor_training_loss=0.638800323009491\n",
      "[2023-09-13 13:53:51][INFO] user_preference = 0.5\n",
      "[2023-09-13 13:53:51][INFO] reward_predictor_training_loss=0.8200138807296753\n",
      "[2023-09-13 13:54:09][INFO] user_preference = 1\n",
      "[2023-09-13 13:54:09][INFO] reward_predictor_training_loss=0.16045765578746796\n",
      "[2023-09-13 13:55:17][INFO] user_preference = 0\n",
      "[2023-09-13 13:55:17][INFO] reward_predictor_training_loss=0.8899137377738953\n",
      "[2023-09-13 13:56:10][INFO] user_preference = 1\n",
      "[2023-09-13 13:56:10][INFO] reward_predictor_training_loss=0.04258016124367714\n",
      "[2023-09-13 13:56:11][INFO] global_step=114728, episodic_reward_predictor_return=0.23183640837669373\n",
      "[2023-09-13 13:56:11][INFO] global_step=114728, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:11][INFO] global_step=114736, episodic_reward_predictor_return=0.12589198350906372\n",
      "[2023-09-13 13:56:11][INFO] global_step=114736, episodic_env_return=95.0\n",
      "[2023-09-13 13:56:11][INFO] global_step=114736, episodic_reward_predictor_return=0.11038810759782791\n",
      "[2023-09-13 13:56:11][INFO] global_step=114736, episodic_env_return=94.0\n",
      "[2023-09-13 13:56:11][INFO] global_step=114744, episodic_reward_predictor_return=-0.9108949303627014\n",
      "[2023-09-13 13:56:11][INFO] global_step=114744, episodic_env_return=-72.0\n",
      "[2023-09-13 13:56:11][INFO] global_step=114744, episodic_reward_predictor_return=0.09582190215587616\n",
      "[2023-09-13 13:56:11][INFO] global_step=114744, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:12][INFO] global_step=114800, episodic_reward_predictor_return=0.05228076130151749\n",
      "[2023-09-13 13:56:12][INFO] global_step=114800, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:12][INFO] global_step=114816, episodic_reward_predictor_return=0.21648439764976501\n",
      "[2023-09-13 13:56:12][INFO] global_step=114816, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:13][INFO] global_step=114848, episodic_reward_predictor_return=0.13841354846954346\n",
      "[2023-09-13 13:56:13][INFO] global_step=114848, episodic_env_return=88.0\n",
      "[2023-09-13 13:56:13][INFO] global_step=114864, episodic_reward_predictor_return=0.18876250088214874\n",
      "[2023-09-13 13:56:13][INFO] global_step=114864, episodic_env_return=85.0\n",
      "[2023-09-13 13:56:14][INFO] global_step=114880, episodic_reward_predictor_return=0.3737187087535858\n",
      "[2023-09-13 13:56:14][INFO] global_step=114880, episodic_env_return=41.0\n",
      "[2023-09-13 13:56:14][INFO] global_step=114936, episodic_reward_predictor_return=-1.664466142654419\n",
      "[2023-09-13 13:56:14][INFO] global_step=114936, episodic_env_return=24.0\n",
      "[2023-09-13 13:56:14][INFO] global_step=114936, episodic_reward_predictor_return=0.41278448700904846\n",
      "[2023-09-13 13:56:14][INFO] global_step=114936, episodic_env_return=67.0\n",
      "[2023-09-13 13:56:15][INFO] global_step=114976, episodic_reward_predictor_return=0.2082623839378357\n",
      "[2023-09-13 13:56:15][INFO] global_step=114976, episodic_env_return=81.0\n",
      "[2023-09-13 13:56:15][INFO] global_step=115000, episodic_reward_predictor_return=0.20767730474472046\n",
      "[2023-09-13 13:56:15][INFO] global_step=115000, episodic_env_return=86.0\n",
      "[2023-09-13 13:56:16][INFO] global_step=115024, episodic_reward_predictor_return=0.08269257843494415\n",
      "[2023-09-13 13:56:16][INFO] global_step=115024, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:16][INFO] global_step=115056, episodic_reward_predictor_return=0.23268753290176392\n",
      "[2023-09-13 13:56:16][INFO] global_step=115056, episodic_env_return=75.0\n",
      "[2023-09-13 13:56:17][INFO] global_step=115104, episodic_reward_predictor_return=0.16548344492912292\n",
      "[2023-09-13 13:56:17][INFO] global_step=115104, episodic_env_return=95.0\n",
      "[2023-09-13 13:56:17][INFO] global_step=115112, episodic_reward_predictor_return=0.15148308873176575\n",
      "[2023-09-13 13:56:17][INFO] global_step=115112, episodic_env_return=84.0\n",
      "[2023-09-13 13:56:18][INFO] global_step=115160, episodic_reward_predictor_return=0.6637299656867981\n",
      "[2023-09-13 13:56:18][INFO] global_step=115160, episodic_env_return=73.0\n",
      "[2023-09-13 13:56:19][INFO] global_step=115200, episodic_reward_predictor_return=-1.0755772590637207\n",
      "[2023-09-13 13:56:19][INFO] global_step=115200, episodic_env_return=29.0\n",
      "[2023-09-13 13:56:19][INFO] global_step=115208, episodic_reward_predictor_return=0.37269866466522217\n",
      "[2023-09-13 13:56:19][INFO] global_step=115208, episodic_env_return=88.0\n",
      "[2023-09-13 13:56:21][INFO] global_step=115312, episodic_reward_predictor_return=-0.31893882155418396\n",
      "[2023-09-13 13:56:21][INFO] global_step=115312, episodic_env_return=30.0\n",
      "[2023-09-13 13:56:21][INFO] global_step=115336, episodic_reward_predictor_return=0.7300230860710144\n",
      "[2023-09-13 13:56:21][INFO] global_step=115336, episodic_env_return=24.0\n",
      "[2023-09-13 13:56:21][INFO] global_step=115336, episodic_reward_predictor_return=0.36827272176742554\n",
      "[2023-09-13 13:56:21][INFO] global_step=115336, episodic_env_return=57.0\n",
      "[2023-09-13 13:56:22][INFO] global_step=115352, episodic_reward_predictor_return=0.25465846061706543\n",
      "[2023-09-13 13:56:22][INFO] global_step=115352, episodic_env_return=57.0\n",
      "[2023-09-13 13:56:22][INFO] global_step=115384, episodic_reward_predictor_return=-0.061826035380363464\n",
      "[2023-09-13 13:56:22][INFO] global_step=115384, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:23][INFO] global_step=115416, episodic_reward_predictor_return=0.0037880539894104004\n",
      "[2023-09-13 13:56:23][INFO] global_step=115416, episodic_env_return=64.0\n",
      "[2023-09-13 13:56:23][INFO] global_step=115432, episodic_reward_predictor_return=0.2783677279949188\n",
      "[2023-09-13 13:56:23][INFO] global_step=115432, episodic_env_return=89.0\n",
      "[2023-09-13 13:56:24][INFO] global_step=115480, episodic_reward_predictor_return=0.3437178432941437\n",
      "[2023-09-13 13:56:24][INFO] global_step=115480, episodic_env_return=85.0\n",
      "[2023-09-13 13:56:25][INFO] global_step=115536, episodic_reward_predictor_return=-0.020582130178809166\n",
      "[2023-09-13 13:56:25][INFO] global_step=115536, episodic_env_return=71.0\n",
      "[2023-09-13 13:56:26][INFO] global_step=115632, episodic_reward_predictor_return=-0.7089427709579468\n",
      "[2023-09-13 13:56:26][INFO] global_step=115632, episodic_env_return=16.0\n",
      "[2023-09-13 13:56:27][INFO] global_step=115648, episodic_reward_predictor_return=-0.16551272571086884\n",
      "[2023-09-13 13:56:27][INFO] global_step=115648, episodic_env_return=40.0\n",
      "[2023-09-13 13:56:27][INFO] global_step=115664, episodic_reward_predictor_return=0.036636851727962494\n",
      "[2023-09-13 13:56:27][INFO] global_step=115664, episodic_env_return=73.0\n",
      "[2023-09-13 13:56:27][INFO] global_step=115672, episodic_reward_predictor_return=-0.19501803815364838\n",
      "[2023-09-13 13:56:27][INFO] global_step=115672, episodic_env_return=60.0\n",
      "[2023-09-13 13:56:28][INFO] global_step=115720, episodic_reward_predictor_return=0.011597852222621441\n",
      "[2023-09-13 13:56:28][INFO] global_step=115720, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:28][INFO] global_step=115752, episodic_reward_predictor_return=-0.745693564414978\n",
      "[2023-09-13 13:56:28][INFO] global_step=115752, episodic_env_return=13.0\n",
      "[2023-09-13 13:56:29][INFO] global_step=115792, episodic_reward_predictor_return=0.15771622955799103\n",
      "[2023-09-13 13:56:29][INFO] global_step=115792, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:29][INFO] global_step=115816, episodic_reward_predictor_return=0.12688912451267242\n",
      "[2023-09-13 13:56:29][INFO] global_step=115816, episodic_env_return=43.0\n",
      "[2023-09-13 13:56:30][INFO] global_step=115832, episodic_reward_predictor_return=0.0697038546204567\n",
      "[2023-09-13 13:56:30][INFO] global_step=115832, episodic_env_return=54.0\n",
      "[2023-09-13 13:56:30][INFO] global_step=115848, episodic_reward_predictor_return=0.23137690126895905\n",
      "[2023-09-13 13:56:30][INFO] global_step=115848, episodic_env_return=94.0\n",
      "[2023-09-13 13:56:31][INFO] global_step=115904, episodic_reward_predictor_return=0.16577304899692535\n",
      "[2023-09-13 13:56:31][INFO] global_step=115904, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:31][INFO] global_step=115912, episodic_reward_predictor_return=0.16447420418262482\n",
      "[2023-09-13 13:56:31][INFO] global_step=115912, episodic_env_return=65.0\n",
      "[2023-09-13 13:56:32][INFO] global_step=115984, episodic_reward_predictor_return=0.02581690438091755\n",
      "[2023-09-13 13:56:32][INFO] global_step=115984, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:33][INFO] global_step=116032, episodic_reward_predictor_return=0.314460813999176\n",
      "[2023-09-13 13:56:33][INFO] global_step=116032, episodic_env_return=69.0\n",
      "[2023-09-13 13:56:33][INFO] global_step=116048, episodic_reward_predictor_return=0.08928143978118896\n",
      "[2023-09-13 13:56:33][INFO] global_step=116048, episodic_env_return=59.0\n",
      "[2023-09-13 13:56:34][INFO] global_step=116072, episodic_reward_predictor_return=-0.4750082194805145\n",
      "[2023-09-13 13:56:34][INFO] global_step=116072, episodic_env_return=43.0\n",
      "[2023-09-13 13:56:34][INFO] global_step=116104, episodic_reward_predictor_return=-0.14931276440620422\n",
      "[2023-09-13 13:56:34][INFO] global_step=116104, episodic_env_return=71.0\n",
      "[2023-09-13 13:56:35][INFO] global_step=116144, episodic_reward_predictor_return=0.20339471101760864\n",
      "[2023-09-13 13:56:35][INFO] global_step=116144, episodic_env_return=89.0\n",
      "[2023-09-13 13:56:35][INFO] global_step=116160, episodic_reward_predictor_return=0.28086966276168823\n",
      "[2023-09-13 13:56:35][INFO] global_step=116160, episodic_env_return=52.0\n",
      "[2023-09-13 13:56:36][INFO] global_step=116184, episodic_reward_predictor_return=0.07511475682258606\n",
      "[2023-09-13 13:56:36][INFO] global_step=116184, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:36][INFO] global_step=116224, episodic_reward_predictor_return=0.06850072741508484\n",
      "[2023-09-13 13:56:36][INFO] global_step=116224, episodic_env_return=-30.0\n",
      "[2023-09-13 13:56:37][INFO] global_step=116232, episodic_reward_predictor_return=-0.0061246976256370544\n",
      "[2023-09-13 13:56:37][INFO] global_step=116232, episodic_env_return=76.0\n",
      "[2023-09-13 13:56:37][INFO] global_step=116264, episodic_reward_predictor_return=0.6987336874008179\n",
      "[2023-09-13 13:56:37][INFO] global_step=116264, episodic_env_return=66.0\n",
      "[2023-09-13 13:56:37][INFO] global_step=116272, episodic_reward_predictor_return=0.33882400393486023\n",
      "[2023-09-13 13:56:37][INFO] global_step=116272, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:38][INFO] global_step=116312, episodic_reward_predictor_return=-0.1438068449497223\n",
      "[2023-09-13 13:56:38][INFO] global_step=116312, episodic_env_return=75.0\n",
      "[2023-09-13 13:56:39][INFO] global_step=116392, episodic_reward_predictor_return=0.511053204536438\n",
      "[2023-09-13 13:56:39][INFO] global_step=116392, episodic_env_return=86.0\n",
      "[2023-09-13 13:56:40][INFO] global_step=116408, episodic_reward_predictor_return=0.0920858383178711\n",
      "[2023-09-13 13:56:40][INFO] global_step=116408, episodic_env_return=83.0\n",
      "[2023-09-13 13:56:40][INFO] global_step=116424, episodic_reward_predictor_return=0.2338777482509613\n",
      "[2023-09-13 13:56:40][INFO] global_step=116424, episodic_env_return=71.0\n",
      "[2023-09-13 13:56:40][INFO] global_step=116440, episodic_reward_predictor_return=0.08420747518539429\n",
      "[2023-09-13 13:56:40][INFO] global_step=116440, episodic_env_return=45.0\n",
      "[2023-09-13 13:56:41][INFO] global_step=116496, episodic_reward_predictor_return=-0.11152946949005127\n",
      "[2023-09-13 13:56:41][INFO] global_step=116496, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:42][INFO] global_step=116520, episodic_reward_predictor_return=-0.6982630491256714\n",
      "[2023-09-13 13:56:42][INFO] global_step=116520, episodic_env_return=-35.0\n",
      "[2023-09-13 13:56:42][INFO] global_step=116544, episodic_reward_predictor_return=-0.3421345353126526\n",
      "[2023-09-13 13:56:42][INFO] global_step=116544, episodic_env_return=48.0\n",
      "[2023-09-13 13:56:42][INFO] global_step=116576, episodic_reward_predictor_return=-0.07282152771949768\n",
      "[2023-09-13 13:56:42][INFO] global_step=116576, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:43][INFO] global_step=116592, episodic_reward_predictor_return=0.013266526162624359\n",
      "[2023-09-13 13:56:43][INFO] global_step=116592, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:43][INFO] global_step=116592, episodic_reward_predictor_return=0.21344126760959625\n",
      "[2023-09-13 13:56:43][INFO] global_step=116592, episodic_env_return=73.0\n",
      "[2023-09-13 13:56:43][INFO] global_step=116616, episodic_reward_predictor_return=0.3161846995353699\n",
      "[2023-09-13 13:56:43][INFO] global_step=116616, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:43][INFO] global_step=116624, episodic_reward_predictor_return=0.16067984700202942\n",
      "[2023-09-13 13:56:43][INFO] global_step=116624, episodic_env_return=95.0\n",
      "[2023-09-13 13:56:44][INFO] global_step=116672, episodic_reward_predictor_return=-0.06377950310707092\n",
      "[2023-09-13 13:56:44][INFO] global_step=116672, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:44][INFO] global_step=116680, episodic_reward_predictor_return=0.08528202027082443\n",
      "[2023-09-13 13:56:44][INFO] global_step=116680, episodic_env_return=90.0\n",
      "[2023-09-13 13:56:44][INFO] global_step=116688, episodic_reward_predictor_return=0.4237791895866394\n",
      "[2023-09-13 13:56:44][INFO] global_step=116688, episodic_env_return=70.0\n",
      "[2023-09-13 13:56:45][INFO] global_step=116728, episodic_reward_predictor_return=0.49034056067466736\n",
      "[2023-09-13 13:56:45][INFO] global_step=116728, episodic_env_return=39.0\n",
      "[2023-09-13 13:56:45][INFO] Current Mean Episodic Return = 0.053000785410404205\n",
      "[2023-09-13 13:56:45][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_116736`...\n",
      "[2023-09-13 13:56:45][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_116736`!\n",
      "[2023-09-13 13:56:48][INFO] SPS: 22\n",
      "[2023-09-13 13:56:48][INFO] global_step=116744, episodic_reward_predictor_return=0.21290048956871033\n",
      "[2023-09-13 13:56:48][INFO] global_step=116744, episodic_env_return=86.0\n",
      "[2023-09-13 13:56:48][INFO] global_step=116752, episodic_reward_predictor_return=-0.7764406204223633\n",
      "[2023-09-13 13:56:48][INFO] global_step=116752, episodic_env_return=46.0\n",
      "[2023-09-13 13:56:49][INFO] global_step=116768, episodic_reward_predictor_return=0.011006946675479412\n",
      "[2023-09-13 13:56:49][INFO] global_step=116768, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:50][INFO] global_step=116864, episodic_reward_predictor_return=0.4501354694366455\n",
      "[2023-09-13 13:56:50][INFO] global_step=116864, episodic_env_return=72.0\n",
      "[2023-09-13 13:56:50][INFO] global_step=116864, episodic_reward_predictor_return=0.1301858127117157\n",
      "[2023-09-13 13:56:50][INFO] global_step=116864, episodic_env_return=73.0\n",
      "[2023-09-13 13:56:51][INFO] global_step=116928, episodic_reward_predictor_return=0.2708626091480255\n",
      "[2023-09-13 13:56:51][INFO] global_step=116928, episodic_env_return=76.0\n",
      "[2023-09-13 13:56:52][INFO] global_step=116968, episodic_reward_predictor_return=0.13012824952602386\n",
      "[2023-09-13 13:56:52][INFO] global_step=116968, episodic_env_return=88.0\n",
      "[2023-09-13 13:56:52][INFO] global_step=117000, episodic_reward_predictor_return=0.3294565975666046\n",
      "[2023-09-13 13:56:52][INFO] global_step=117000, episodic_env_return=64.0\n",
      "[2023-09-13 13:56:53][INFO] global_step=117024, episodic_reward_predictor_return=0.7205789685249329\n",
      "[2023-09-13 13:56:53][INFO] global_step=117024, episodic_env_return=69.0\n",
      "[2023-09-13 13:56:53][INFO] global_step=117056, episodic_reward_predictor_return=0.15789413452148438\n",
      "[2023-09-13 13:56:53][INFO] global_step=117056, episodic_env_return=58.0\n",
      "[2023-09-13 13:56:54][INFO] global_step=117104, episodic_reward_predictor_return=0.2716864049434662\n",
      "[2023-09-13 13:56:54][INFO] global_step=117104, episodic_env_return=84.0\n",
      "[2023-09-13 13:56:54][INFO] global_step=117112, episodic_reward_predictor_return=-0.005351033061742783\n",
      "[2023-09-13 13:56:54][INFO] global_step=117112, episodic_env_return=94.0\n",
      "[2023-09-13 13:56:55][INFO] global_step=117128, episodic_reward_predictor_return=0.67461758852005\n",
      "[2023-09-13 13:56:55][INFO] global_step=117128, episodic_env_return=88.0\n",
      "[2023-09-13 13:56:55][INFO] global_step=117168, episodic_reward_predictor_return=0.08590081334114075\n",
      "[2023-09-13 13:56:55][INFO] global_step=117168, episodic_env_return=63.0\n",
      "[2023-09-13 13:56:55][INFO] global_step=117176, episodic_reward_predictor_return=0.7754508852958679\n",
      "[2023-09-13 13:56:55][INFO] global_step=117176, episodic_env_return=70.0\n",
      "[2023-09-13 13:56:56][INFO] global_step=117192, episodic_reward_predictor_return=0.031935468316078186\n",
      "[2023-09-13 13:56:56][INFO] global_step=117192, episodic_env_return=91.0\n",
      "[2023-09-13 13:56:56][INFO] global_step=117208, episodic_reward_predictor_return=0.34989050030708313\n",
      "[2023-09-13 13:56:56][INFO] global_step=117208, episodic_env_return=12.0\n",
      "[2023-09-13 13:56:57][INFO] global_step=117248, episodic_reward_predictor_return=0.3350018262863159\n",
      "[2023-09-13 13:56:57][INFO] global_step=117248, episodic_env_return=86.0\n",
      "[2023-09-13 13:56:57][INFO] global_step=117280, episodic_reward_predictor_return=0.14318595826625824\n",
      "[2023-09-13 13:56:57][INFO] global_step=117280, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:57][INFO] global_step=117280, episodic_reward_predictor_return=0.18671579658985138\n",
      "[2023-09-13 13:56:57][INFO] global_step=117280, episodic_env_return=88.0\n",
      "[2023-09-13 13:56:57][INFO] global_step=117288, episodic_reward_predictor_return=0.11441408097743988\n",
      "[2023-09-13 13:56:57][INFO] global_step=117288, episodic_env_return=89.0\n",
      "[2023-09-13 13:56:58][INFO] global_step=117336, episodic_reward_predictor_return=-0.14031285047531128\n",
      "[2023-09-13 13:56:58][INFO] global_step=117336, episodic_env_return=75.0\n",
      "[2023-09-13 13:56:58][INFO] global_step=117336, episodic_reward_predictor_return=0.03170759230852127\n",
      "[2023-09-13 13:56:58][INFO] global_step=117336, episodic_env_return=-57.0\n",
      "[2023-09-13 13:56:59][INFO] global_step=117360, episodic_reward_predictor_return=-0.22141264379024506\n",
      "[2023-09-13 13:56:59][INFO] global_step=117360, episodic_env_return=92.0\n",
      "[2023-09-13 13:56:59][INFO] global_step=117376, episodic_reward_predictor_return=0.32905423641204834\n",
      "[2023-09-13 13:56:59][INFO] global_step=117376, episodic_env_return=67.0\n",
      "[2023-09-13 13:56:59][INFO] global_step=117408, episodic_reward_predictor_return=-0.016125934198498726\n",
      "[2023-09-13 13:56:59][INFO] global_step=117408, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:00][INFO] global_step=117448, episodic_reward_predictor_return=0.06276858597993851\n",
      "[2023-09-13 13:57:00][INFO] global_step=117448, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:00][INFO] global_step=117456, episodic_reward_predictor_return=-0.03889540582895279\n",
      "[2023-09-13 13:57:00][INFO] global_step=117456, episodic_env_return=74.0\n",
      "[2023-09-13 13:57:01][INFO] global_step=117488, episodic_reward_predictor_return=0.34259912371635437\n",
      "[2023-09-13 13:57:01][INFO] global_step=117488, episodic_env_return=70.0\n",
      "[2023-09-13 13:57:02][INFO] global_step=117536, episodic_reward_predictor_return=0.317341148853302\n",
      "[2023-09-13 13:57:02][INFO] global_step=117536, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:02][INFO] global_step=117560, episodic_reward_predictor_return=0.4325270354747772\n",
      "[2023-09-13 13:57:02][INFO] global_step=117560, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:02][INFO] global_step=117560, episodic_reward_predictor_return=-0.7178887128829956\n",
      "[2023-09-13 13:57:02][INFO] global_step=117560, episodic_env_return=57.0\n",
      "[2023-09-13 13:57:03][INFO] global_step=117600, episodic_reward_predictor_return=0.2913380265235901\n",
      "[2023-09-13 13:57:03][INFO] global_step=117600, episodic_env_return=77.0\n",
      "[2023-09-13 13:57:03][INFO] global_step=117632, episodic_reward_predictor_return=-0.1867963671684265\n",
      "[2023-09-13 13:57:03][INFO] global_step=117632, episodic_env_return=2.0\n",
      "[2023-09-13 13:57:04][INFO] global_step=117672, episodic_reward_predictor_return=0.26313164830207825\n",
      "[2023-09-13 13:57:04][INFO] global_step=117672, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:05][INFO] global_step=117752, episodic_reward_predictor_return=0.6849832534790039\n",
      "[2023-09-13 13:57:05][INFO] global_step=117752, episodic_env_return=49.0\n",
      "[2023-09-13 13:57:06][INFO] global_step=117784, episodic_reward_predictor_return=-0.2092423141002655\n",
      "[2023-09-13 13:57:06][INFO] global_step=117784, episodic_env_return=68.0\n",
      "[2023-09-13 13:57:06][INFO] global_step=117816, episodic_reward_predictor_return=-0.29442837834358215\n",
      "[2023-09-13 13:57:06][INFO] global_step=117816, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:07][INFO] global_step=117848, episodic_reward_predictor_return=-0.029280928894877434\n",
      "[2023-09-13 13:57:07][INFO] global_step=117848, episodic_env_return=65.0\n",
      "[2023-09-13 13:57:07][INFO] global_step=117872, episodic_reward_predictor_return=0.26902592182159424\n",
      "[2023-09-13 13:57:07][INFO] global_step=117872, episodic_env_return=86.0\n",
      "[2023-09-13 13:57:08][INFO] global_step=117912, episodic_reward_predictor_return=-0.13110925257205963\n",
      "[2023-09-13 13:57:08][INFO] global_step=117912, episodic_env_return=52.0\n",
      "[2023-09-13 13:57:08][INFO] global_step=117944, episodic_reward_predictor_return=0.12508824467658997\n",
      "[2023-09-13 13:57:08][INFO] global_step=117944, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:10][INFO] global_step=118000, episodic_reward_predictor_return=-0.4076381325721741\n",
      "[2023-09-13 13:57:10][INFO] global_step=118000, episodic_env_return=28.0\n",
      "[2023-09-13 13:57:10][INFO] global_step=118000, episodic_reward_predictor_return=0.18595580756664276\n",
      "[2023-09-13 13:57:10][INFO] global_step=118000, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:10][INFO] global_step=118048, episodic_reward_predictor_return=0.2388019561767578\n",
      "[2023-09-13 13:57:10][INFO] global_step=118048, episodic_env_return=72.0\n",
      "[2023-09-13 13:57:10][INFO] global_step=118048, episodic_reward_predictor_return=-0.811307430267334\n",
      "[2023-09-13 13:57:10][INFO] global_step=118048, episodic_env_return=49.0\n",
      "[2023-09-13 13:57:10][INFO] global_step=118056, episodic_reward_predictor_return=0.26824307441711426\n",
      "[2023-09-13 13:57:10][INFO] global_step=118056, episodic_env_return=62.0\n",
      "[2023-09-13 13:57:11][INFO] global_step=118104, episodic_reward_predictor_return=0.36489832401275635\n",
      "[2023-09-13 13:57:11][INFO] global_step=118104, episodic_env_return=95.0\n",
      "[2023-09-13 13:57:12][INFO] global_step=118128, episodic_reward_predictor_return=0.0965178906917572\n",
      "[2023-09-13 13:57:12][INFO] global_step=118128, episodic_env_return=91.0\n",
      "[2023-09-13 13:57:13][INFO] global_step=118216, episodic_reward_predictor_return=0.41642865538597107\n",
      "[2023-09-13 13:57:13][INFO] global_step=118216, episodic_env_return=74.0\n",
      "[2023-09-13 13:57:13][INFO] global_step=118224, episodic_reward_predictor_return=-0.058803461492061615\n",
      "[2023-09-13 13:57:13][INFO] global_step=118224, episodic_env_return=86.0\n",
      "[2023-09-13 13:57:14][INFO] global_step=118264, episodic_reward_predictor_return=-0.2280658334493637\n",
      "[2023-09-13 13:57:14][INFO] global_step=118264, episodic_env_return=34.0\n",
      "[2023-09-13 13:57:15][INFO] global_step=118280, episodic_reward_predictor_return=0.19534538686275482\n",
      "[2023-09-13 13:57:15][INFO] global_step=118280, episodic_env_return=94.0\n",
      "[2023-09-13 13:57:15][INFO] global_step=118288, episodic_reward_predictor_return=0.04134949669241905\n",
      "[2023-09-13 13:57:15][INFO] global_step=118288, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:15][INFO] global_step=118304, episodic_reward_predictor_return=0.54320228099823\n",
      "[2023-09-13 13:57:15][INFO] global_step=118304, episodic_env_return=63.0\n",
      "[2023-09-13 13:57:15][INFO] global_step=118304, episodic_reward_predictor_return=0.08886613696813583\n",
      "[2023-09-13 13:57:15][INFO] global_step=118304, episodic_env_return=64.0\n",
      "[2023-09-13 13:57:15][INFO] global_step=118328, episodic_reward_predictor_return=-0.12745168805122375\n",
      "[2023-09-13 13:57:15][INFO] global_step=118328, episodic_env_return=71.0\n",
      "[2023-09-13 13:57:16][INFO] global_step=118352, episodic_reward_predictor_return=0.31869927048683167\n",
      "[2023-09-13 13:57:16][INFO] global_step=118352, episodic_env_return=95.0\n",
      "[2023-09-13 13:57:16][INFO] global_step=118376, episodic_reward_predictor_return=0.3172381520271301\n",
      "[2023-09-13 13:57:16][INFO] global_step=118376, episodic_env_return=87.0\n",
      "[2023-09-13 13:57:17][INFO] global_step=118408, episodic_reward_predictor_return=0.38709500432014465\n",
      "[2023-09-13 13:57:17][INFO] global_step=118408, episodic_env_return=88.0\n",
      "[2023-09-13 13:57:17][INFO] global_step=118448, episodic_reward_predictor_return=0.018616333603858948\n",
      "[2023-09-13 13:57:17][INFO] global_step=118448, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:18][INFO] global_step=118488, episodic_reward_predictor_return=0.01726910099387169\n",
      "[2023-09-13 13:57:18][INFO] global_step=118488, episodic_env_return=75.0\n",
      "[2023-09-13 13:57:18][INFO] global_step=118496, episodic_reward_predictor_return=0.2647455930709839\n",
      "[2023-09-13 13:57:18][INFO] global_step=118496, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:18][INFO] global_step=118504, episodic_reward_predictor_return=0.06558150053024292\n",
      "[2023-09-13 13:57:18][INFO] global_step=118504, episodic_env_return=69.0\n",
      "[2023-09-13 13:57:19][INFO] global_step=118528, episodic_reward_predictor_return=0.07388348132371902\n",
      "[2023-09-13 13:57:19][INFO] global_step=118528, episodic_env_return=91.0\n",
      "[2023-09-13 13:57:20][INFO] global_step=118584, episodic_reward_predictor_return=-0.1532728374004364\n",
      "[2023-09-13 13:57:20][INFO] global_step=118584, episodic_env_return=91.0\n",
      "[2023-09-13 13:57:20][INFO] global_step=118608, episodic_reward_predictor_return=0.2244335561990738\n",
      "[2023-09-13 13:57:20][INFO] global_step=118608, episodic_env_return=61.0\n",
      "[2023-09-13 13:57:21][INFO] global_step=118632, episodic_reward_predictor_return=0.496587336063385\n",
      "[2023-09-13 13:57:21][INFO] global_step=118632, episodic_env_return=84.0\n",
      "[2023-09-13 13:57:21][INFO] global_step=118656, episodic_reward_predictor_return=0.1474204957485199\n",
      "[2023-09-13 13:57:21][INFO] global_step=118656, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:23][INFO] global_step=118776, episodic_reward_predictor_return=0.0013150647282600403\n",
      "[2023-09-13 13:57:23][INFO] global_step=118776, episodic_env_return=83.0\n",
      "[2023-09-13 13:57:23][INFO] Current Mean Episodic Return = 0.12500262260437012\n",
      "[2023-09-13 13:57:23][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_118784`...\n",
      "[2023-09-13 13:57:23][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_118784`!\n",
      "[2023-09-13 13:57:26][INFO] SPS: 22\n",
      "[2023-09-13 13:57:27][INFO] global_step=118864, episodic_reward_predictor_return=0.23206117749214172\n",
      "[2023-09-13 13:57:27][INFO] global_step=118864, episodic_env_return=49.0\n",
      "[2023-09-13 13:57:27][INFO] global_step=118864, episodic_reward_predictor_return=-0.23793065547943115\n",
      "[2023-09-13 13:57:27][INFO] global_step=118864, episodic_env_return=64.0\n",
      "[2023-09-13 13:57:29][INFO] global_step=118952, episodic_reward_predictor_return=-0.03882455453276634\n",
      "[2023-09-13 13:57:29][INFO] global_step=118952, episodic_env_return=33.0\n",
      "[2023-09-13 13:57:30][INFO] global_step=119024, episodic_reward_predictor_return=0.33493152260780334\n",
      "[2023-09-13 13:57:30][INFO] global_step=119024, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:30][INFO] global_step=119040, episodic_reward_predictor_return=0.27784889936447144\n",
      "[2023-09-13 13:57:30][INFO] global_step=119040, episodic_env_return=79.0\n",
      "[2023-09-13 13:57:30][INFO] global_step=119048, episodic_reward_predictor_return=0.35192441940307617\n",
      "[2023-09-13 13:57:30][INFO] global_step=119048, episodic_env_return=-6.0\n",
      "[2023-09-13 13:57:30][INFO] global_step=119064, episodic_reward_predictor_return=-0.5491752028465271\n",
      "[2023-09-13 13:57:30][INFO] global_step=119064, episodic_env_return=40.0\n",
      "[2023-09-13 13:57:32][INFO] global_step=119160, episodic_reward_predictor_return=-0.021025385707616806\n",
      "[2023-09-13 13:57:32][INFO] global_step=119160, episodic_env_return=43.0\n",
      "[2023-09-13 13:57:33][INFO] global_step=119224, episodic_reward_predictor_return=0.03918932378292084\n",
      "[2023-09-13 13:57:33][INFO] global_step=119224, episodic_env_return=78.0\n",
      "[2023-09-13 13:57:33][INFO] global_step=119240, episodic_reward_predictor_return=0.22351622581481934\n",
      "[2023-09-13 13:57:33][INFO] global_step=119240, episodic_env_return=72.0\n",
      "[2023-09-13 13:57:34][INFO] global_step=119304, episodic_reward_predictor_return=0.31907135248184204\n",
      "[2023-09-13 13:57:34][INFO] global_step=119304, episodic_env_return=91.0\n",
      "[2023-09-13 13:57:35][INFO] global_step=119328, episodic_reward_predictor_return=0.17071032524108887\n",
      "[2023-09-13 13:57:35][INFO] global_step=119328, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:36][INFO] global_step=119384, episodic_reward_predictor_return=0.3094998300075531\n",
      "[2023-09-13 13:57:36][INFO] global_step=119384, episodic_env_return=26.0\n",
      "[2023-09-13 13:57:36][INFO] global_step=119424, episodic_reward_predictor_return=0.7124857306480408\n",
      "[2023-09-13 13:57:36][INFO] global_step=119424, episodic_env_return=56.0\n",
      "[2023-09-13 13:57:38][INFO] global_step=119504, episodic_reward_predictor_return=0.4788338840007782\n",
      "[2023-09-13 13:57:38][INFO] global_step=119504, episodic_env_return=58.0\n",
      "[2023-09-13 13:57:38][INFO] global_step=119512, episodic_reward_predictor_return=0.12265327572822571\n",
      "[2023-09-13 13:57:38][INFO] global_step=119512, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:38][INFO] global_step=119520, episodic_reward_predictor_return=0.11137019842863083\n",
      "[2023-09-13 13:57:38][INFO] global_step=119520, episodic_env_return=74.0\n",
      "[2023-09-13 13:57:38][INFO] global_step=119544, episodic_reward_predictor_return=-0.41038778424263\n",
      "[2023-09-13 13:57:38][INFO] global_step=119544, episodic_env_return=21.0\n",
      "[2023-09-13 13:57:39][INFO] global_step=119560, episodic_reward_predictor_return=-0.07275446504354477\n",
      "[2023-09-13 13:57:39][INFO] global_step=119560, episodic_env_return=67.0\n",
      "[2023-09-13 13:57:39][INFO] global_step=119592, episodic_reward_predictor_return=0.14508302509784698\n",
      "[2023-09-13 13:57:39][INFO] global_step=119592, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:39][INFO] global_step=119600, episodic_reward_predictor_return=0.54201340675354\n",
      "[2023-09-13 13:57:39][INFO] global_step=119600, episodic_env_return=89.0\n",
      "[2023-09-13 13:57:40][INFO] global_step=119640, episodic_reward_predictor_return=0.11606618762016296\n",
      "[2023-09-13 13:57:40][INFO] global_step=119640, episodic_env_return=64.0\n",
      "[2023-09-13 13:57:40][INFO] global_step=119656, episodic_reward_predictor_return=0.2814027667045593\n",
      "[2023-09-13 13:57:40][INFO] global_step=119656, episodic_env_return=83.0\n",
      "[2023-09-13 13:57:41][INFO] global_step=119720, episodic_reward_predictor_return=0.4923454523086548\n",
      "[2023-09-13 13:57:41][INFO] global_step=119720, episodic_env_return=81.0\n",
      "[2023-09-13 13:57:43][INFO] global_step=119840, episodic_reward_predictor_return=-0.0035081617534160614\n",
      "[2023-09-13 13:57:43][INFO] global_step=119840, episodic_env_return=59.0\n",
      "[2023-09-13 13:57:43][INFO] global_step=119840, episodic_reward_predictor_return=0.23167215287685394\n",
      "[2023-09-13 13:57:43][INFO] global_step=119840, episodic_env_return=71.0\n",
      "[2023-09-13 13:57:43][INFO] global_step=119856, episodic_reward_predictor_return=-1.941782832145691\n",
      "[2023-09-13 13:57:43][INFO] global_step=119856, episodic_env_return=-375.0\n",
      "[2023-09-13 13:57:44][INFO] global_step=119912, episodic_reward_predictor_return=-0.20798420906066895\n",
      "[2023-09-13 13:57:44][INFO] global_step=119912, episodic_env_return=56.0\n",
      "[2023-09-13 13:57:44][INFO] global_step=119912, episodic_reward_predictor_return=0.0740349218249321\n",
      "[2023-09-13 13:57:44][INFO] global_step=119912, episodic_env_return=92.0\n",
      "[2023-09-13 13:57:45][INFO] global_step=119944, episodic_reward_predictor_return=0.24510535597801208\n",
      "[2023-09-13 13:57:45][INFO] global_step=119944, episodic_env_return=53.0\n",
      "[2023-09-13 13:57:46][INFO] global_step=120000, episodic_reward_predictor_return=0.3351413905620575\n",
      "[2023-09-13 13:57:46][INFO] global_step=120000, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:46][INFO] global_step=120000, episodic_reward_predictor_return=0.014590483158826828\n",
      "[2023-09-13 13:57:46][INFO] global_step=120000, episodic_env_return=53.0\n",
      "[2023-09-13 13:57:47][INFO] global_step=120040, episodic_reward_predictor_return=-0.22499966621398926\n",
      "[2023-09-13 13:57:47][INFO] global_step=120040, episodic_env_return=51.0\n",
      "[2023-09-13 13:57:47][INFO] global_step=120048, episodic_reward_predictor_return=0.0628466010093689\n",
      "[2023-09-13 13:57:47][INFO] global_step=120048, episodic_env_return=72.0\n",
      "[2023-09-13 13:57:47][INFO] global_step=120088, episodic_reward_predictor_return=0.06864085048437119\n",
      "[2023-09-13 13:57:47][INFO] global_step=120088, episodic_env_return=95.0\n",
      "[2023-09-13 13:57:48][INFO] global_step=120112, episodic_reward_predictor_return=-0.13359728455543518\n",
      "[2023-09-13 13:57:48][INFO] global_step=120112, episodic_env_return=71.0\n",
      "[2023-09-13 13:57:49][INFO] global_step=120152, episodic_reward_predictor_return=-0.1469273418188095\n",
      "[2023-09-13 13:57:49][INFO] global_step=120152, episodic_env_return=52.0\n",
      "[2023-09-13 13:57:49][INFO] global_step=120168, episodic_reward_predictor_return=0.26075753569602966\n",
      "[2023-09-13 13:57:49][INFO] global_step=120168, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:50][INFO] global_step=120232, episodic_reward_predictor_return=-0.32353273034095764\n",
      "[2023-09-13 13:57:50][INFO] global_step=120232, episodic_env_return=67.0\n",
      "[2023-09-13 13:57:51][INFO] global_step=120272, episodic_reward_predictor_return=0.17477160692214966\n",
      "[2023-09-13 13:57:51][INFO] global_step=120272, episodic_env_return=78.0\n",
      "[2023-09-13 13:57:52][INFO] global_step=120344, episodic_reward_predictor_return=0.5459323525428772\n",
      "[2023-09-13 13:57:52][INFO] global_step=120344, episodic_env_return=79.0\n",
      "[2023-09-13 13:57:52][INFO] global_step=120344, episodic_reward_predictor_return=-3.760889768600464\n",
      "[2023-09-13 13:57:52][INFO] global_step=120344, episodic_env_return=-375.0\n",
      "[2023-09-13 13:57:53][INFO] global_step=120384, episodic_reward_predictor_return=0.3956455886363983\n",
      "[2023-09-13 13:57:53][INFO] global_step=120384, episodic_env_return=87.0\n",
      "[2023-09-13 13:57:53][INFO] global_step=120384, episodic_reward_predictor_return=-1.2694181203842163\n",
      "[2023-09-13 13:57:53][INFO] global_step=120384, episodic_env_return=43.0\n",
      "[2023-09-13 13:57:53][INFO] global_step=120392, episodic_reward_predictor_return=0.08221421390771866\n",
      "[2023-09-13 13:57:53][INFO] global_step=120392, episodic_env_return=66.0\n",
      "[2023-09-13 13:57:53][INFO] global_step=120432, episodic_reward_predictor_return=0.4527550935745239\n",
      "[2023-09-13 13:57:53][INFO] global_step=120432, episodic_env_return=90.0\n",
      "[2023-09-13 13:57:54][INFO] global_step=120448, episodic_reward_predictor_return=0.48276665806770325\n",
      "[2023-09-13 13:57:54][INFO] global_step=120448, episodic_env_return=88.0\n",
      "[2023-09-13 13:57:54][INFO] global_step=120448, episodic_reward_predictor_return=0.2552858889102936\n",
      "[2023-09-13 13:57:54][INFO] global_step=120448, episodic_env_return=74.0\n",
      "[2023-09-13 13:57:55][INFO] global_step=120496, episodic_reward_predictor_return=0.15098457038402557\n",
      "[2023-09-13 13:57:55][INFO] global_step=120496, episodic_env_return=87.0\n",
      "[2023-09-13 13:57:55][INFO] global_step=120520, episodic_reward_predictor_return=0.0789647102355957\n",
      "[2023-09-13 13:57:55][INFO] global_step=120520, episodic_env_return=84.0\n",
      "[2023-09-13 13:57:56][INFO] global_step=120568, episodic_reward_predictor_return=-0.16395454108715057\n",
      "[2023-09-13 13:57:56][INFO] global_step=120568, episodic_env_return=74.0\n",
      "[2023-09-13 13:57:57][INFO] global_step=120616, episodic_reward_predictor_return=0.2816084027290344\n",
      "[2023-09-13 13:57:57][INFO] global_step=120616, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:57][INFO] global_step=120616, episodic_reward_predictor_return=0.3215523958206177\n",
      "[2023-09-13 13:57:57][INFO] global_step=120616, episodic_env_return=89.0\n",
      "[2023-09-13 13:57:57][INFO] global_step=120632, episodic_reward_predictor_return=0.08005375415086746\n",
      "[2023-09-13 13:57:57][INFO] global_step=120632, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:58][INFO] global_step=120720, episodic_reward_predictor_return=0.12883682548999786\n",
      "[2023-09-13 13:57:58][INFO] global_step=120720, episodic_env_return=88.0\n",
      "[2023-09-13 13:57:59][INFO] global_step=120736, episodic_reward_predictor_return=0.0788843035697937\n",
      "[2023-09-13 13:57:59][INFO] global_step=120736, episodic_env_return=86.0\n",
      "[2023-09-13 13:57:59][INFO] global_step=120752, episodic_reward_predictor_return=-0.02812889777123928\n",
      "[2023-09-13 13:57:59][INFO] global_step=120752, episodic_env_return=73.0\n",
      "[2023-09-13 13:57:59][INFO] global_step=120752, episodic_reward_predictor_return=-0.33761581778526306\n",
      "[2023-09-13 13:57:59][INFO] global_step=120752, episodic_env_return=64.0\n",
      "[2023-09-13 13:58:00][INFO] global_step=120800, episodic_reward_predictor_return=-0.010691031813621521\n",
      "[2023-09-13 13:58:00][INFO] global_step=120800, episodic_env_return=91.0\n",
      "[2023-09-13 13:58:00][INFO] Current Mean Episodic Return = 0.0030665153171867132\n",
      "[2023-09-13 13:58:00][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_120832`...\n",
      "[2023-09-13 13:58:00][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_120832`!\n",
      "[2023-09-13 13:58:03][INFO] SPS: 22\n",
      "[2023-09-13 13:58:03][INFO] global_step=120848, episodic_reward_predictor_return=-0.03804678097367287\n",
      "[2023-09-13 13:58:03][INFO] global_step=120848, episodic_env_return=69.0\n",
      "[2023-09-13 13:58:04][INFO] global_step=120872, episodic_reward_predictor_return=0.06070889160037041\n",
      "[2023-09-13 13:58:04][INFO] global_step=120872, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:04][INFO] global_step=120888, episodic_reward_predictor_return=0.4040660858154297\n",
      "[2023-09-13 13:58:04][INFO] global_step=120888, episodic_env_return=84.0\n",
      "[2023-09-13 13:58:05][INFO] global_step=120928, episodic_reward_predictor_return=0.03210202604532242\n",
      "[2023-09-13 13:58:05][INFO] global_step=120928, episodic_env_return=72.0\n",
      "[2023-09-13 13:58:05][INFO] global_step=120936, episodic_reward_predictor_return=0.06151824817061424\n",
      "[2023-09-13 13:58:05][INFO] global_step=120936, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:06][INFO] global_step=121016, episodic_reward_predictor_return=0.13255295157432556\n",
      "[2023-09-13 13:58:06][INFO] global_step=121016, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:06][INFO] global_step=121024, episodic_reward_predictor_return=0.26355957984924316\n",
      "[2023-09-13 13:58:06][INFO] global_step=121024, episodic_env_return=89.0\n",
      "[2023-09-13 13:58:07][INFO] global_step=121056, episodic_reward_predictor_return=0.09092995524406433\n",
      "[2023-09-13 13:58:07][INFO] global_step=121056, episodic_env_return=86.0\n",
      "[2023-09-13 13:58:07][INFO] global_step=121096, episodic_reward_predictor_return=0.0015025027096271515\n",
      "[2023-09-13 13:58:07][INFO] global_step=121096, episodic_env_return=53.0\n",
      "[2023-09-13 13:58:09][INFO] global_step=121216, episodic_reward_predictor_return=0.30433863401412964\n",
      "[2023-09-13 13:58:09][INFO] global_step=121216, episodic_env_return=71.0\n",
      "[2023-09-13 13:58:10][INFO] global_step=121240, episodic_reward_predictor_return=0.042672768235206604\n",
      "[2023-09-13 13:58:10][INFO] global_step=121240, episodic_env_return=74.0\n",
      "[2023-09-13 13:58:10][INFO] global_step=121248, episodic_reward_predictor_return=-1.9993449449539185\n",
      "[2023-09-13 13:58:10][INFO] global_step=121248, episodic_env_return=-29.0\n",
      "[2023-09-13 13:58:10][INFO] global_step=121280, episodic_reward_predictor_return=-0.07991769909858704\n",
      "[2023-09-13 13:58:10][INFO] global_step=121280, episodic_env_return=73.0\n",
      "[2023-09-13 13:58:11][INFO] global_step=121320, episodic_reward_predictor_return=0.13261714577674866\n",
      "[2023-09-13 13:58:11][INFO] global_step=121320, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:11][INFO] global_step=121328, episodic_reward_predictor_return=0.16270336508750916\n",
      "[2023-09-13 13:58:11][INFO] global_step=121328, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:11][INFO] global_step=121336, episodic_reward_predictor_return=-0.3580865263938904\n",
      "[2023-09-13 13:58:11][INFO] global_step=121336, episodic_env_return=61.0\n",
      "[2023-09-13 13:58:12][INFO] global_step=121352, episodic_reward_predictor_return=0.16731630265712738\n",
      "[2023-09-13 13:58:12][INFO] global_step=121352, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:12][INFO] global_step=121368, episodic_reward_predictor_return=-2.6669697761535645\n",
      "[2023-09-13 13:58:12][INFO] global_step=121368, episodic_env_return=-99.0\n",
      "[2023-09-13 13:58:13][INFO] global_step=121448, episodic_reward_predictor_return=0.14272546768188477\n",
      "[2023-09-13 13:58:13][INFO] global_step=121448, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:15][INFO] global_step=121536, episodic_reward_predictor_return=0.3186664879322052\n",
      "[2023-09-13 13:58:15][INFO] global_step=121536, episodic_env_return=76.0\n",
      "[2023-09-13 13:58:15][INFO] global_step=121536, episodic_reward_predictor_return=0.38508743047714233\n",
      "[2023-09-13 13:58:15][INFO] global_step=121536, episodic_env_return=56.0\n",
      "[2023-09-13 13:58:15][INFO] global_step=121552, episodic_reward_predictor_return=-0.19183725118637085\n",
      "[2023-09-13 13:58:15][INFO] global_step=121552, episodic_env_return=73.0\n",
      "[2023-09-13 13:58:16][INFO] global_step=121592, episodic_reward_predictor_return=0.41126492619514465\n",
      "[2023-09-13 13:58:16][INFO] global_step=121592, episodic_env_return=83.0\n",
      "[2023-09-13 13:58:16][INFO] global_step=121592, episodic_reward_predictor_return=0.1325533539056778\n",
      "[2023-09-13 13:58:16][INFO] global_step=121592, episodic_env_return=-119.0\n",
      "[2023-09-13 13:58:16][INFO] global_step=121608, episodic_reward_predictor_return=-0.008229135535657406\n",
      "[2023-09-13 13:58:16][INFO] global_step=121608, episodic_env_return=94.0\n",
      "[2023-09-13 13:58:16][INFO] global_step=121616, episodic_reward_predictor_return=0.25641679763793945\n",
      "[2023-09-13 13:58:16][INFO] global_step=121616, episodic_env_return=65.0\n",
      "[2023-09-13 13:58:18][INFO] global_step=121704, episodic_reward_predictor_return=0.14786195755004883\n",
      "[2023-09-13 13:58:18][INFO] global_step=121704, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:18][INFO] global_step=121704, episodic_reward_predictor_return=0.05786866694688797\n",
      "[2023-09-13 13:58:18][INFO] global_step=121704, episodic_env_return=87.0\n",
      "[2023-09-13 13:58:18][INFO] global_step=121744, episodic_reward_predictor_return=-0.4886297285556793\n",
      "[2023-09-13 13:58:18][INFO] global_step=121744, episodic_env_return=42.0\n",
      "[2023-09-13 13:58:19][INFO] global_step=121752, episodic_reward_predictor_return=-0.03050236776471138\n",
      "[2023-09-13 13:58:19][INFO] global_step=121752, episodic_env_return=74.0\n",
      "[2023-09-13 13:58:19][INFO] global_step=121800, episodic_reward_predictor_return=0.6421492695808411\n",
      "[2023-09-13 13:58:19][INFO] global_step=121800, episodic_env_return=68.0\n",
      "[2023-09-13 13:58:20][INFO] global_step=121840, episodic_reward_predictor_return=0.21613198518753052\n",
      "[2023-09-13 13:58:20][INFO] global_step=121840, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:21][INFO] global_step=121880, episodic_reward_predictor_return=-0.019174622371792793\n",
      "[2023-09-13 13:58:21][INFO] global_step=121880, episodic_env_return=74.0\n",
      "[2023-09-13 13:58:22][INFO] global_step=121952, episodic_reward_predictor_return=0.48288077116012573\n",
      "[2023-09-13 13:58:22][INFO] global_step=121952, episodic_env_return=65.0\n",
      "[2023-09-13 13:58:22][INFO] global_step=121960, episodic_reward_predictor_return=0.3118463456630707\n",
      "[2023-09-13 13:58:22][INFO] global_step=121960, episodic_env_return=86.0\n",
      "[2023-09-13 13:58:22][INFO] global_step=121976, episodic_reward_predictor_return=-0.31184524297714233\n",
      "[2023-09-13 13:58:22][INFO] global_step=121976, episodic_env_return=43.0\n",
      "[2023-09-13 13:58:22][INFO] global_step=121984, episodic_reward_predictor_return=0.17961803078651428\n",
      "[2023-09-13 13:58:22][INFO] global_step=121984, episodic_env_return=73.0\n",
      "[2023-09-13 13:58:23][INFO] global_step=122048, episodic_reward_predictor_return=-0.39081865549087524\n",
      "[2023-09-13 13:58:23][INFO] global_step=122048, episodic_env_return=36.0\n",
      "[2023-09-13 13:58:24][INFO] global_step=122064, episodic_reward_predictor_return=0.3089815378189087\n",
      "[2023-09-13 13:58:24][INFO] global_step=122064, episodic_env_return=78.0\n",
      "[2023-09-13 13:58:24][INFO] global_step=122080, episodic_reward_predictor_return=-0.03440038487315178\n",
      "[2023-09-13 13:58:24][INFO] global_step=122080, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:24][INFO] global_step=122096, episodic_reward_predictor_return=0.05945596098899841\n",
      "[2023-09-13 13:58:24][INFO] global_step=122096, episodic_env_return=86.0\n",
      "[2023-09-13 13:58:25][INFO] global_step=122112, episodic_reward_predictor_return=0.1755809336900711\n",
      "[2023-09-13 13:58:25][INFO] global_step=122112, episodic_env_return=95.0\n",
      "[2023-09-13 13:58:25][INFO] global_step=122136, episodic_reward_predictor_return=-0.2566598951816559\n",
      "[2023-09-13 13:58:25][INFO] global_step=122136, episodic_env_return=42.0\n",
      "[2023-09-13 13:58:25][INFO] global_step=122152, episodic_reward_predictor_return=0.09298993647098541\n",
      "[2023-09-13 13:58:25][INFO] global_step=122152, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:26][INFO] global_step=122176, episodic_reward_predictor_return=0.22145411372184753\n",
      "[2023-09-13 13:58:26][INFO] global_step=122176, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:26][INFO] global_step=122208, episodic_reward_predictor_return=0.19611063599586487\n",
      "[2023-09-13 13:58:26][INFO] global_step=122208, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:27][INFO] global_step=122256, episodic_reward_predictor_return=0.2453932911157608\n",
      "[2023-09-13 13:58:27][INFO] global_step=122256, episodic_env_return=88.0\n",
      "[2023-09-13 13:58:27][INFO] global_step=122256, episodic_reward_predictor_return=0.1481751799583435\n",
      "[2023-09-13 13:58:27][INFO] global_step=122256, episodic_env_return=59.0\n",
      "[2023-09-13 13:58:28][INFO] global_step=122296, episodic_reward_predictor_return=0.20769745111465454\n",
      "[2023-09-13 13:58:28][INFO] global_step=122296, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:28][INFO] global_step=122304, episodic_reward_predictor_return=0.06018255278468132\n",
      "[2023-09-13 13:58:28][INFO] global_step=122304, episodic_env_return=70.0\n",
      "[2023-09-13 13:58:28][INFO] global_step=122336, episodic_reward_predictor_return=0.07745323330163956\n",
      "[2023-09-13 13:58:28][INFO] global_step=122336, episodic_env_return=91.0\n",
      "[2023-09-13 13:58:29][INFO] global_step=122384, episodic_reward_predictor_return=0.4379376471042633\n",
      "[2023-09-13 13:58:29][INFO] global_step=122384, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:29][INFO] global_step=122392, episodic_reward_predictor_return=1.0319818258285522\n",
      "[2023-09-13 13:58:29][INFO] global_step=122392, episodic_env_return=-124.0\n",
      "[2023-09-13 13:58:30][INFO] global_step=122432, episodic_reward_predictor_return=0.31596001982688904\n",
      "[2023-09-13 13:58:30][INFO] global_step=122432, episodic_env_return=84.0\n",
      "[2023-09-13 13:58:31][INFO] global_step=122472, episodic_reward_predictor_return=0.1545809507369995\n",
      "[2023-09-13 13:58:31][INFO] global_step=122472, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:31][INFO] global_step=122504, episodic_reward_predictor_return=0.6658979654312134\n",
      "[2023-09-13 13:58:31][INFO] global_step=122504, episodic_env_return=80.0\n",
      "[2023-09-13 13:58:31][INFO] global_step=122504, episodic_reward_predictor_return=0.4360100328922272\n",
      "[2023-09-13 13:58:31][INFO] global_step=122504, episodic_env_return=76.0\n",
      "[2023-09-13 13:58:32][INFO] global_step=122520, episodic_reward_predictor_return=0.059926871210336685\n",
      "[2023-09-13 13:58:32][INFO] global_step=122520, episodic_env_return=45.0\n",
      "[2023-09-13 13:58:32][INFO] global_step=122544, episodic_reward_predictor_return=0.15805484354496002\n",
      "[2023-09-13 13:58:32][INFO] global_step=122544, episodic_env_return=55.0\n",
      "[2023-09-13 13:58:33][INFO] global_step=122592, episodic_reward_predictor_return=0.15539658069610596\n",
      "[2023-09-13 13:58:33][INFO] global_step=122592, episodic_env_return=86.0\n",
      "[2023-09-13 13:58:33][INFO] global_step=122600, episodic_reward_predictor_return=0.257928729057312\n",
      "[2023-09-13 13:58:33][INFO] global_step=122600, episodic_env_return=89.0\n",
      "[2023-09-13 13:58:33][INFO] global_step=122632, episodic_reward_predictor_return=0.02792615257203579\n",
      "[2023-09-13 13:58:33][INFO] global_step=122632, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:34][INFO] global_step=122640, episodic_reward_predictor_return=-0.5772711038589478\n",
      "[2023-09-13 13:58:34][INFO] global_step=122640, episodic_env_return=-6.0\n",
      "[2023-09-13 13:58:34][INFO] global_step=122648, episodic_reward_predictor_return=0.11537901312112808\n",
      "[2023-09-13 13:58:34][INFO] global_step=122648, episodic_env_return=85.0\n",
      "[2023-09-13 13:58:34][INFO] global_step=122664, episodic_reward_predictor_return=-0.370296835899353\n",
      "[2023-09-13 13:58:34][INFO] global_step=122664, episodic_env_return=62.0\n",
      "[2023-09-13 13:58:34][INFO] global_step=122680, episodic_reward_predictor_return=-0.10446695983409882\n",
      "[2023-09-13 13:58:34][INFO] global_step=122680, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:35][INFO] global_step=122712, episodic_reward_predictor_return=0.4223553240299225\n",
      "[2023-09-13 13:58:35][INFO] global_step=122712, episodic_env_return=91.0\n",
      "[2023-09-13 13:58:35][INFO] global_step=122720, episodic_reward_predictor_return=0.3774903118610382\n",
      "[2023-09-13 13:58:35][INFO] global_step=122720, episodic_env_return=79.0\n",
      "[2023-09-13 13:58:35][INFO] global_step=122728, episodic_reward_predictor_return=-0.0952414944767952\n",
      "[2023-09-13 13:58:35][INFO] global_step=122728, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:36][INFO] global_step=122752, episodic_reward_predictor_return=0.27505895495414734\n",
      "[2023-09-13 13:58:36][INFO] global_step=122752, episodic_env_return=88.0\n",
      "[2023-09-13 13:58:37][INFO] global_step=122808, episodic_reward_predictor_return=0.1350276917219162\n",
      "[2023-09-13 13:58:37][INFO] global_step=122808, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:37][INFO] global_step=122824, episodic_reward_predictor_return=0.4298724830150604\n",
      "[2023-09-13 13:58:37][INFO] global_step=122824, episodic_env_return=87.0\n",
      "[2023-09-13 13:58:38][INFO] global_step=122872, episodic_reward_predictor_return=0.2557603716850281\n",
      "[2023-09-13 13:58:38][INFO] global_step=122872, episodic_env_return=67.0\n",
      "[2023-09-13 13:58:38][INFO] Current Mean Episodic Return = 0.06884850561618805\n",
      "[2023-09-13 13:58:38][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_122880`...\n",
      "[2023-09-13 13:58:38][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_122880`!\n",
      "[2023-09-13 13:58:41][INFO] SPS: 23\n",
      "[2023-09-13 13:58:41][INFO] global_step=122920, episodic_reward_predictor_return=0.23253624141216278\n",
      "[2023-09-13 13:58:41][INFO] global_step=122920, episodic_env_return=89.0\n",
      "[2023-09-13 13:58:41][INFO] global_step=122928, episodic_reward_predictor_return=0.08140335232019424\n",
      "[2023-09-13 13:58:41][INFO] global_step=122928, episodic_env_return=68.0\n",
      "[2023-09-13 13:58:42][INFO] global_step=122936, episodic_reward_predictor_return=0.04230278730392456\n",
      "[2023-09-13 13:58:42][INFO] global_step=122936, episodic_env_return=70.0\n",
      "[2023-09-13 13:58:43][INFO] global_step=123016, episodic_reward_predictor_return=-0.02648877166211605\n",
      "[2023-09-13 13:58:43][INFO] global_step=123016, episodic_env_return=89.0\n",
      "[2023-09-13 13:58:43][INFO] global_step=123056, episodic_reward_predictor_return=0.14807972311973572\n",
      "[2023-09-13 13:58:43][INFO] global_step=123056, episodic_env_return=49.0\n",
      "[2023-09-13 13:58:45][INFO] global_step=123136, episodic_reward_predictor_return=0.026219192892313004\n",
      "[2023-09-13 13:58:45][INFO] global_step=123136, episodic_env_return=60.0\n",
      "[2023-09-13 13:58:46][INFO] global_step=123216, episodic_reward_predictor_return=-0.14864234626293182\n",
      "[2023-09-13 13:58:46][INFO] global_step=123216, episodic_env_return=65.0\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_reward_predictor_return=-0.16149477660655975\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_env_return=27.0\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_reward_predictor_return=0.28309333324432373\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_reward_predictor_return=0.279358834028244\n",
      "[2023-09-13 13:58:46][INFO] global_step=123224, episodic_env_return=75.0\n",
      "[2023-09-13 13:58:47][INFO] global_step=123296, episodic_reward_predictor_return=0.25429999828338623\n",
      "[2023-09-13 13:58:47][INFO] global_step=123296, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:47][INFO] global_step=123296, episodic_reward_predictor_return=-0.05967479199171066\n",
      "[2023-09-13 13:58:47][INFO] global_step=123296, episodic_env_return=51.0\n",
      "[2023-09-13 13:58:48][INFO] global_step=123320, episodic_reward_predictor_return=0.28350695967674255\n",
      "[2023-09-13 13:58:48][INFO] global_step=123320, episodic_env_return=89.0\n",
      "[2023-09-13 13:58:49][INFO] global_step=123392, episodic_reward_predictor_return=0.008640751242637634\n",
      "[2023-09-13 13:58:49][INFO] global_step=123392, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:49][INFO] global_step=123400, episodic_reward_predictor_return=0.2551004886627197\n",
      "[2023-09-13 13:58:49][INFO] global_step=123400, episodic_env_return=88.0\n",
      "[2023-09-13 13:58:50][INFO] global_step=123440, episodic_reward_predictor_return=0.32065582275390625\n",
      "[2023-09-13 13:58:50][INFO] global_step=123440, episodic_env_return=83.0\n",
      "[2023-09-13 13:58:51][INFO] global_step=123496, episodic_reward_predictor_return=-0.35341963171958923\n",
      "[2023-09-13 13:58:51][INFO] global_step=123496, episodic_env_return=62.0\n",
      "[2023-09-13 13:58:51][INFO] global_step=123512, episodic_reward_predictor_return=0.12569813430309296\n",
      "[2023-09-13 13:58:51][INFO] global_step=123512, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:52][INFO] global_step=123544, episodic_reward_predictor_return=0.09809157997369766\n",
      "[2023-09-13 13:58:52][INFO] global_step=123544, episodic_env_return=50.0\n",
      "[2023-09-13 13:58:52][INFO] global_step=123584, episodic_reward_predictor_return=0.12286456674337387\n",
      "[2023-09-13 13:58:52][INFO] global_step=123584, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:53][INFO] global_step=123616, episodic_reward_predictor_return=0.665475606918335\n",
      "[2023-09-13 13:58:53][INFO] global_step=123616, episodic_env_return=74.0\n",
      "[2023-09-13 13:58:53][INFO] global_step=123640, episodic_reward_predictor_return=0.5051206350326538\n",
      "[2023-09-13 13:58:53][INFO] global_step=123640, episodic_env_return=70.0\n",
      "[2023-09-13 13:58:53][INFO] global_step=123648, episodic_reward_predictor_return=0.16766521334648132\n",
      "[2023-09-13 13:58:53][INFO] global_step=123648, episodic_env_return=12.0\n",
      "[2023-09-13 13:58:55][INFO] global_step=123760, episodic_reward_predictor_return=0.22817334532737732\n",
      "[2023-09-13 13:58:55][INFO] global_step=123760, episodic_env_return=87.0\n",
      "[2023-09-13 13:58:56][INFO] global_step=123800, episodic_reward_predictor_return=-0.024490462616086006\n",
      "[2023-09-13 13:58:56][INFO] global_step=123800, episodic_env_return=63.0\n",
      "[2023-09-13 13:58:56][INFO] global_step=123808, episodic_reward_predictor_return=0.31403279304504395\n",
      "[2023-09-13 13:58:56][INFO] global_step=123808, episodic_env_return=68.0\n",
      "[2023-09-13 13:58:57][INFO] global_step=123856, episodic_reward_predictor_return=0.30255547165870667\n",
      "[2023-09-13 13:58:57][INFO] global_step=123856, episodic_env_return=-32.0\n",
      "[2023-09-13 13:58:58][INFO] global_step=123896, episodic_reward_predictor_return=-0.04378630965948105\n",
      "[2023-09-13 13:58:58][INFO] global_step=123896, episodic_env_return=90.0\n",
      "[2023-09-13 13:58:58][INFO] global_step=123904, episodic_reward_predictor_return=0.008154075592756271\n",
      "[2023-09-13 13:58:58][INFO] global_step=123904, episodic_env_return=88.0\n",
      "[2023-09-13 13:58:58][INFO] global_step=123912, episodic_reward_predictor_return=-0.44478583335876465\n",
      "[2023-09-13 13:58:58][INFO] global_step=123912, episodic_env_return=59.0\n",
      "[2023-09-13 13:58:58][INFO] global_step=123928, episodic_reward_predictor_return=0.14651156961917877\n",
      "[2023-09-13 13:58:58][INFO] global_step=123928, episodic_env_return=92.0\n",
      "[2023-09-13 13:58:58][INFO] global_step=123936, episodic_reward_predictor_return=0.5149624943733215\n",
      "[2023-09-13 13:58:58][INFO] global_step=123936, episodic_env_return=64.0\n",
      "[2023-09-13 13:59:00][INFO] global_step=124008, episodic_reward_predictor_return=0.5456700325012207\n",
      "[2023-09-13 13:59:00][INFO] global_step=124008, episodic_env_return=70.0\n",
      "[2023-09-13 13:59:00][INFO] global_step=124008, episodic_reward_predictor_return=0.15774336457252502\n",
      "[2023-09-13 13:59:00][INFO] global_step=124008, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:00][INFO] global_step=124016, episodic_reward_predictor_return=0.0561344251036644\n",
      "[2023-09-13 13:59:00][INFO] global_step=124016, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:00][INFO] global_step=124024, episodic_reward_predictor_return=0.295033723115921\n",
      "[2023-09-13 13:59:00][INFO] global_step=124024, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:00][INFO] global_step=124056, episodic_reward_predictor_return=0.0803157165646553\n",
      "[2023-09-13 13:59:00][INFO] global_step=124056, episodic_env_return=32.0\n",
      "[2023-09-13 13:59:01][INFO] global_step=124088, episodic_reward_predictor_return=0.11639537662267685\n",
      "[2023-09-13 13:59:01][INFO] global_step=124088, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:01][INFO] global_step=124088, episodic_reward_predictor_return=0.2007458359003067\n",
      "[2023-09-13 13:59:01][INFO] global_step=124088, episodic_env_return=78.0\n",
      "[2023-09-13 13:59:01][INFO] global_step=124096, episodic_reward_predictor_return=0.10214526951313019\n",
      "[2023-09-13 13:59:01][INFO] global_step=124096, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:03][INFO] global_step=124184, episodic_reward_predictor_return=0.11818589270114899\n",
      "[2023-09-13 13:59:03][INFO] global_step=124184, episodic_env_return=65.0\n",
      "[2023-09-13 13:59:03][INFO] global_step=124192, episodic_reward_predictor_return=0.3285471796989441\n",
      "[2023-09-13 13:59:03][INFO] global_step=124192, episodic_env_return=73.0\n",
      "[2023-09-13 13:59:04][INFO] global_step=124248, episodic_reward_predictor_return=-0.3382135331630707\n",
      "[2023-09-13 13:59:04][INFO] global_step=124248, episodic_env_return=67.0\n",
      "[2023-09-13 13:59:04][INFO] global_step=124272, episodic_reward_predictor_return=0.4314519166946411\n",
      "[2023-09-13 13:59:04][INFO] global_step=124272, episodic_env_return=78.0\n",
      "[2023-09-13 13:59:04][INFO] global_step=124280, episodic_reward_predictor_return=-0.16032527387142181\n",
      "[2023-09-13 13:59:04][INFO] global_step=124280, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:04][INFO] global_step=124280, episodic_reward_predictor_return=0.1603456735610962\n",
      "[2023-09-13 13:59:04][INFO] global_step=124280, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:05][INFO] global_step=124312, episodic_reward_predictor_return=0.250108927488327\n",
      "[2023-09-13 13:59:05][INFO] global_step=124312, episodic_env_return=74.0\n",
      "[2023-09-13 13:59:05][INFO] global_step=124336, episodic_reward_predictor_return=0.21168793737888336\n",
      "[2023-09-13 13:59:05][INFO] global_step=124336, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:07][INFO] global_step=124424, episodic_reward_predictor_return=0.5493242144584656\n",
      "[2023-09-13 13:59:07][INFO] global_step=124424, episodic_env_return=50.0\n",
      "[2023-09-13 13:59:08][INFO] global_step=124504, episodic_reward_predictor_return=0.060071155428886414\n",
      "[2023-09-13 13:59:08][INFO] global_step=124504, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:09][INFO] global_step=124544, episodic_reward_predictor_return=-0.3505036532878876\n",
      "[2023-09-13 13:59:09][INFO] global_step=124544, episodic_env_return=34.0\n",
      "[2023-09-13 13:59:09][INFO] global_step=124576, episodic_reward_predictor_return=0.014543110504746437\n",
      "[2023-09-13 13:59:09][INFO] global_step=124576, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:10][INFO] global_step=124640, episodic_reward_predictor_return=0.3935835361480713\n",
      "[2023-09-13 13:59:10][INFO] global_step=124640, episodic_env_return=46.0\n",
      "[2023-09-13 13:59:11][INFO] global_step=124648, episodic_reward_predictor_return=0.03388486057519913\n",
      "[2023-09-13 13:59:11][INFO] global_step=124648, episodic_env_return=55.0\n",
      "[2023-09-13 13:59:11][INFO] global_step=124648, episodic_reward_predictor_return=0.11694697290658951\n",
      "[2023-09-13 13:59:11][INFO] global_step=124648, episodic_env_return=88.0\n",
      "[2023-09-13 13:59:11][INFO] global_step=124688, episodic_reward_predictor_return=-0.6252456903457642\n",
      "[2023-09-13 13:59:11][INFO] global_step=124688, episodic_env_return=39.0\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_reward_predictor_return=0.020177708938717842\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_reward_predictor_return=0.16476643085479736\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_env_return=34.0\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_reward_predictor_return=-0.14778690040111542\n",
      "[2023-09-13 13:59:12][INFO] global_step=124728, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:13][INFO] global_step=124784, episodic_reward_predictor_return=0.3307677209377289\n",
      "[2023-09-13 13:59:13][INFO] global_step=124784, episodic_env_return=94.0\n",
      "[2023-09-13 13:59:14][INFO] global_step=124816, episodic_reward_predictor_return=0.1779039204120636\n",
      "[2023-09-13 13:59:14][INFO] global_step=124816, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:14][INFO] global_step=124832, episodic_reward_predictor_return=-4.545476913452148\n",
      "[2023-09-13 13:59:14][INFO] global_step=124832, episodic_env_return=-375.0\n",
      "[2023-09-13 13:59:14][INFO] global_step=124840, episodic_reward_predictor_return=0.39954838156700134\n",
      "[2023-09-13 13:59:14][INFO] global_step=124840, episodic_env_return=76.0\n",
      "[2023-09-13 13:59:14][INFO] global_step=124856, episodic_reward_predictor_return=0.0009239502251148224\n",
      "[2023-09-13 13:59:14][INFO] global_step=124856, episodic_env_return=85.0\n",
      "[2023-09-13 13:59:15][INFO] global_step=124888, episodic_reward_predictor_return=0.34287238121032715\n",
      "[2023-09-13 13:59:15][INFO] global_step=124888, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:15][INFO] Current Mean Episodic Return = 0.05606143921613693\n",
      "[2023-09-13 13:59:15][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_124928`...\n",
      "[2023-09-13 13:59:16][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_124928`!\n",
      "[2023-09-13 13:59:18][INFO] SPS: 23\n",
      "[2023-09-13 13:59:19][INFO] global_step=125000, episodic_reward_predictor_return=0.4017268419265747\n",
      "[2023-09-13 13:59:19][INFO] global_step=125000, episodic_env_return=74.0\n",
      "[2023-09-13 13:59:20][INFO] global_step=125016, episodic_reward_predictor_return=0.5384727716445923\n",
      "[2023-09-13 13:59:20][INFO] global_step=125016, episodic_env_return=81.0\n",
      "[2023-09-13 13:59:20][INFO] global_step=125040, episodic_reward_predictor_return=0.2474677413702011\n",
      "[2023-09-13 13:59:20][INFO] global_step=125040, episodic_env_return=76.0\n",
      "[2023-09-13 13:59:20][INFO] global_step=125056, episodic_reward_predictor_return=-0.25895506143569946\n",
      "[2023-09-13 13:59:20][INFO] global_step=125056, episodic_env_return=50.0\n",
      "[2023-09-13 13:59:21][INFO] global_step=125072, episodic_reward_predictor_return=0.28629356622695923\n",
      "[2023-09-13 13:59:21][INFO] global_step=125072, episodic_env_return=71.0\n",
      "[2023-09-13 13:59:21][INFO] global_step=125080, episodic_reward_predictor_return=0.327198326587677\n",
      "[2023-09-13 13:59:21][INFO] global_step=125080, episodic_env_return=28.0\n",
      "[2023-09-13 13:59:22][INFO] global_step=125128, episodic_reward_predictor_return=0.21575205028057098\n",
      "[2023-09-13 13:59:22][INFO] global_step=125128, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_reward_predictor_return=0.24059930443763733\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_env_return=83.0\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_reward_predictor_return=0.26121270656585693\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_reward_predictor_return=0.07366631925106049\n",
      "[2023-09-13 13:59:22][INFO] global_step=125160, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:23][INFO] global_step=125200, episodic_reward_predictor_return=0.3306886851787567\n",
      "[2023-09-13 13:59:23][INFO] global_step=125200, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:24][INFO] global_step=125264, episodic_reward_predictor_return=0.2607862949371338\n",
      "[2023-09-13 13:59:24][INFO] global_step=125264, episodic_env_return=75.0\n",
      "[2023-09-13 13:59:24][INFO] global_step=125288, episodic_reward_predictor_return=0.13087506592273712\n",
      "[2023-09-13 13:59:24][INFO] global_step=125288, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:25][INFO] global_step=125352, episodic_reward_predictor_return=0.1936505138874054\n",
      "[2023-09-13 13:59:25][INFO] global_step=125352, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:26][INFO] global_step=125368, episodic_reward_predictor_return=0.03679068759083748\n",
      "[2023-09-13 13:59:26][INFO] global_step=125368, episodic_env_return=75.0\n",
      "[2023-09-13 13:59:26][INFO] global_step=125400, episodic_reward_predictor_return=-0.25366783142089844\n",
      "[2023-09-13 13:59:26][INFO] global_step=125400, episodic_env_return=66.0\n",
      "[2023-09-13 13:59:27][INFO] global_step=125456, episodic_reward_predictor_return=-0.07337328791618347\n",
      "[2023-09-13 13:59:27][INFO] global_step=125456, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:27][INFO] global_step=125456, episodic_reward_predictor_return=0.5059280395507812\n",
      "[2023-09-13 13:59:27][INFO] global_step=125456, episodic_env_return=34.0\n",
      "[2023-09-13 13:59:27][INFO] global_step=125472, episodic_reward_predictor_return=0.20788343250751495\n",
      "[2023-09-13 13:59:27][INFO] global_step=125472, episodic_env_return=57.0\n",
      "[2023-09-13 13:59:28][INFO] global_step=125496, episodic_reward_predictor_return=0.2717417776584625\n",
      "[2023-09-13 13:59:28][INFO] global_step=125496, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:28][INFO] global_step=125496, episodic_reward_predictor_return=0.5540545582771301\n",
      "[2023-09-13 13:59:28][INFO] global_step=125496, episodic_env_return=75.0\n",
      "[2023-09-13 13:59:29][INFO] global_step=125536, episodic_reward_predictor_return=0.314397931098938\n",
      "[2023-09-13 13:59:29][INFO] global_step=125536, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:29][INFO] global_step=125536, episodic_reward_predictor_return=0.10930764675140381\n",
      "[2023-09-13 13:59:29][INFO] global_step=125536, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:29][INFO] global_step=125576, episodic_reward_predictor_return=0.06315667927265167\n",
      "[2023-09-13 13:59:29][INFO] global_step=125576, episodic_env_return=68.0\n",
      "[2023-09-13 13:59:31][INFO] global_step=125648, episodic_reward_predictor_return=0.26508793234825134\n",
      "[2023-09-13 13:59:31][INFO] global_step=125648, episodic_env_return=82.0\n",
      "[2023-09-13 13:59:31][INFO] global_step=125696, episodic_reward_predictor_return=0.3550572395324707\n",
      "[2023-09-13 13:59:31][INFO] global_step=125696, episodic_env_return=81.0\n",
      "[2023-09-13 13:59:33][INFO] global_step=125776, episodic_reward_predictor_return=0.8743336200714111\n",
      "[2023-09-13 13:59:33][INFO] global_step=125776, episodic_env_return=76.0\n",
      "[2023-09-13 13:59:33][INFO] global_step=125784, episodic_reward_predictor_return=0.4404725432395935\n",
      "[2023-09-13 13:59:33][INFO] global_step=125784, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:33][INFO] global_step=125808, episodic_reward_predictor_return=0.20521986484527588\n",
      "[2023-09-13 13:59:33][INFO] global_step=125808, episodic_env_return=67.0\n",
      "[2023-09-13 13:59:33][INFO] global_step=125816, episodic_reward_predictor_return=-0.18878351151943207\n",
      "[2023-09-13 13:59:33][INFO] global_step=125816, episodic_env_return=56.0\n",
      "[2023-09-13 13:59:34][INFO] global_step=125856, episodic_reward_predictor_return=0.07620526850223541\n",
      "[2023-09-13 13:59:34][INFO] global_step=125856, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:35][INFO] global_step=125912, episodic_reward_predictor_return=0.329852432012558\n",
      "[2023-09-13 13:59:35][INFO] global_step=125912, episodic_env_return=85.0\n",
      "[2023-09-13 13:59:37][INFO] global_step=126040, episodic_reward_predictor_return=0.154276043176651\n",
      "[2023-09-13 13:59:37][INFO] global_step=126040, episodic_env_return=78.0\n",
      "[2023-09-13 13:59:37][INFO] global_step=126048, episodic_reward_predictor_return=0.03466459736227989\n",
      "[2023-09-13 13:59:37][INFO] global_step=126048, episodic_env_return=66.0\n",
      "[2023-09-13 13:59:38][INFO] global_step=126056, episodic_reward_predictor_return=-0.09323354065418243\n",
      "[2023-09-13 13:59:38][INFO] global_step=126056, episodic_env_return=13.0\n",
      "[2023-09-13 13:59:38][INFO] global_step=126072, episodic_reward_predictor_return=0.33930471539497375\n",
      "[2023-09-13 13:59:38][INFO] global_step=126072, episodic_env_return=69.0\n",
      "[2023-09-13 13:59:39][INFO] global_step=126112, episodic_reward_predictor_return=0.1922985315322876\n",
      "[2023-09-13 13:59:39][INFO] global_step=126112, episodic_env_return=76.0\n",
      "[2023-09-13 13:59:40][INFO] global_step=126184, episodic_reward_predictor_return=0.2698204815387726\n",
      "[2023-09-13 13:59:40][INFO] global_step=126184, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:40][INFO] global_step=126200, episodic_reward_predictor_return=0.042411644011735916\n",
      "[2023-09-13 13:59:40][INFO] global_step=126200, episodic_env_return=83.0\n",
      "[2023-09-13 13:59:40][INFO] global_step=126200, episodic_reward_predictor_return=0.37414830923080444\n",
      "[2023-09-13 13:59:40][INFO] global_step=126200, episodic_env_return=85.0\n",
      "[2023-09-13 13:59:41][INFO] global_step=126264, episodic_reward_predictor_return=0.3391445577144623\n",
      "[2023-09-13 13:59:41][INFO] global_step=126264, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:41][INFO] global_step=126288, episodic_reward_predictor_return=0.1056114137172699\n",
      "[2023-09-13 13:59:41][INFO] global_step=126288, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:42][INFO] global_step=126296, episodic_reward_predictor_return=0.06765353679656982\n",
      "[2023-09-13 13:59:42][INFO] global_step=126296, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:42][INFO] global_step=126304, episodic_reward_predictor_return=-0.31893694400787354\n",
      "[2023-09-13 13:59:42][INFO] global_step=126304, episodic_env_return=63.0\n",
      "[2023-09-13 13:59:42][INFO] global_step=126320, episodic_reward_predictor_return=0.5185220837593079\n",
      "[2023-09-13 13:59:42][INFO] global_step=126320, episodic_env_return=67.0\n",
      "[2023-09-13 13:59:43][INFO] global_step=126352, episodic_reward_predictor_return=0.33589795231819153\n",
      "[2023-09-13 13:59:43][INFO] global_step=126352, episodic_env_return=90.0\n",
      "[2023-09-13 13:59:43][INFO] global_step=126400, episodic_reward_predictor_return=0.1809067279100418\n",
      "[2023-09-13 13:59:43][INFO] global_step=126400, episodic_env_return=87.0\n",
      "[2023-09-13 13:59:43][INFO] global_step=126408, episodic_reward_predictor_return=-0.0098603880032897\n",
      "[2023-09-13 13:59:43][INFO] global_step=126408, episodic_env_return=88.0\n",
      "[2023-09-13 13:59:44][INFO] global_step=126448, episodic_reward_predictor_return=0.41928398609161377\n",
      "[2023-09-13 13:59:44][INFO] global_step=126448, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:45][INFO] global_step=126512, episodic_reward_predictor_return=-0.05946442112326622\n",
      "[2023-09-13 13:59:45][INFO] global_step=126512, episodic_env_return=77.0\n",
      "[2023-09-13 13:59:47][INFO] global_step=126600, episodic_reward_predictor_return=0.1322440654039383\n",
      "[2023-09-13 13:59:47][INFO] global_step=126600, episodic_env_return=82.0\n",
      "[2023-09-13 13:59:47][INFO] global_step=126608, episodic_reward_predictor_return=0.5548542737960815\n",
      "[2023-09-13 13:59:47][INFO] global_step=126608, episodic_env_return=62.0\n",
      "[2023-09-13 13:59:48][INFO] global_step=126664, episodic_reward_predictor_return=0.41364458203315735\n",
      "[2023-09-13 13:59:48][INFO] global_step=126664, episodic_env_return=68.0\n",
      "[2023-09-13 13:59:48][INFO] global_step=126696, episodic_reward_predictor_return=0.13821887969970703\n",
      "[2023-09-13 13:59:48][INFO] global_step=126696, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:49][INFO] global_step=126736, episodic_reward_predictor_return=-4.7760515213012695\n",
      "[2023-09-13 13:59:49][INFO] global_step=126736, episodic_env_return=-380.0\n",
      "[2023-09-13 13:59:49][INFO] global_step=126744, episodic_reward_predictor_return=0.2209833562374115\n",
      "[2023-09-13 13:59:49][INFO] global_step=126744, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:51][INFO] global_step=126816, episodic_reward_predictor_return=-0.29076290130615234\n",
      "[2023-09-13 13:59:51][INFO] global_step=126816, episodic_env_return=58.0\n",
      "[2023-09-13 13:59:51][INFO] global_step=126824, episodic_reward_predictor_return=0.2518090605735779\n",
      "[2023-09-13 13:59:51][INFO] global_step=126824, episodic_env_return=91.0\n",
      "[2023-09-13 13:59:52][INFO] global_step=126896, episodic_reward_predictor_return=0.5609395503997803\n",
      "[2023-09-13 13:59:52][INFO] global_step=126896, episodic_env_return=65.0\n",
      "[2023-09-13 13:59:52][INFO] global_step=126920, episodic_reward_predictor_return=0.23742768168449402\n",
      "[2023-09-13 13:59:52][INFO] global_step=126920, episodic_env_return=89.0\n",
      "[2023-09-13 13:59:53][INFO] global_step=126928, episodic_reward_predictor_return=0.17428246140480042\n",
      "[2023-09-13 13:59:53][INFO] global_step=126928, episodic_env_return=87.0\n",
      "[2023-09-13 13:59:53][INFO] global_step=126968, episodic_reward_predictor_return=-0.20211492478847504\n",
      "[2023-09-13 13:59:53][INFO] global_step=126968, episodic_env_return=67.0\n",
      "[2023-09-13 13:59:53][INFO] Current Mean Episodic Return = 0.12340361624956131\n",
      "[2023-09-13 13:59:53][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_126976`...\n",
      "[2023-09-13 13:59:53][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_126976`!\n",
      "[2023-09-13 13:59:56][INFO] SPS: 23\n",
      "[2023-09-13 13:59:56][INFO] global_step=127000, episodic_reward_predictor_return=0.08300426602363586\n",
      "[2023-09-13 13:59:56][INFO] global_step=127000, episodic_env_return=92.0\n",
      "[2023-09-13 13:59:57][INFO] global_step=127008, episodic_reward_predictor_return=0.38217607140541077\n",
      "[2023-09-13 13:59:57][INFO] global_step=127008, episodic_env_return=87.0\n",
      "[2023-09-13 13:59:58][INFO] global_step=127088, episodic_reward_predictor_return=-0.3930843770503998\n",
      "[2023-09-13 13:59:58][INFO] global_step=127088, episodic_env_return=42.0\n",
      "[2023-09-13 13:59:58][INFO] global_step=127096, episodic_reward_predictor_return=0.3712348937988281\n",
      "[2023-09-13 13:59:58][INFO] global_step=127096, episodic_env_return=85.0\n",
      "[2023-09-13 13:59:58][INFO] global_step=127112, episodic_reward_predictor_return=1.3525419235229492\n",
      "[2023-09-13 13:59:58][INFO] global_step=127112, episodic_env_return=8.0\n",
      "[2023-09-13 13:59:59][INFO] global_step=127184, episodic_reward_predictor_return=0.2056419998407364\n",
      "[2023-09-13 13:59:59][INFO] global_step=127184, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:00][INFO] global_step=127200, episodic_reward_predictor_return=0.2799258530139923\n",
      "[2023-09-13 14:00:00][INFO] global_step=127200, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:00][INFO] global_step=127216, episodic_reward_predictor_return=0.4523717164993286\n",
      "[2023-09-13 14:00:00][INFO] global_step=127216, episodic_env_return=74.0\n",
      "[2023-09-13 14:00:01][INFO] global_step=127248, episodic_reward_predictor_return=0.007834479212760925\n",
      "[2023-09-13 14:00:01][INFO] global_step=127248, episodic_env_return=95.0\n",
      "[2023-09-13 14:00:01][INFO] global_step=127256, episodic_reward_predictor_return=0.5541592836380005\n",
      "[2023-09-13 14:00:01][INFO] global_step=127256, episodic_env_return=80.0\n",
      "[2023-09-13 14:00:01][INFO] global_step=127288, episodic_reward_predictor_return=-2.411639451980591\n",
      "[2023-09-13 14:00:01][INFO] global_step=127288, episodic_env_return=-360.0\n",
      "[2023-09-13 14:00:01][INFO] global_step=127296, episodic_reward_predictor_return=0.20185135304927826\n",
      "[2023-09-13 14:00:01][INFO] global_step=127296, episodic_env_return=87.0\n",
      "[2023-09-13 14:00:02][INFO] global_step=127312, episodic_reward_predictor_return=-0.12248227000236511\n",
      "[2023-09-13 14:00:02][INFO] global_step=127312, episodic_env_return=58.0\n",
      "[2023-09-13 14:00:02][INFO] global_step=127336, episodic_reward_predictor_return=0.22342520952224731\n",
      "[2023-09-13 14:00:02][INFO] global_step=127336, episodic_env_return=44.0\n",
      "[2023-09-13 14:00:02][INFO] global_step=127360, episodic_reward_predictor_return=0.09582488238811493\n",
      "[2023-09-13 14:00:02][INFO] global_step=127360, episodic_env_return=88.0\n",
      "[2023-09-13 14:00:03][INFO] global_step=127368, episodic_reward_predictor_return=0.04545554518699646\n",
      "[2023-09-13 14:00:03][INFO] global_step=127368, episodic_env_return=91.0\n",
      "[2023-09-13 14:00:03][INFO] global_step=127416, episodic_reward_predictor_return=0.11989336460828781\n",
      "[2023-09-13 14:00:03][INFO] global_step=127416, episodic_env_return=86.0\n",
      "[2023-09-13 14:00:04][INFO] global_step=127432, episodic_reward_predictor_return=0.04462146386504173\n",
      "[2023-09-13 14:00:04][INFO] global_step=127432, episodic_env_return=73.0\n",
      "[2023-09-13 14:00:05][INFO] global_step=127504, episodic_reward_predictor_return=0.10992960631847382\n",
      "[2023-09-13 14:00:05][INFO] global_step=127504, episodic_env_return=92.0\n",
      "[2023-09-13 14:00:05][INFO] global_step=127512, episodic_reward_predictor_return=0.07131952047348022\n",
      "[2023-09-13 14:00:05][INFO] global_step=127512, episodic_env_return=83.0\n",
      "[2023-09-13 14:00:06][INFO] global_step=127536, episodic_reward_predictor_return=0.3688271939754486\n",
      "[2023-09-13 14:00:06][INFO] global_step=127536, episodic_env_return=86.0\n",
      "[2023-09-13 14:00:06][INFO] global_step=127552, episodic_reward_predictor_return=0.16616730391979218\n",
      "[2023-09-13 14:00:06][INFO] global_step=127552, episodic_env_return=77.0\n",
      "[2023-09-13 14:00:06][INFO] global_step=127576, episodic_reward_predictor_return=-0.09722620993852615\n",
      "[2023-09-13 14:00:06][INFO] global_step=127576, episodic_env_return=66.0\n",
      "[2023-09-13 14:00:07][INFO] global_step=127592, episodic_reward_predictor_return=0.5287778973579407\n",
      "[2023-09-13 14:00:07][INFO] global_step=127592, episodic_env_return=-202.0\n",
      "[2023-09-13 14:00:07][INFO] global_step=127616, episodic_reward_predictor_return=0.5435848832130432\n",
      "[2023-09-13 14:00:07][INFO] global_step=127616, episodic_env_return=46.0\n",
      "[2023-09-13 14:00:07][INFO] global_step=127616, episodic_reward_predictor_return=-0.4406539499759674\n",
      "[2023-09-13 14:00:07][INFO] global_step=127616, episodic_env_return=58.0\n",
      "[2023-09-13 14:00:07][INFO] global_step=127624, episodic_reward_predictor_return=0.29157307744026184\n",
      "[2023-09-13 14:00:07][INFO] global_step=127624, episodic_env_return=86.0\n",
      "[2023-09-13 14:00:08][INFO] global_step=127640, episodic_reward_predictor_return=0.3729681968688965\n",
      "[2023-09-13 14:00:08][INFO] global_step=127640, episodic_env_return=85.0\n",
      "[2023-09-13 14:00:08][INFO] global_step=127680, episodic_reward_predictor_return=-0.09606520086526871\n",
      "[2023-09-13 14:00:08][INFO] global_step=127680, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:08][INFO] global_step=127696, episodic_reward_predictor_return=0.014064699411392212\n",
      "[2023-09-13 14:00:08][INFO] global_step=127696, episodic_env_return=91.0\n",
      "[2023-09-13 14:00:09][INFO] global_step=127752, episodic_reward_predictor_return=0.40514838695526123\n",
      "[2023-09-13 14:00:09][INFO] global_step=127752, episodic_env_return=87.0\n",
      "[2023-09-13 14:00:10][INFO] global_step=127784, episodic_reward_predictor_return=0.11039049178361893\n",
      "[2023-09-13 14:00:10][INFO] global_step=127784, episodic_env_return=80.0\n",
      "[2023-09-13 14:00:10][INFO] global_step=127792, episodic_reward_predictor_return=0.22748294472694397\n",
      "[2023-09-13 14:00:10][INFO] global_step=127792, episodic_env_return=69.0\n",
      "[2023-09-13 14:00:11][INFO] global_step=127840, episodic_reward_predictor_return=0.18069271743297577\n",
      "[2023-09-13 14:00:11][INFO] global_step=127840, episodic_env_return=65.0\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_reward_predictor_return=0.6164493560791016\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_env_return=72.0\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_reward_predictor_return=0.3950921595096588\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_env_return=56.0\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_reward_predictor_return=0.6791160106658936\n",
      "[2023-09-13 14:00:11][INFO] global_step=127856, episodic_env_return=81.0\n",
      "[2023-09-13 14:00:11][INFO] global_step=127864, episodic_reward_predictor_return=0.3674907982349396\n",
      "[2023-09-13 14:00:11][INFO] global_step=127864, episodic_env_return=87.0\n",
      "[2023-09-13 14:00:12][INFO] global_step=127872, episodic_reward_predictor_return=0.44111692905426025\n",
      "[2023-09-13 14:00:12][INFO] global_step=127872, episodic_env_return=77.0\n",
      "[2023-09-13 14:00:12][INFO] global_step=127920, episodic_reward_predictor_return=0.3608420789241791\n",
      "[2023-09-13 14:00:12][INFO] global_step=127920, episodic_env_return=91.0\n",
      "[2023-09-13 14:00:13][INFO] global_step=127928, episodic_reward_predictor_return=0.23666922748088837\n",
      "[2023-09-13 14:00:13][INFO] global_step=127928, episodic_env_return=92.0\n",
      "[2023-09-13 14:00:13][INFO] global_step=127976, episodic_reward_predictor_return=0.6114558577537537\n",
      "[2023-09-13 14:00:13][INFO] global_step=127976, episodic_env_return=77.0\n",
      "[2023-09-13 14:00:14][INFO] global_step=128016, episodic_reward_predictor_return=0.03647392988204956\n",
      "[2023-09-13 14:00:14][INFO] global_step=128016, episodic_env_return=89.0\n",
      "[2023-09-13 14:00:15][INFO] global_step=128040, episodic_reward_predictor_return=0.16468623280525208\n",
      "[2023-09-13 14:00:15][INFO] global_step=128040, episodic_env_return=73.0\n",
      "[2023-09-13 14:00:15][INFO] global_step=128056, episodic_reward_predictor_return=0.008614622056484222\n",
      "[2023-09-13 14:00:15][INFO] global_step=128056, episodic_env_return=72.0\n",
      "[2023-09-13 14:00:15][INFO] global_step=128096, episodic_reward_predictor_return=0.1853918582201004\n",
      "[2023-09-13 14:00:15][INFO] global_step=128096, episodic_env_return=73.0\n",
      "[2023-09-13 14:00:16][INFO] global_step=128104, episodic_reward_predictor_return=-0.40594276785850525\n",
      "[2023-09-13 14:00:16][INFO] global_step=128104, episodic_env_return=57.0\n",
      "[2023-09-13 14:00:16][INFO] global_step=128144, episodic_reward_predictor_return=0.23444941639900208\n",
      "[2023-09-13 14:00:16][INFO] global_step=128144, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:16][INFO] global_step=128144, episodic_reward_predictor_return=0.11308170855045319\n",
      "[2023-09-13 14:00:16][INFO] global_step=128144, episodic_env_return=95.0\n",
      "[2023-09-13 14:00:16][INFO] global_step=128152, episodic_reward_predictor_return=0.2585415840148926\n",
      "[2023-09-13 14:00:16][INFO] global_step=128152, episodic_env_return=87.0\n",
      "[2023-09-13 14:00:17][INFO] global_step=128168, episodic_reward_predictor_return=0.29825669527053833\n",
      "[2023-09-13 14:00:17][INFO] global_step=128168, episodic_env_return=77.0\n",
      "[2023-09-13 14:00:17][INFO] global_step=128200, episodic_reward_predictor_return=-0.045177560299634933\n",
      "[2023-09-13 14:00:17][INFO] global_step=128200, episodic_env_return=62.0\n",
      "[2023-09-13 14:00:18][INFO] global_step=128232, episodic_reward_predictor_return=0.4360898435115814\n",
      "[2023-09-13 14:00:18][INFO] global_step=128232, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:18][INFO] global_step=128248, episodic_reward_predictor_return=0.003137350082397461\n",
      "[2023-09-13 14:00:18][INFO] global_step=128248, episodic_env_return=47.0\n",
      "[2023-09-13 14:00:18][INFO] global_step=128256, episodic_reward_predictor_return=0.17957961559295654\n",
      "[2023-09-13 14:00:18][INFO] global_step=128256, episodic_env_return=88.0\n",
      "[2023-09-13 14:00:18][INFO] global_step=128264, episodic_reward_predictor_return=0.1670897901058197\n",
      "[2023-09-13 14:00:18][INFO] global_step=128264, episodic_env_return=89.0\n",
      "[2023-09-13 14:00:20][INFO] global_step=128336, episodic_reward_predictor_return=0.1979791224002838\n",
      "[2023-09-13 14:00:20][INFO] global_step=128336, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:20][INFO] global_step=128344, episodic_reward_predictor_return=0.5799887180328369\n",
      "[2023-09-13 14:00:20][INFO] global_step=128344, episodic_env_return=71.0\n",
      "[2023-09-13 14:00:21][INFO] global_step=128416, episodic_reward_predictor_return=0.33669525384902954\n",
      "[2023-09-13 14:00:21][INFO] global_step=128416, episodic_env_return=91.0\n",
      "[2023-09-13 14:00:21][INFO] global_step=128424, episodic_reward_predictor_return=0.39826497435569763\n",
      "[2023-09-13 14:00:21][INFO] global_step=128424, episodic_env_return=45.0\n",
      "[2023-09-13 14:00:21][INFO] global_step=128448, episodic_reward_predictor_return=-0.2836448848247528\n",
      "[2023-09-13 14:00:21][INFO] global_step=128448, episodic_env_return=63.0\n",
      "[2023-09-13 14:00:23][INFO] global_step=128520, episodic_reward_predictor_return=0.24151164293289185\n",
      "[2023-09-13 14:00:23][INFO] global_step=128520, episodic_env_return=65.0\n",
      "[2023-09-13 14:00:23][INFO] global_step=128528, episodic_reward_predictor_return=0.32791608572006226\n",
      "[2023-09-13 14:00:23][INFO] global_step=128528, episodic_env_return=87.0\n",
      "[2023-09-13 14:00:23][INFO] global_step=128536, episodic_reward_predictor_return=0.08801156282424927\n",
      "[2023-09-13 14:00:23][INFO] global_step=128536, episodic_env_return=62.0\n",
      "[2023-09-13 14:00:23][INFO] global_step=128544, episodic_reward_predictor_return=0.8350149989128113\n",
      "[2023-09-13 14:00:23][INFO] global_step=128544, episodic_env_return=65.0\n",
      "[2023-09-13 14:00:24][INFO] global_step=128584, episodic_reward_predictor_return=0.19202855229377747\n",
      "[2023-09-13 14:00:24][INFO] global_step=128584, episodic_env_return=93.0\n",
      "[2023-09-13 14:00:24][INFO] global_step=128592, episodic_reward_predictor_return=0.24848130345344543\n",
      "[2023-09-13 14:00:24][INFO] global_step=128592, episodic_env_return=70.0\n",
      "[2023-09-13 14:00:24][INFO] global_step=128592, episodic_reward_predictor_return=0.45431387424468994\n",
      "[2023-09-13 14:00:24][INFO] global_step=128592, episodic_env_return=80.0\n",
      "[2023-09-13 14:00:25][INFO] global_step=128640, episodic_reward_predictor_return=0.10792317241430283\n",
      "[2023-09-13 14:00:25][INFO] global_step=128640, episodic_env_return=41.0\n",
      "[2023-09-13 14:00:25][INFO] global_step=128672, episodic_reward_predictor_return=0.4554687440395355\n",
      "[2023-09-13 14:00:25][INFO] global_step=128672, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:26][INFO] global_step=128712, episodic_reward_predictor_return=0.029456231743097305\n",
      "[2023-09-13 14:00:26][INFO] global_step=128712, episodic_env_return=78.0\n",
      "[2023-09-13 14:00:26][INFO] global_step=128720, episodic_reward_predictor_return=-0.08195335417985916\n",
      "[2023-09-13 14:00:26][INFO] global_step=128720, episodic_env_return=62.0\n",
      "[2023-09-13 14:00:27][INFO] global_step=128744, episodic_reward_predictor_return=0.38262441754341125\n",
      "[2023-09-13 14:00:27][INFO] global_step=128744, episodic_env_return=82.0\n",
      "[2023-09-13 14:00:28][INFO] global_step=128800, episodic_reward_predictor_return=-0.001162208616733551\n",
      "[2023-09-13 14:00:28][INFO] global_step=128800, episodic_env_return=69.0\n",
      "[2023-09-13 14:00:28][INFO] global_step=128832, episodic_reward_predictor_return=0.14771996438503265\n",
      "[2023-09-13 14:00:28][INFO] global_step=128832, episodic_env_return=86.0\n",
      "[2023-09-13 14:00:28][INFO] global_step=128840, episodic_reward_predictor_return=0.4006938338279724\n",
      "[2023-09-13 14:00:28][INFO] global_step=128840, episodic_env_return=89.0\n",
      "[2023-09-13 14:00:29][INFO] global_step=128848, episodic_reward_predictor_return=-0.025742754340171814\n",
      "[2023-09-13 14:00:29][INFO] global_step=128848, episodic_env_return=69.0\n",
      "[2023-09-13 14:00:29][INFO] global_step=128856, episodic_reward_predictor_return=0.41701406240463257\n",
      "[2023-09-13 14:00:29][INFO] global_step=128856, episodic_env_return=84.0\n",
      "[2023-09-13 14:00:30][INFO] global_step=128920, episodic_reward_predictor_return=0.40900248289108276\n",
      "[2023-09-13 14:00:30][INFO] global_step=128920, episodic_env_return=48.0\n",
      "[2023-09-13 14:00:30][INFO] global_step=128944, episodic_reward_predictor_return=0.4801560342311859\n",
      "[2023-09-13 14:00:30][INFO] global_step=128944, episodic_env_return=90.0\n",
      "[2023-09-13 14:00:31][INFO] global_step=128984, episodic_reward_predictor_return=-0.5235891342163086\n",
      "[2023-09-13 14:00:31][INFO] global_step=128984, episodic_env_return=57.0\n",
      "[2023-09-13 14:00:31][INFO] global_step=128992, episodic_reward_predictor_return=-0.1382608264684677\n",
      "[2023-09-13 14:00:31][INFO] global_step=128992, episodic_env_return=82.0\n",
      "[2023-09-13 14:00:32][INFO] Current Mean Episodic Return = 0.18619699776172638\n",
      "[2023-09-13 14:00:32][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_129024`...\n",
      "[2023-09-13 14:00:32][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_129024`!\n",
      "[2023-09-13 14:00:34][INFO] SPS: 23\n",
      "[2023-09-13 14:02:09][INFO] user_preference = 0\n",
      "[2023-09-13 14:02:09][INFO] reward_predictor_training_loss=1.5701526403427124\n",
      "[2023-09-13 14:03:12][INFO] user_preference = 1\n",
      "[2023-09-13 14:03:12][INFO] reward_predictor_training_loss=0.46680116653442383\n",
      "[2023-09-13 14:03:56][INFO] user_preference = 1\n",
      "[2023-09-13 14:03:56][INFO] reward_predictor_training_loss=0.2364104837179184\n",
      "[2023-09-13 14:04:27][INFO] user_preference = 1\n",
      "[2023-09-13 14:04:28][INFO] reward_predictor_training_loss=0.7186996936798096\n",
      "[2023-09-13 14:04:40][INFO] user_preference = 1\n",
      "[2023-09-13 14:04:40][INFO] reward_predictor_training_loss=0.3704926073551178\n",
      "[2023-09-13 14:05:11][INFO] user_preference = 0\n",
      "[2023-09-13 14:05:11][INFO] reward_predictor_training_loss=1.597165822982788\n",
      "[2023-09-13 14:05:54][INFO] user_preference = 1\n",
      "[2023-09-13 14:05:54][INFO] reward_predictor_training_loss=0.967735767364502\n",
      "[2023-09-13 14:06:43][INFO] user_preference = 1\n",
      "[2023-09-13 14:06:43][INFO] reward_predictor_training_loss=0.904375433921814\n",
      "[2023-09-13 14:06:59][INFO] user_preference = 1\n",
      "[2023-09-13 14:06:59][INFO] reward_predictor_training_loss=0.13142089545726776\n",
      "[2023-09-13 14:07:54][INFO] user_preference = 0.5\n",
      "[2023-09-13 14:07:54][INFO] reward_predictor_training_loss=0.7655141949653625\n",
      "[2023-09-13 14:08:52][INFO] user_preference = 1\n",
      "[2023-09-13 14:08:52][INFO] reward_predictor_training_loss=1.116938829421997\n",
      "[2023-09-13 14:10:26][INFO] user_preference = 1\n",
      "[2023-09-13 14:10:26][INFO] reward_predictor_training_loss=0.03508991748094559\n",
      "[2023-09-13 14:11:14][INFO] user_preference = 0\n",
      "[2023-09-13 14:11:14][INFO] reward_predictor_training_loss=0.5214062333106995\n",
      "[2023-09-13 14:12:13][INFO] user_preference = 0\n",
      "[2023-09-13 14:12:13][INFO] reward_predictor_training_loss=1.627143383026123\n",
      "[2023-09-13 14:13:21][INFO] user_preference = 0\n",
      "[2023-09-13 14:13:21][INFO] reward_predictor_training_loss=0.3885331451892853\n",
      "[2023-09-13 14:14:31][INFO] user_preference = 1\n",
      "[2023-09-13 14:14:31][INFO] reward_predictor_training_loss=0.40597546100616455\n",
      "[2023-09-13 14:14:31][INFO] global_step=129040, episodic_reward_predictor_return=0.9732047319412231\n",
      "[2023-09-13 14:14:31][INFO] global_step=129040, episodic_env_return=51.0\n",
      "[2023-09-13 14:14:31][INFO] global_step=129056, episodic_reward_predictor_return=-0.04555583745241165\n",
      "[2023-09-13 14:14:31][INFO] global_step=129056, episodic_env_return=75.0\n",
      "[2023-09-13 14:14:32][INFO] global_step=129080, episodic_reward_predictor_return=0.30422812700271606\n",
      "[2023-09-13 14:14:32][INFO] global_step=129080, episodic_env_return=89.0\n",
      "[2023-09-13 14:14:33][INFO] global_step=129160, episodic_reward_predictor_return=0.37549889087677\n",
      "[2023-09-13 14:14:33][INFO] global_step=129160, episodic_env_return=91.0\n",
      "[2023-09-13 14:14:33][INFO] global_step=129176, episodic_reward_predictor_return=0.4713125228881836\n",
      "[2023-09-13 14:14:33][INFO] global_step=129176, episodic_env_return=49.0\n",
      "[2023-09-13 14:14:34][INFO] global_step=129192, episodic_reward_predictor_return=0.6096497774124146\n",
      "[2023-09-13 14:14:34][INFO] global_step=129192, episodic_env_return=76.0\n",
      "[2023-09-13 14:14:34][INFO] global_step=129200, episodic_reward_predictor_return=0.9378100633621216\n",
      "[2023-09-13 14:14:34][INFO] global_step=129200, episodic_env_return=69.0\n",
      "[2023-09-13 14:14:34][INFO] global_step=129232, episodic_reward_predictor_return=0.1651768684387207\n",
      "[2023-09-13 14:14:34][INFO] global_step=129232, episodic_env_return=79.0\n",
      "[2023-09-13 14:14:35][INFO] global_step=129248, episodic_reward_predictor_return=0.4567492604255676\n",
      "[2023-09-13 14:14:35][INFO] global_step=129248, episodic_env_return=92.0\n",
      "[2023-09-13 14:14:35][INFO] global_step=129256, episodic_reward_predictor_return=-0.07257948815822601\n",
      "[2023-09-13 14:14:35][INFO] global_step=129256, episodic_env_return=54.0\n",
      "[2023-09-13 14:14:35][INFO] global_step=129256, episodic_reward_predictor_return=0.006854227744042873\n",
      "[2023-09-13 14:14:35][INFO] global_step=129256, episodic_env_return=38.0\n",
      "[2023-09-13 14:14:35][INFO] global_step=129272, episodic_reward_predictor_return=0.41253381967544556\n",
      "[2023-09-13 14:14:35][INFO] global_step=129272, episodic_env_return=91.0\n",
      "[2023-09-13 14:14:35][INFO] global_step=129280, episodic_reward_predictor_return=0.08938849717378616\n",
      "[2023-09-13 14:14:35][INFO] global_step=129280, episodic_env_return=86.0\n",
      "[2023-09-13 14:14:36][INFO] global_step=129296, episodic_reward_predictor_return=0.025539834052324295\n",
      "[2023-09-13 14:14:36][INFO] global_step=129296, episodic_env_return=69.0\n",
      "[2023-09-13 14:14:37][INFO] global_step=129368, episodic_reward_predictor_return=0.8335930705070496\n",
      "[2023-09-13 14:14:37][INFO] global_step=129368, episodic_env_return=87.0\n",
      "[2023-09-13 14:14:37][INFO] global_step=129384, episodic_reward_predictor_return=0.38172483444213867\n",
      "[2023-09-13 14:14:37][INFO] global_step=129384, episodic_env_return=87.0\n",
      "[2023-09-13 14:14:37][INFO] global_step=129392, episodic_reward_predictor_return=0.0013270750641822815\n",
      "[2023-09-13 14:14:37][INFO] global_step=129392, episodic_env_return=81.0\n",
      "[2023-09-13 14:14:38][INFO] global_step=129424, episodic_reward_predictor_return=0.6546702980995178\n",
      "[2023-09-13 14:14:38][INFO] global_step=129424, episodic_env_return=80.0\n",
      "[2023-09-13 14:14:38][INFO] global_step=129456, episodic_reward_predictor_return=0.6833774447441101\n",
      "[2023-09-13 14:14:38][INFO] global_step=129456, episodic_env_return=69.0\n",
      "[2023-09-13 14:14:39][INFO] global_step=129496, episodic_reward_predictor_return=0.5854231119155884\n",
      "[2023-09-13 14:14:39][INFO] global_step=129496, episodic_env_return=76.0\n",
      "[2023-09-13 14:14:40][INFO] global_step=129544, episodic_reward_predictor_return=0.010233238339424133\n",
      "[2023-09-13 14:14:40][INFO] global_step=129544, episodic_env_return=82.0\n",
      "[2023-09-13 14:14:40][INFO] global_step=129568, episodic_reward_predictor_return=0.23868528008460999\n",
      "[2023-09-13 14:14:40][INFO] global_step=129568, episodic_env_return=87.0\n",
      "[2023-09-13 14:14:40][INFO] global_step=129584, episodic_reward_predictor_return=0.4902089834213257\n",
      "[2023-09-13 14:14:40][INFO] global_step=129584, episodic_env_return=63.0\n",
      "[2023-09-13 14:14:41][INFO] global_step=129640, episodic_reward_predictor_return=0.7457937002182007\n",
      "[2023-09-13 14:14:41][INFO] global_step=129640, episodic_env_return=67.0\n",
      "[2023-09-13 14:14:41][INFO] global_step=129656, episodic_reward_predictor_return=0.07474783807992935\n",
      "[2023-09-13 14:14:41][INFO] global_step=129656, episodic_env_return=92.0\n",
      "[2023-09-13 14:14:42][INFO] global_step=129672, episodic_reward_predictor_return=0.3914722502231598\n",
      "[2023-09-13 14:14:42][INFO] global_step=129672, episodic_env_return=88.0\n",
      "[2023-09-13 14:14:43][INFO] global_step=129752, episodic_reward_predictor_return=0.32189124822616577\n",
      "[2023-09-13 14:14:43][INFO] global_step=129752, episodic_env_return=89.0\n",
      "[2023-09-13 14:14:44][INFO] global_step=129784, episodic_reward_predictor_return=0.358946830034256\n",
      "[2023-09-13 14:14:44][INFO] global_step=129784, episodic_env_return=87.0\n",
      "[2023-09-13 14:14:44][INFO] global_step=129784, episodic_reward_predictor_return=0.5622501969337463\n",
      "[2023-09-13 14:14:44][INFO] global_step=129784, episodic_env_return=71.0\n",
      "[2023-09-13 14:14:44][INFO] global_step=129824, episodic_reward_predictor_return=0.23772983253002167\n",
      "[2023-09-13 14:14:44][INFO] global_step=129824, episodic_env_return=92.0\n",
      "[2023-09-13 14:14:44][INFO] global_step=129832, episodic_reward_predictor_return=0.3850284218788147\n",
      "[2023-09-13 14:14:44][INFO] global_step=129832, episodic_env_return=45.0\n",
      "[2023-09-13 14:14:46][INFO] global_step=129912, episodic_reward_predictor_return=0.3098280727863312\n",
      "[2023-09-13 14:14:46][INFO] global_step=129912, episodic_env_return=39.0\n",
      "[2023-09-13 14:14:46][INFO] global_step=129952, episodic_reward_predictor_return=0.6080905795097351\n",
      "[2023-09-13 14:14:46][INFO] global_step=129952, episodic_env_return=20.0\n",
      "[2023-09-13 14:14:46][INFO] global_step=129960, episodic_reward_predictor_return=0.45540082454681396\n",
      "[2023-09-13 14:14:46][INFO] global_step=129960, episodic_env_return=84.0\n",
      "[2023-09-13 14:14:47][INFO] global_step=129992, episodic_reward_predictor_return=0.17775185406208038\n",
      "[2023-09-13 14:14:47][INFO] global_step=129992, episodic_env_return=47.0\n",
      "[2023-09-13 14:14:47][INFO] global_step=129992, episodic_reward_predictor_return=0.5457341074943542\n",
      "[2023-09-13 14:14:47][INFO] global_step=129992, episodic_env_return=75.0\n",
      "[2023-09-13 14:14:48][INFO] global_step=130032, episodic_reward_predictor_return=0.46324408054351807\n",
      "[2023-09-13 14:14:48][INFO] global_step=130032, episodic_env_return=92.0\n",
      "[2023-09-13 14:14:48][INFO] global_step=130072, episodic_reward_predictor_return=0.11138154566287994\n",
      "[2023-09-13 14:14:48][INFO] global_step=130072, episodic_env_return=71.0\n",
      "[2023-09-13 14:14:49][INFO] global_step=130088, episodic_reward_predictor_return=0.18362991511821747\n",
      "[2023-09-13 14:14:49][INFO] global_step=130088, episodic_env_return=84.0\n",
      "[2023-09-13 14:14:49][INFO] global_step=130136, episodic_reward_predictor_return=-0.082525335252285\n",
      "[2023-09-13 14:14:49][INFO] global_step=130136, episodic_env_return=83.0\n",
      "[2023-09-13 14:14:50][INFO] global_step=130160, episodic_reward_predictor_return=0.29742690920829773\n",
      "[2023-09-13 14:14:50][INFO] global_step=130160, episodic_env_return=90.0\n",
      "[2023-09-13 14:14:50][INFO] global_step=130160, episodic_reward_predictor_return=0.30186739563941956\n",
      "[2023-09-13 14:14:50][INFO] global_step=130160, episodic_env_return=92.0\n",
      "[2023-09-13 14:14:51][INFO] global_step=130216, episodic_reward_predictor_return=0.2715247571468353\n",
      "[2023-09-13 14:14:51][INFO] global_step=130216, episodic_env_return=94.0\n",
      "[2023-09-13 14:14:51][INFO] global_step=130232, episodic_reward_predictor_return=0.3478764295578003\n",
      "[2023-09-13 14:14:51][INFO] global_step=130232, episodic_env_return=56.0\n",
      "[2023-09-13 14:14:51][INFO] global_step=130248, episodic_reward_predictor_return=0.7674040198326111\n",
      "[2023-09-13 14:14:51][INFO] global_step=130248, episodic_env_return=74.0\n",
      "[2023-09-13 14:14:53][INFO] global_step=130336, episodic_reward_predictor_return=0.3828055262565613\n",
      "[2023-09-13 14:14:53][INFO] global_step=130336, episodic_env_return=76.0\n",
      "[2023-09-13 14:14:53][INFO] global_step=130352, episodic_reward_predictor_return=-0.3659423589706421\n",
      "[2023-09-13 14:14:53][INFO] global_step=130352, episodic_env_return=51.0\n",
      "[2023-09-13 14:14:54][INFO] global_step=130392, episodic_reward_predictor_return=-0.3342358469963074\n",
      "[2023-09-13 14:14:54][INFO] global_step=130392, episodic_env_return=-72.0\n",
      "[2023-09-13 14:14:55][INFO] global_step=130448, episodic_reward_predictor_return=0.37187469005584717\n",
      "[2023-09-13 14:14:55][INFO] global_step=130448, episodic_env_return=89.0\n",
      "[2023-09-13 14:14:55][INFO] global_step=130456, episodic_reward_predictor_return=0.2564249336719513\n",
      "[2023-09-13 14:14:55][INFO] global_step=130456, episodic_env_return=73.0\n",
      "[2023-09-13 14:14:55][INFO] global_step=130464, episodic_reward_predictor_return=0.47977763414382935\n",
      "[2023-09-13 14:14:55][INFO] global_step=130464, episodic_env_return=63.0\n",
      "[2023-09-13 14:14:55][INFO] global_step=130472, episodic_reward_predictor_return=0.25122737884521484\n",
      "[2023-09-13 14:14:55][INFO] global_step=130472, episodic_env_return=91.0\n",
      "[2023-09-13 14:14:56][INFO] global_step=130528, episodic_reward_predictor_return=0.4018857181072235\n",
      "[2023-09-13 14:14:56][INFO] global_step=130528, episodic_env_return=91.0\n",
      "[2023-09-13 14:14:56][INFO] global_step=130552, episodic_reward_predictor_return=0.25091809034347534\n",
      "[2023-09-13 14:14:56][INFO] global_step=130552, episodic_env_return=89.0\n",
      "[2023-09-13 14:14:57][INFO] global_step=130608, episodic_reward_predictor_return=0.14978042244911194\n",
      "[2023-09-13 14:14:57][INFO] global_step=130608, episodic_env_return=56.0\n",
      "[2023-09-13 14:14:58][INFO] global_step=130640, episodic_reward_predictor_return=-0.14606884121894836\n",
      "[2023-09-13 14:14:58][INFO] global_step=130640, episodic_env_return=58.0\n",
      "[2023-09-13 14:14:58][INFO] global_step=130664, episodic_reward_predictor_return=0.6459200382232666\n",
      "[2023-09-13 14:14:58][INFO] global_step=130664, episodic_env_return=40.0\n",
      "[2023-09-13 14:14:59][INFO] global_step=130704, episodic_reward_predictor_return=0.3724468946456909\n",
      "[2023-09-13 14:14:59][INFO] global_step=130704, episodic_env_return=72.0\n",
      "[2023-09-13 14:14:59][INFO] global_step=130704, episodic_reward_predictor_return=0.15798260271549225\n",
      "[2023-09-13 14:14:59][INFO] global_step=130704, episodic_env_return=66.0\n",
      "[2023-09-13 14:15:00][INFO] global_step=130776, episodic_reward_predictor_return=0.11243733763694763\n",
      "[2023-09-13 14:15:00][INFO] global_step=130776, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:00][INFO] global_step=130792, episodic_reward_predictor_return=0.5341736674308777\n",
      "[2023-09-13 14:15:00][INFO] global_step=130792, episodic_env_return=82.0\n",
      "[2023-09-13 14:15:00][INFO] global_step=130792, episodic_reward_predictor_return=0.4836254417896271\n",
      "[2023-09-13 14:15:00][INFO] global_step=130792, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:00][INFO] global_step=130800, episodic_reward_predictor_return=0.2034076452255249\n",
      "[2023-09-13 14:15:00][INFO] global_step=130800, episodic_env_return=70.0\n",
      "[2023-09-13 14:15:01][INFO] global_step=130808, episodic_reward_predictor_return=0.29578542709350586\n",
      "[2023-09-13 14:15:01][INFO] global_step=130808, episodic_env_return=83.0\n",
      "[2023-09-13 14:15:01][INFO] global_step=130864, episodic_reward_predictor_return=0.2530044615268707\n",
      "[2023-09-13 14:15:01][INFO] global_step=130864, episodic_env_return=90.0\n",
      "[2023-09-13 14:15:02][INFO] global_step=130872, episodic_reward_predictor_return=0.12486516684293747\n",
      "[2023-09-13 14:15:02][INFO] global_step=130872, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:02][INFO] global_step=130888, episodic_reward_predictor_return=0.17320935428142548\n",
      "[2023-09-13 14:15:02][INFO] global_step=130888, episodic_env_return=90.0\n",
      "[2023-09-13 14:15:02][INFO] global_step=130912, episodic_reward_predictor_return=-0.016590392217040062\n",
      "[2023-09-13 14:15:02][INFO] global_step=130912, episodic_env_return=43.0\n",
      "[2023-09-13 14:15:03][INFO] global_step=130936, episodic_reward_predictor_return=0.5425529479980469\n",
      "[2023-09-13 14:15:03][INFO] global_step=130936, episodic_env_return=83.0\n",
      "[2023-09-13 14:15:03][INFO] global_step=130952, episodic_reward_predictor_return=0.4320138394832611\n",
      "[2023-09-13 14:15:03][INFO] global_step=130952, episodic_env_return=83.0\n",
      "[2023-09-13 14:15:03][INFO] global_step=130952, episodic_reward_predictor_return=0.3204236924648285\n",
      "[2023-09-13 14:15:03][INFO] global_step=130952, episodic_env_return=90.0\n",
      "[2023-09-13 14:15:04][INFO] global_step=130976, episodic_reward_predictor_return=0.22929292917251587\n",
      "[2023-09-13 14:15:04][INFO] global_step=130976, episodic_env_return=88.0\n",
      "[2023-09-13 14:15:05][INFO] global_step=131024, episodic_reward_predictor_return=0.27129748463630676\n",
      "[2023-09-13 14:15:05][INFO] global_step=131024, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:05][INFO] global_step=131048, episodic_reward_predictor_return=0.470485121011734\n",
      "[2023-09-13 14:15:05][INFO] global_step=131048, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:05][INFO] global_step=131056, episodic_reward_predictor_return=0.17509517073631287\n",
      "[2023-09-13 14:15:05][INFO] global_step=131056, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:05][INFO] Current Mean Episodic Return = 0.31873902678489685\n",
      "[2023-09-13 14:15:05][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_131072`...\n",
      "[2023-09-13 14:15:05][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_131072`!\n",
      "[2023-09-13 14:15:08][INFO] SPS: 20\n",
      "[2023-09-13 14:15:09][INFO] global_step=131104, episodic_reward_predictor_return=0.13032189011573792\n",
      "[2023-09-13 14:15:09][INFO] global_step=131104, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:09][INFO] global_step=131128, episodic_reward_predictor_return=0.22091460227966309\n",
      "[2023-09-13 14:15:09][INFO] global_step=131128, episodic_env_return=66.0\n",
      "[2023-09-13 14:15:09][INFO] global_step=131136, episodic_reward_predictor_return=-0.011355053633451462\n",
      "[2023-09-13 14:15:09][INFO] global_step=131136, episodic_env_return=68.0\n",
      "[2023-09-13 14:15:10][INFO] global_step=131168, episodic_reward_predictor_return=0.11419344693422318\n",
      "[2023-09-13 14:15:10][INFO] global_step=131168, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:10][INFO] global_step=131192, episodic_reward_predictor_return=0.7604994177818298\n",
      "[2023-09-13 14:15:10][INFO] global_step=131192, episodic_env_return=30.0\n",
      "[2023-09-13 14:15:11][INFO] global_step=131232, episodic_reward_predictor_return=0.2210313230752945\n",
      "[2023-09-13 14:15:11][INFO] global_step=131232, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:11][INFO] global_step=131232, episodic_reward_predictor_return=0.5922993421554565\n",
      "[2023-09-13 14:15:11][INFO] global_step=131232, episodic_env_return=85.0\n",
      "[2023-09-13 14:15:11][INFO] global_step=131240, episodic_reward_predictor_return=0.31623876094818115\n",
      "[2023-09-13 14:15:11][INFO] global_step=131240, episodic_env_return=88.0\n",
      "[2023-09-13 14:15:11][INFO] global_step=131264, episodic_reward_predictor_return=0.3387729823589325\n",
      "[2023-09-13 14:15:11][INFO] global_step=131264, episodic_env_return=84.0\n",
      "[2023-09-13 14:15:12][INFO] global_step=131288, episodic_reward_predictor_return=0.3259098529815674\n",
      "[2023-09-13 14:15:12][INFO] global_step=131288, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:12][INFO] global_step=131328, episodic_reward_predictor_return=0.2684314548969269\n",
      "[2023-09-13 14:15:12][INFO] global_step=131328, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:13][INFO] global_step=131352, episodic_reward_predictor_return=0.1732003539800644\n",
      "[2023-09-13 14:15:13][INFO] global_step=131352, episodic_env_return=90.0\n",
      "[2023-09-13 14:15:13][INFO] global_step=131368, episodic_reward_predictor_return=0.3109852075576782\n",
      "[2023-09-13 14:15:13][INFO] global_step=131368, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:14][INFO] global_step=131408, episodic_reward_predictor_return=0.37846970558166504\n",
      "[2023-09-13 14:15:14][INFO] global_step=131408, episodic_env_return=80.0\n",
      "[2023-09-13 14:15:14][INFO] global_step=131424, episodic_reward_predictor_return=0.1974765807390213\n",
      "[2023-09-13 14:15:14][INFO] global_step=131424, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:14][INFO] global_step=131448, episodic_reward_predictor_return=0.20426151156425476\n",
      "[2023-09-13 14:15:14][INFO] global_step=131448, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:15][INFO] global_step=131464, episodic_reward_predictor_return=-0.0029215477406978607\n",
      "[2023-09-13 14:15:15][INFO] global_step=131464, episodic_env_return=64.0\n",
      "[2023-09-13 14:15:15][INFO] global_step=131488, episodic_reward_predictor_return=0.062088802456855774\n",
      "[2023-09-13 14:15:15][INFO] global_step=131488, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:16][INFO] global_step=131520, episodic_reward_predictor_return=0.16760361194610596\n",
      "[2023-09-13 14:15:16][INFO] global_step=131520, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:16][INFO] global_step=131520, episodic_reward_predictor_return=0.2224818915128708\n",
      "[2023-09-13 14:15:16][INFO] global_step=131520, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:16][INFO] global_step=131552, episodic_reward_predictor_return=0.772400975227356\n",
      "[2023-09-13 14:15:16][INFO] global_step=131552, episodic_env_return=61.0\n",
      "[2023-09-13 14:15:17][INFO] global_step=131568, episodic_reward_predictor_return=0.4091961085796356\n",
      "[2023-09-13 14:15:17][INFO] global_step=131568, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:17][INFO] global_step=131576, episodic_reward_predictor_return=0.33154213428497314\n",
      "[2023-09-13 14:15:17][INFO] global_step=131576, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:17][INFO] global_step=131616, episodic_reward_predictor_return=0.36565834283828735\n",
      "[2023-09-13 14:15:17][INFO] global_step=131616, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:18][INFO] global_step=131648, episodic_reward_predictor_return=0.05837414041161537\n",
      "[2023-09-13 14:15:18][INFO] global_step=131648, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:18][INFO] global_step=131664, episodic_reward_predictor_return=0.32651084661483765\n",
      "[2023-09-13 14:15:18][INFO] global_step=131664, episodic_env_return=83.0\n",
      "[2023-09-13 14:15:19][INFO] global_step=131720, episodic_reward_predictor_return=0.3134482800960541\n",
      "[2023-09-13 14:15:19][INFO] global_step=131720, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:20][INFO] global_step=131760, episodic_reward_predictor_return=0.3700990676879883\n",
      "[2023-09-13 14:15:20][INFO] global_step=131760, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:20][INFO] global_step=131760, episodic_reward_predictor_return=0.49932411313056946\n",
      "[2023-09-13 14:15:20][INFO] global_step=131760, episodic_env_return=83.0\n",
      "[2023-09-13 14:15:21][INFO] global_step=131832, episodic_reward_predictor_return=0.481431782245636\n",
      "[2023-09-13 14:15:21][INFO] global_step=131832, episodic_env_return=68.0\n",
      "[2023-09-13 14:15:21][INFO] global_step=131840, episodic_reward_predictor_return=0.7098826766014099\n",
      "[2023-09-13 14:15:21][INFO] global_step=131840, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:22][INFO] global_step=131888, episodic_reward_predictor_return=0.28946906328201294\n",
      "[2023-09-13 14:15:22][INFO] global_step=131888, episodic_env_return=62.0\n",
      "[2023-09-13 14:15:23][INFO] global_step=131920, episodic_reward_predictor_return=0.12716683745384216\n",
      "[2023-09-13 14:15:23][INFO] global_step=131920, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:23][INFO] global_step=131920, episodic_reward_predictor_return=-0.012071076780557632\n",
      "[2023-09-13 14:15:23][INFO] global_step=131920, episodic_env_return=42.0\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_reward_predictor_return=0.3997720181941986\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_env_return=85.0\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_reward_predictor_return=0.43510526418685913\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_reward_predictor_return=0.6476213932037354\n",
      "[2023-09-13 14:15:24][INFO] global_step=132016, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:25][INFO] global_step=132040, episodic_reward_predictor_return=1.5238052606582642\n",
      "[2023-09-13 14:15:25][INFO] global_step=132040, episodic_env_return=-50.0\n",
      "[2023-09-13 14:15:25][INFO] global_step=132064, episodic_reward_predictor_return=-0.0763469785451889\n",
      "[2023-09-13 14:15:25][INFO] global_step=132064, episodic_env_return=63.0\n",
      "[2023-09-13 14:15:25][INFO] global_step=132072, episodic_reward_predictor_return=0.8216038942337036\n",
      "[2023-09-13 14:15:25][INFO] global_step=132072, episodic_env_return=57.0\n",
      "[2023-09-13 14:15:26][INFO] global_step=132104, episodic_reward_predictor_return=0.3363080620765686\n",
      "[2023-09-13 14:15:26][INFO] global_step=132104, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:26][INFO] global_step=132128, episodic_reward_predictor_return=0.2181563377380371\n",
      "[2023-09-13 14:15:26][INFO] global_step=132128, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:27][INFO] global_step=132168, episodic_reward_predictor_return=0.6763383150100708\n",
      "[2023-09-13 14:15:27][INFO] global_step=132168, episodic_env_return=85.0\n",
      "[2023-09-13 14:15:27][INFO] global_step=132184, episodic_reward_predictor_return=-3.878584861755371\n",
      "[2023-09-13 14:15:27][INFO] global_step=132184, episodic_env_return=-375.0\n",
      "[2023-09-13 14:15:28][INFO] global_step=132216, episodic_reward_predictor_return=0.380338191986084\n",
      "[2023-09-13 14:15:28][INFO] global_step=132216, episodic_env_return=76.0\n",
      "[2023-09-13 14:15:29][INFO] global_step=132256, episodic_reward_predictor_return=0.318788081407547\n",
      "[2023-09-13 14:15:29][INFO] global_step=132256, episodic_env_return=77.0\n",
      "[2023-09-13 14:15:29][INFO] global_step=132272, episodic_reward_predictor_return=-0.11880354583263397\n",
      "[2023-09-13 14:15:29][INFO] global_step=132272, episodic_env_return=71.0\n",
      "[2023-09-13 14:15:29][INFO] global_step=132296, episodic_reward_predictor_return=0.42472487688064575\n",
      "[2023-09-13 14:15:29][INFO] global_step=132296, episodic_env_return=80.0\n",
      "[2023-09-13 14:15:30][INFO] global_step=132344, episodic_reward_predictor_return=0.8064661026000977\n",
      "[2023-09-13 14:15:30][INFO] global_step=132344, episodic_env_return=81.0\n",
      "[2023-09-13 14:15:30][INFO] global_step=132352, episodic_reward_predictor_return=0.505457878112793\n",
      "[2023-09-13 14:15:30][INFO] global_step=132352, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:32][INFO] global_step=132440, episodic_reward_predictor_return=0.7783107161521912\n",
      "[2023-09-13 14:15:32][INFO] global_step=132440, episodic_env_return=43.0\n",
      "[2023-09-13 14:15:32][INFO] global_step=132448, episodic_reward_predictor_return=0.312133252620697\n",
      "[2023-09-13 14:15:32][INFO] global_step=132448, episodic_env_return=82.0\n",
      "[2023-09-13 14:15:34][INFO] global_step=132544, episodic_reward_predictor_return=0.11666897684335709\n",
      "[2023-09-13 14:15:34][INFO] global_step=132544, episodic_env_return=77.0\n",
      "[2023-09-13 14:15:34][INFO] global_step=132552, episodic_reward_predictor_return=0.02225877344608307\n",
      "[2023-09-13 14:15:34][INFO] global_step=132552, episodic_env_return=30.0\n",
      "[2023-09-13 14:15:34][INFO] global_step=132560, episodic_reward_predictor_return=0.445039302110672\n",
      "[2023-09-13 14:15:34][INFO] global_step=132560, episodic_env_return=74.0\n",
      "[2023-09-13 14:15:36][INFO] global_step=132656, episodic_reward_predictor_return=0.1071072667837143\n",
      "[2023-09-13 14:15:36][INFO] global_step=132656, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:36][INFO] global_step=132664, episodic_reward_predictor_return=0.4110082983970642\n",
      "[2023-09-13 14:15:36][INFO] global_step=132664, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:36][INFO] global_step=132688, episodic_reward_predictor_return=0.38876351714134216\n",
      "[2023-09-13 14:15:36][INFO] global_step=132688, episodic_env_return=71.0\n",
      "[2023-09-13 14:15:36][INFO] global_step=132704, episodic_reward_predictor_return=0.7177503108978271\n",
      "[2023-09-13 14:15:36][INFO] global_step=132704, episodic_env_return=47.0\n",
      "[2023-09-13 14:15:37][INFO] global_step=132728, episodic_reward_predictor_return=0.4372485876083374\n",
      "[2023-09-13 14:15:37][INFO] global_step=132728, episodic_env_return=60.0\n",
      "[2023-09-13 14:15:37][INFO] global_step=132752, episodic_reward_predictor_return=0.3152187466621399\n",
      "[2023-09-13 14:15:37][INFO] global_step=132752, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:38][INFO] global_step=132808, episodic_reward_predictor_return=0.34551721811294556\n",
      "[2023-09-13 14:15:38][INFO] global_step=132808, episodic_env_return=69.0\n",
      "[2023-09-13 14:15:38][INFO] global_step=132832, episodic_reward_predictor_return=0.6063855290412903\n",
      "[2023-09-13 14:15:38][INFO] global_step=132832, episodic_env_return=88.0\n",
      "[2023-09-13 14:15:39][INFO] global_step=132864, episodic_reward_predictor_return=-0.1872401386499405\n",
      "[2023-09-13 14:15:39][INFO] global_step=132864, episodic_env_return=15.0\n",
      "[2023-09-13 14:15:39][INFO] global_step=132864, episodic_reward_predictor_return=0.3489835858345032\n",
      "[2023-09-13 14:15:39][INFO] global_step=132864, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:39][INFO] global_step=132872, episodic_reward_predictor_return=0.36975041031837463\n",
      "[2023-09-13 14:15:39][INFO] global_step=132872, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:39][INFO] global_step=132880, episodic_reward_predictor_return=0.3571558892726898\n",
      "[2023-09-13 14:15:39][INFO] global_step=132880, episodic_env_return=79.0\n",
      "[2023-09-13 14:15:40][INFO] global_step=132936, episodic_reward_predictor_return=0.5835795998573303\n",
      "[2023-09-13 14:15:40][INFO] global_step=132936, episodic_env_return=67.0\n",
      "[2023-09-13 14:15:41][INFO] global_step=132968, episodic_reward_predictor_return=0.18781927227973938\n",
      "[2023-09-13 14:15:41][INFO] global_step=132968, episodic_env_return=84.0\n",
      "[2023-09-13 14:15:42][INFO] global_step=133048, episodic_reward_predictor_return=0.40682393312454224\n",
      "[2023-09-13 14:15:42][INFO] global_step=133048, episodic_env_return=87.0\n",
      "[2023-09-13 14:15:42][INFO] global_step=133064, episodic_reward_predictor_return=0.4254835546016693\n",
      "[2023-09-13 14:15:42][INFO] global_step=133064, episodic_env_return=76.0\n",
      "[2023-09-13 14:15:43][INFO] global_step=133080, episodic_reward_predictor_return=0.13710857927799225\n",
      "[2023-09-13 14:15:43][INFO] global_step=133080, episodic_env_return=76.0\n",
      "[2023-09-13 14:15:43][INFO] global_step=133104, episodic_reward_predictor_return=0.2967376410961151\n",
      "[2023-09-13 14:15:43][INFO] global_step=133104, episodic_env_return=84.0\n",
      "[2023-09-13 14:15:43][INFO] global_step=133104, episodic_reward_predictor_return=0.8737116456031799\n",
      "[2023-09-13 14:15:43][INFO] global_step=133104, episodic_env_return=71.0\n",
      "[2023-09-13 14:15:43][INFO] global_step=133112, episodic_reward_predictor_return=1.1324418783187866\n",
      "[2023-09-13 14:15:43][INFO] global_step=133112, episodic_env_return=71.0\n",
      "[2023-09-13 14:15:43][INFO] Current Mean Episodic Return = 0.3118647336959839\n",
      "[2023-09-13 14:15:43][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_133120`...\n",
      "[2023-09-13 14:15:44][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_133120`!\n",
      "[2023-09-13 14:15:46][INFO] SPS: 21\n",
      "[2023-09-13 14:15:47][INFO] global_step=133144, episodic_reward_predictor_return=-0.6574704051017761\n",
      "[2023-09-13 14:15:47][INFO] global_step=133144, episodic_env_return=-40.0\n",
      "[2023-09-13 14:15:47][INFO] global_step=133176, episodic_reward_predictor_return=0.2335866540670395\n",
      "[2023-09-13 14:15:47][INFO] global_step=133176, episodic_env_return=50.0\n",
      "[2023-09-13 14:15:48][INFO] global_step=133208, episodic_reward_predictor_return=0.27838069200515747\n",
      "[2023-09-13 14:15:48][INFO] global_step=133208, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:48][INFO] global_step=133216, episodic_reward_predictor_return=0.7023951411247253\n",
      "[2023-09-13 14:15:48][INFO] global_step=133216, episodic_env_return=84.0\n",
      "[2023-09-13 14:15:48][INFO] global_step=133224, episodic_reward_predictor_return=0.27860280871391296\n",
      "[2023-09-13 14:15:48][INFO] global_step=133224, episodic_env_return=81.0\n",
      "[2023-09-13 14:15:48][INFO] global_step=133224, episodic_reward_predictor_return=0.526939332485199\n",
      "[2023-09-13 14:15:48][INFO] global_step=133224, episodic_env_return=86.0\n",
      "[2023-09-13 14:15:48][INFO] global_step=133248, episodic_reward_predictor_return=-0.17245478928089142\n",
      "[2023-09-13 14:15:48][INFO] global_step=133248, episodic_env_return=76.0\n",
      "[2023-09-13 14:15:49][INFO] global_step=133272, episodic_reward_predictor_return=0.5703704357147217\n",
      "[2023-09-13 14:15:49][INFO] global_step=133272, episodic_env_return=80.0\n",
      "[2023-09-13 14:15:49][INFO] global_step=133288, episodic_reward_predictor_return=0.321740984916687\n",
      "[2023-09-13 14:15:49][INFO] global_step=133288, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:51][INFO] global_step=133384, episodic_reward_predictor_return=0.2873014807701111\n",
      "[2023-09-13 14:15:51][INFO] global_step=133384, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:52][INFO] global_step=133448, episodic_reward_predictor_return=0.8205360770225525\n",
      "[2023-09-13 14:15:52][INFO] global_step=133448, episodic_env_return=73.0\n",
      "[2023-09-13 14:15:52][INFO] global_step=133464, episodic_reward_predictor_return=0.5880022644996643\n",
      "[2023-09-13 14:15:52][INFO] global_step=133464, episodic_env_return=64.0\n",
      "[2023-09-13 14:15:53][INFO] global_step=133496, episodic_reward_predictor_return=0.023329436779022217\n",
      "[2023-09-13 14:15:53][INFO] global_step=133496, episodic_env_return=62.0\n",
      "[2023-09-13 14:15:53][INFO] global_step=133512, episodic_reward_predictor_return=0.572161853313446\n",
      "[2023-09-13 14:15:53][INFO] global_step=133512, episodic_env_return=55.0\n",
      "[2023-09-13 14:15:54][INFO] global_step=133560, episodic_reward_predictor_return=-0.07904180884361267\n",
      "[2023-09-13 14:15:54][INFO] global_step=133560, episodic_env_return=53.0\n",
      "[2023-09-13 14:15:54][INFO] global_step=133576, episodic_reward_predictor_return=0.8340432643890381\n",
      "[2023-09-13 14:15:54][INFO] global_step=133576, episodic_env_return=63.0\n",
      "[2023-09-13 14:15:54][INFO] global_step=133584, episodic_reward_predictor_return=0.45689982175827026\n",
      "[2023-09-13 14:15:54][INFO] global_step=133584, episodic_env_return=90.0\n",
      "[2023-09-13 14:15:55][INFO] global_step=133648, episodic_reward_predictor_return=0.6064556837081909\n",
      "[2023-09-13 14:15:55][INFO] global_step=133648, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:55][INFO] global_step=133656, episodic_reward_predictor_return=0.29498186707496643\n",
      "[2023-09-13 14:15:55][INFO] global_step=133656, episodic_env_return=89.0\n",
      "[2023-09-13 14:15:55][INFO] global_step=133672, episodic_reward_predictor_return=0.6603513956069946\n",
      "[2023-09-13 14:15:55][INFO] global_step=133672, episodic_env_return=65.0\n",
      "[2023-09-13 14:15:57][INFO] global_step=133760, episodic_reward_predictor_return=0.11263618618249893\n",
      "[2023-09-13 14:15:57][INFO] global_step=133760, episodic_env_return=78.0\n",
      "[2023-09-13 14:15:57][INFO] global_step=133784, episodic_reward_predictor_return=0.11278606951236725\n",
      "[2023-09-13 14:15:57][INFO] global_step=133784, episodic_env_return=71.0\n",
      "[2023-09-13 14:15:58][INFO] global_step=133808, episodic_reward_predictor_return=0.5815640687942505\n",
      "[2023-09-13 14:15:58][INFO] global_step=133808, episodic_env_return=84.0\n",
      "[2023-09-13 14:15:58][INFO] global_step=133848, episodic_reward_predictor_return=0.61983323097229\n",
      "[2023-09-13 14:15:58][INFO] global_step=133848, episodic_env_return=59.0\n",
      "[2023-09-13 14:15:58][INFO] global_step=133856, episodic_reward_predictor_return=0.20639625191688538\n",
      "[2023-09-13 14:15:58][INFO] global_step=133856, episodic_env_return=92.0\n",
      "[2023-09-13 14:15:59][INFO] global_step=133888, episodic_reward_predictor_return=0.06448405981063843\n",
      "[2023-09-13 14:15:59][INFO] global_step=133888, episodic_env_return=91.0\n",
      "[2023-09-13 14:15:59][INFO] global_step=133896, episodic_reward_predictor_return=0.5608505010604858\n",
      "[2023-09-13 14:15:59][INFO] global_step=133896, episodic_env_return=84.0\n",
      "[2023-09-13 14:16:00][INFO] global_step=133928, episodic_reward_predictor_return=0.5521903038024902\n",
      "[2023-09-13 14:16:00][INFO] global_step=133928, episodic_env_return=67.0\n",
      "[2023-09-13 14:16:00][INFO] global_step=133936, episodic_reward_predictor_return=0.40671107172966003\n",
      "[2023-09-13 14:16:00][INFO] global_step=133936, episodic_env_return=60.0\n",
      "[2023-09-13 14:16:00][INFO] global_step=133952, episodic_reward_predictor_return=0.15093186497688293\n",
      "[2023-09-13 14:16:00][INFO] global_step=133952, episodic_env_return=89.0\n",
      "[2023-09-13 14:16:00][INFO] global_step=133952, episodic_reward_predictor_return=0.30961668491363525\n",
      "[2023-09-13 14:16:00][INFO] global_step=133952, episodic_env_return=-2.0\n",
      "[2023-09-13 14:16:01][INFO] global_step=134000, episodic_reward_predictor_return=0.3970431685447693\n",
      "[2023-09-13 14:16:01][INFO] global_step=134000, episodic_env_return=87.0\n",
      "[2023-09-13 14:16:01][INFO] global_step=134024, episodic_reward_predictor_return=0.3662126660346985\n",
      "[2023-09-13 14:16:01][INFO] global_step=134024, episodic_env_return=79.0\n",
      "[2023-09-13 14:16:03][INFO] global_step=134104, episodic_reward_predictor_return=0.2842402458190918\n",
      "[2023-09-13 14:16:03][INFO] global_step=134104, episodic_env_return=75.0\n",
      "[2023-09-13 14:16:04][INFO] global_step=134160, episodic_reward_predictor_return=0.3435296416282654\n",
      "[2023-09-13 14:16:04][INFO] global_step=134160, episodic_env_return=73.0\n",
      "[2023-09-13 14:16:04][INFO] global_step=134168, episodic_reward_predictor_return=0.1636096090078354\n",
      "[2023-09-13 14:16:04][INFO] global_step=134168, episodic_env_return=-4.0\n",
      "[2023-09-13 14:16:04][INFO] global_step=134184, episodic_reward_predictor_return=-0.20158793032169342\n",
      "[2023-09-13 14:16:04][INFO] global_step=134184, episodic_env_return=67.0\n",
      "[2023-09-13 14:16:05][INFO] global_step=134224, episodic_reward_predictor_return=0.3592430353164673\n",
      "[2023-09-13 14:16:05][INFO] global_step=134224, episodic_env_return=86.0\n",
      "[2023-09-13 14:16:05][INFO] global_step=134248, episodic_reward_predictor_return=0.3514312207698822\n",
      "[2023-09-13 14:16:05][INFO] global_step=134248, episodic_env_return=68.0\n",
      "[2023-09-13 14:16:06][INFO] global_step=134288, episodic_reward_predictor_return=0.32647180557250977\n",
      "[2023-09-13 14:16:06][INFO] global_step=134288, episodic_env_return=59.0\n",
      "[2023-09-13 14:16:07][INFO] global_step=134360, episodic_reward_predictor_return=0.6649394631385803\n",
      "[2023-09-13 14:16:07][INFO] global_step=134360, episodic_env_return=51.0\n",
      "[2023-09-13 14:16:07][INFO] global_step=134368, episodic_reward_predictor_return=-0.48276737332344055\n",
      "[2023-09-13 14:16:07][INFO] global_step=134368, episodic_env_return=41.0\n",
      "[2023-09-13 14:16:08][INFO] global_step=134408, episodic_reward_predictor_return=0.07861144840717316\n",
      "[2023-09-13 14:16:08][INFO] global_step=134408, episodic_env_return=71.0\n",
      "[2023-09-13 14:16:09][INFO] global_step=134464, episodic_reward_predictor_return=0.30050337314605713\n",
      "[2023-09-13 14:16:09][INFO] global_step=134464, episodic_env_return=88.0\n",
      "[2023-09-13 14:16:10][INFO] global_step=134544, episodic_reward_predictor_return=0.6765568852424622\n",
      "[2023-09-13 14:16:10][INFO] global_step=134544, episodic_env_return=79.0\n",
      "[2023-09-13 14:16:10][INFO] global_step=134552, episodic_reward_predictor_return=0.22676780819892883\n",
      "[2023-09-13 14:16:10][INFO] global_step=134552, episodic_env_return=90.0\n",
      "[2023-09-13 14:16:10][INFO] global_step=134568, episodic_reward_predictor_return=0.2852875590324402\n",
      "[2023-09-13 14:16:10][INFO] global_step=134568, episodic_env_return=58.0\n",
      "[2023-09-13 14:16:12][INFO] global_step=134680, episodic_reward_predictor_return=-0.0013532182201743126\n",
      "[2023-09-13 14:16:12][INFO] global_step=134680, episodic_env_return=87.0\n",
      "[2023-09-13 14:16:13][INFO] global_step=134720, episodic_reward_predictor_return=0.1858348250389099\n",
      "[2023-09-13 14:16:13][INFO] global_step=134720, episodic_env_return=24.0\n",
      "[2023-09-13 14:16:13][INFO] global_step=134728, episodic_reward_predictor_return=0.35668984055519104\n",
      "[2023-09-13 14:16:13][INFO] global_step=134728, episodic_env_return=78.0\n",
      "[2023-09-13 14:16:14][INFO] global_step=134760, episodic_reward_predictor_return=0.5634072422981262\n",
      "[2023-09-13 14:16:14][INFO] global_step=134760, episodic_env_return=52.0\n",
      "[2023-09-13 14:16:14][INFO] global_step=134784, episodic_reward_predictor_return=-0.7043409943580627\n",
      "[2023-09-13 14:16:14][INFO] global_step=134784, episodic_env_return=3.0\n",
      "[2023-09-13 14:16:15][INFO] global_step=134824, episodic_reward_predictor_return=0.41676065325737\n",
      "[2023-09-13 14:16:15][INFO] global_step=134824, episodic_env_return=88.0\n",
      "[2023-09-13 14:16:15][INFO] global_step=134832, episodic_reward_predictor_return=0.2765295207500458\n",
      "[2023-09-13 14:16:15][INFO] global_step=134832, episodic_env_return=92.0\n",
      "[2023-09-13 14:16:16][INFO] global_step=134880, episodic_reward_predictor_return=-0.0610755980014801\n",
      "[2023-09-13 14:16:16][INFO] global_step=134880, episodic_env_return=55.0\n",
      "[2023-09-13 14:16:16][INFO] global_step=134896, episodic_reward_predictor_return=0.25798797607421875\n",
      "[2023-09-13 14:16:16][INFO] global_step=134896, episodic_env_return=92.0\n",
      "[2023-09-13 14:16:16][INFO] global_step=134904, episodic_reward_predictor_return=0.6955623626708984\n",
      "[2023-09-13 14:16:16][INFO] global_step=134904, episodic_env_return=9.0\n",
      "[2023-09-13 14:16:16][INFO] global_step=134912, episodic_reward_predictor_return=0.2620939016342163\n",
      "[2023-09-13 14:16:16][INFO] global_step=134912, episodic_env_return=85.0\n",
      "[2023-09-13 14:16:18][INFO] global_step=135000, episodic_reward_predictor_return=0.994080662727356\n",
      "[2023-09-13 14:16:18][INFO] global_step=135000, episodic_env_return=67.0\n",
      "[2023-09-13 14:16:18][INFO] global_step=135008, episodic_reward_predictor_return=0.1421288400888443\n",
      "[2023-09-13 14:16:18][INFO] global_step=135008, episodic_env_return=87.0\n",
      "[2023-09-13 14:16:18][INFO] global_step=135032, episodic_reward_predictor_return=0.3566528260707855\n",
      "[2023-09-13 14:16:18][INFO] global_step=135032, episodic_env_return=-7.0\n",
      "[2023-09-13 14:16:20][INFO] global_step=135120, episodic_reward_predictor_return=0.4727485179901123\n",
      "[2023-09-13 14:16:20][INFO] global_step=135120, episodic_env_return=86.0\n",
      "[2023-09-13 14:16:20][INFO] global_step=135152, episodic_reward_predictor_return=-0.13253091275691986\n",
      "[2023-09-13 14:16:20][INFO] global_step=135152, episodic_env_return=56.0\n",
      "[2023-09-13 14:16:21][INFO] Current Mean Episodic Return = 0.3023235499858856\n",
      "[2023-09-13 14:16:21][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_135168`...\n",
      "[2023-09-13 14:16:21][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_135168`!\n",
      "[2023-09-13 14:16:23][INFO] SPS: 21\n",
      "[2023-09-13 14:16:24][INFO] global_step=135200, episodic_reward_predictor_return=0.17046380043029785\n",
      "[2023-09-13 14:16:24][INFO] global_step=135200, episodic_env_return=59.0\n",
      "[2023-09-13 14:16:25][INFO] global_step=135248, episodic_reward_predictor_return=0.3235842287540436\n",
      "[2023-09-13 14:16:25][INFO] global_step=135248, episodic_env_return=54.0\n",
      "[2023-09-13 14:16:25][INFO] global_step=135280, episodic_reward_predictor_return=0.09397760778665543\n",
      "[2023-09-13 14:16:25][INFO] global_step=135280, episodic_env_return=91.0\n",
      "[2023-09-13 14:16:25][INFO] global_step=135288, episodic_reward_predictor_return=0.28193071484565735\n",
      "[2023-09-13 14:16:25][INFO] global_step=135288, episodic_env_return=61.0\n",
      "[2023-09-13 14:16:26][INFO] global_step=135304, episodic_reward_predictor_return=0.4450744092464447\n",
      "[2023-09-13 14:16:26][INFO] global_step=135304, episodic_env_return=13.0\n",
      "[2023-09-13 14:16:26][INFO] global_step=135344, episodic_reward_predictor_return=0.06113528832793236\n",
      "[2023-09-13 14:16:26][INFO] global_step=135344, episodic_env_return=33.0\n",
      "[2023-09-13 14:16:26][INFO] global_step=135344, episodic_reward_predictor_return=0.6166645288467407\n",
      "[2023-09-13 14:16:26][INFO] global_step=135344, episodic_env_return=89.0\n",
      "[2023-09-13 14:16:27][INFO] global_step=135384, episodic_reward_predictor_return=0.3290402889251709\n",
      "[2023-09-13 14:16:27][INFO] global_step=135384, episodic_env_return=89.0\n",
      "[2023-09-13 14:16:27][INFO] global_step=135400, episodic_reward_predictor_return=0.46133697032928467\n",
      "[2023-09-13 14:16:27][INFO] global_step=135400, episodic_env_return=70.0\n",
      "[2023-09-13 14:16:29][INFO] global_step=135480, episodic_reward_predictor_return=0.2063492089509964\n",
      "[2023-09-13 14:16:29][INFO] global_step=135480, episodic_env_return=51.0\n",
      "[2023-09-13 14:16:29][INFO] global_step=135496, episodic_reward_predictor_return=0.24448230862617493\n",
      "[2023-09-13 14:16:29][INFO] global_step=135496, episodic_env_return=82.0\n",
      "[2023-09-13 14:16:29][INFO] global_step=135528, episodic_reward_predictor_return=0.5286337733268738\n",
      "[2023-09-13 14:16:29][INFO] global_step=135528, episodic_env_return=78.0\n",
      "[2023-09-13 14:16:30][INFO] global_step=135544, episodic_reward_predictor_return=0.1596892774105072\n",
      "[2023-09-13 14:16:30][INFO] global_step=135544, episodic_env_return=27.0\n",
      "[2023-09-13 14:16:30][INFO] global_step=135584, episodic_reward_predictor_return=0.19417864084243774\n",
      "[2023-09-13 14:16:30][INFO] global_step=135584, episodic_env_return=88.0\n",
      "[2023-09-13 14:16:30][INFO] global_step=135600, episodic_reward_predictor_return=0.7219945192337036\n",
      "[2023-09-13 14:16:30][INFO] global_step=135600, episodic_env_return=61.0\n",
      "[2023-09-13 14:16:31][INFO] global_step=135608, episodic_reward_predictor_return=0.08005094528198242\n",
      "[2023-09-13 14:16:31][INFO] global_step=135608, episodic_env_return=68.0\n",
      "[2023-09-13 14:16:32][INFO] global_step=135680, episodic_reward_predictor_return=0.13748718798160553\n",
      "[2023-09-13 14:16:32][INFO] global_step=135680, episodic_env_return=73.0\n",
      "[2023-09-13 14:16:32][INFO] global_step=135704, episodic_reward_predictor_return=-0.10705586522817612\n",
      "[2023-09-13 14:16:32][INFO] global_step=135704, episodic_env_return=46.0\n",
      "[2023-09-13 14:16:34][INFO] global_step=135808, episodic_reward_predictor_return=0.4838458001613617\n",
      "[2023-09-13 14:16:34][INFO] global_step=135808, episodic_env_return=85.0\n",
      "[2023-09-13 14:16:34][INFO] global_step=135824, episodic_reward_predictor_return=0.5176116228103638\n",
      "[2023-09-13 14:16:34][INFO] global_step=135824, episodic_env_return=71.0\n",
      "[2023-09-13 14:16:36][INFO] global_step=135904, episodic_reward_predictor_return=0.4537431597709656\n",
      "[2023-09-13 14:16:36][INFO] global_step=135904, episodic_env_return=33.0\n",
      "[2023-09-13 14:16:37][INFO] global_step=136008, episodic_reward_predictor_return=0.8408620357513428\n",
      "[2023-09-13 14:16:37][INFO] global_step=136008, episodic_env_return=43.0\n",
      "[2023-09-13 14:16:38][INFO] global_step=136040, episodic_reward_predictor_return=0.30296579003334045\n",
      "[2023-09-13 14:16:38][INFO] global_step=136040, episodic_env_return=84.0\n",
      "[2023-09-13 14:16:38][INFO] global_step=136056, episodic_reward_predictor_return=0.287962943315506\n",
      "[2023-09-13 14:16:38][INFO] global_step=136056, episodic_env_return=57.0\n",
      "[2023-09-13 14:16:38][INFO] global_step=136088, episodic_reward_predictor_return=-1.0321201086044312\n",
      "[2023-09-13 14:16:38][INFO] global_step=136088, episodic_env_return=16.0\n",
      "[2023-09-13 14:16:40][INFO] global_step=136152, episodic_reward_predictor_return=0.2830144762992859\n",
      "[2023-09-13 14:16:40][INFO] global_step=136152, episodic_env_return=17.0\n",
      "[2023-09-13 14:16:40][INFO] global_step=136160, episodic_reward_predictor_return=0.15655426681041718\n",
      "[2023-09-13 14:16:40][INFO] global_step=136160, episodic_env_return=54.0\n",
      "[2023-09-13 14:16:41][INFO] global_step=136256, episodic_reward_predictor_return=0.35792332887649536\n",
      "[2023-09-13 14:16:41][INFO] global_step=136256, episodic_env_return=89.0\n",
      "[2023-09-13 14:16:42][INFO] global_step=136264, episodic_reward_predictor_return=0.3530295491218567\n",
      "[2023-09-13 14:16:42][INFO] global_step=136264, episodic_env_return=75.0\n",
      "[2023-09-13 14:16:42][INFO] global_step=136288, episodic_reward_predictor_return=0.4015437662601471\n",
      "[2023-09-13 14:16:42][INFO] global_step=136288, episodic_env_return=70.0\n",
      "[2023-09-13 14:16:43][INFO] global_step=136368, episodic_reward_predictor_return=0.328389972448349\n",
      "[2023-09-13 14:16:43][INFO] global_step=136368, episodic_env_return=87.0\n",
      "[2023-09-13 14:16:45][INFO] global_step=136464, episodic_reward_predictor_return=0.07070288062095642\n",
      "[2023-09-13 14:16:45][INFO] global_step=136464, episodic_env_return=62.0\n",
      "[2023-09-13 14:16:45][INFO] global_step=136464, episodic_reward_predictor_return=-0.42265748977661133\n",
      "[2023-09-13 14:16:45][INFO] global_step=136464, episodic_env_return=39.0\n",
      "[2023-09-13 14:16:45][INFO] global_step=136480, episodic_reward_predictor_return=0.9193518161773682\n",
      "[2023-09-13 14:16:45][INFO] global_step=136480, episodic_env_return=-23.0\n",
      "[2023-09-13 14:16:45][INFO] global_step=136504, episodic_reward_predictor_return=0.5294396877288818\n",
      "[2023-09-13 14:16:45][INFO] global_step=136504, episodic_env_return=4.0\n",
      "[2023-09-13 14:16:46][INFO] global_step=136512, episodic_reward_predictor_return=0.3563655614852905\n",
      "[2023-09-13 14:16:46][INFO] global_step=136512, episodic_env_return=70.0\n",
      "[2023-09-13 14:16:46][INFO] global_step=136520, episodic_reward_predictor_return=1.3496949672698975\n",
      "[2023-09-13 14:16:46][INFO] global_step=136520, episodic_env_return=47.0\n",
      "[2023-09-13 14:16:48][INFO] global_step=136632, episodic_reward_predictor_return=0.18108361959457397\n",
      "[2023-09-13 14:16:48][INFO] global_step=136632, episodic_env_return=85.0\n",
      "[2023-09-13 14:16:48][INFO] global_step=136640, episodic_reward_predictor_return=0.33026260137557983\n",
      "[2023-09-13 14:16:48][INFO] global_step=136640, episodic_env_return=86.0\n",
      "[2023-09-13 14:16:48][INFO] global_step=136680, episodic_reward_predictor_return=0.28929758071899414\n",
      "[2023-09-13 14:16:48][INFO] global_step=136680, episodic_env_return=69.0\n",
      "[2023-09-13 14:16:48][INFO] global_step=136688, episodic_reward_predictor_return=0.02135530486702919\n",
      "[2023-09-13 14:16:48][INFO] global_step=136688, episodic_env_return=46.0\n",
      "[2023-09-13 14:16:50][INFO] global_step=136792, episodic_reward_predictor_return=1.1053889989852905\n",
      "[2023-09-13 14:16:50][INFO] global_step=136792, episodic_env_return=48.0\n",
      "[2023-09-13 14:16:51][INFO] global_step=136816, episodic_reward_predictor_return=0.39410847425460815\n",
      "[2023-09-13 14:16:51][INFO] global_step=136816, episodic_env_return=47.0\n",
      "[2023-09-13 14:16:51][INFO] global_step=136856, episodic_reward_predictor_return=0.2317553162574768\n",
      "[2023-09-13 14:16:51][INFO] global_step=136856, episodic_env_return=80.0\n",
      "[2023-09-13 14:16:52][INFO] global_step=136888, episodic_reward_predictor_return=0.4948185682296753\n",
      "[2023-09-13 14:16:52][INFO] global_step=136888, episodic_env_return=49.0\n",
      "[2023-09-13 14:16:54][INFO] global_step=137016, episodic_reward_predictor_return=-0.18157003819942474\n",
      "[2023-09-13 14:16:54][INFO] global_step=137016, episodic_env_return=43.0\n",
      "[2023-09-13 14:16:54][INFO] global_step=137024, episodic_reward_predictor_return=0.46481257677078247\n",
      "[2023-09-13 14:16:54][INFO] global_step=137024, episodic_env_return=84.0\n",
      "[2023-09-13 14:16:55][INFO] global_step=137056, episodic_reward_predictor_return=0.5208123326301575\n",
      "[2023-09-13 14:16:55][INFO] global_step=137056, episodic_env_return=54.0\n",
      "[2023-09-13 14:16:55][INFO] global_step=137072, episodic_reward_predictor_return=0.3366602063179016\n",
      "[2023-09-13 14:16:55][INFO] global_step=137072, episodic_env_return=69.0\n",
      "[2023-09-13 14:16:56][INFO] global_step=137120, episodic_reward_predictor_return=0.5010063052177429\n",
      "[2023-09-13 14:16:56][INFO] global_step=137120, episodic_env_return=68.0\n",
      "[2023-09-13 14:16:56][INFO] global_step=137128, episodic_reward_predictor_return=0.29596611857414246\n",
      "[2023-09-13 14:16:56][INFO] global_step=137128, episodic_env_return=59.0\n",
      "[2023-09-13 14:16:56][INFO] global_step=137160, episodic_reward_predictor_return=0.20305782556533813\n",
      "[2023-09-13 14:16:56][INFO] global_step=137160, episodic_env_return=90.0\n",
      "[2023-09-13 14:16:57][INFO] global_step=137192, episodic_reward_predictor_return=-0.5323903560638428\n",
      "[2023-09-13 14:16:57][INFO] global_step=137192, episodic_env_return=-3.0\n",
      "[2023-09-13 14:16:57][INFO] global_step=137192, episodic_reward_predictor_return=0.27872371673583984\n",
      "[2023-09-13 14:16:57][INFO] global_step=137192, episodic_env_return=92.0\n",
      "[2023-09-13 14:16:57][INFO] Current Mean Episodic Return = 0.3041183352470398\n",
      "[2023-09-13 14:16:57][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_137216`...\n",
      "[2023-09-13 14:16:57][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_137216`!\n",
      "[2023-09-13 14:17:00][INFO] SPS: 21\n",
      "[2023-09-13 14:17:01][INFO] global_step=137272, episodic_reward_predictor_return=0.4313936233520508\n",
      "[2023-09-13 14:17:01][INFO] global_step=137272, episodic_env_return=87.0\n",
      "[2023-09-13 14:17:02][INFO] global_step=137320, episodic_reward_predictor_return=0.11689389497041702\n",
      "[2023-09-13 14:17:02][INFO] global_step=137320, episodic_env_return=85.0\n",
      "[2023-09-13 14:17:03][INFO] global_step=137368, episodic_reward_predictor_return=0.3948947489261627\n",
      "[2023-09-13 14:17:03][INFO] global_step=137368, episodic_env_return=89.0\n",
      "[2023-09-13 14:17:03][INFO] global_step=137400, episodic_reward_predictor_return=0.4723793864250183\n",
      "[2023-09-13 14:17:03][INFO] global_step=137400, episodic_env_return=67.0\n",
      "[2023-09-13 14:17:04][INFO] global_step=137464, episodic_reward_predictor_return=0.5461857318878174\n",
      "[2023-09-13 14:17:04][INFO] global_step=137464, episodic_env_return=-17.0\n",
      "[2023-09-13 14:17:04][INFO] global_step=137472, episodic_reward_predictor_return=0.3816739320755005\n",
      "[2023-09-13 14:17:04][INFO] global_step=137472, episodic_env_return=92.0\n",
      "[2023-09-13 14:17:05][INFO] global_step=137536, episodic_reward_predictor_return=1.413588047027588\n",
      "[2023-09-13 14:17:05][INFO] global_step=137536, episodic_env_return=37.0\n",
      "[2023-09-13 14:17:06][INFO] global_step=137568, episodic_reward_predictor_return=0.8680492043495178\n",
      "[2023-09-13 14:17:06][INFO] global_step=137568, episodic_env_return=70.0\n",
      "[2023-09-13 14:17:06][INFO] global_step=137600, episodic_reward_predictor_return=1.7802517414093018\n",
      "[2023-09-13 14:17:06][INFO] global_step=137600, episodic_env_return=50.0\n",
      "[2023-09-13 14:17:07][INFO] global_step=137672, episodic_reward_predictor_return=0.4846780002117157\n",
      "[2023-09-13 14:17:07][INFO] global_step=137672, episodic_env_return=84.0\n",
      "[2023-09-13 14:17:08][INFO] global_step=137680, episodic_reward_predictor_return=0.8511455059051514\n",
      "[2023-09-13 14:17:08][INFO] global_step=137680, episodic_env_return=74.0\n",
      "[2023-09-13 14:17:08][INFO] global_step=137712, episodic_reward_predictor_return=0.6511723399162292\n",
      "[2023-09-13 14:17:08][INFO] global_step=137712, episodic_env_return=71.0\n",
      "[2023-09-13 14:17:08][INFO] global_step=137720, episodic_reward_predictor_return=0.5164702534675598\n",
      "[2023-09-13 14:17:08][INFO] global_step=137720, episodic_env_return=57.0\n",
      "[2023-09-13 14:17:09][INFO] global_step=137776, episodic_reward_predictor_return=0.18923476338386536\n",
      "[2023-09-13 14:17:09][INFO] global_step=137776, episodic_env_return=-4.0\n",
      "[2023-09-13 14:17:10][INFO] global_step=137808, episodic_reward_predictor_return=0.14652352035045624\n",
      "[2023-09-13 14:17:10][INFO] global_step=137808, episodic_env_return=89.0\n",
      "[2023-09-13 14:17:10][INFO] global_step=137824, episodic_reward_predictor_return=0.6066452264785767\n",
      "[2023-09-13 14:17:10][INFO] global_step=137824, episodic_env_return=82.0\n",
      "[2023-09-13 14:17:11][INFO] global_step=137880, episodic_reward_predictor_return=1.054776668548584\n",
      "[2023-09-13 14:17:11][INFO] global_step=137880, episodic_env_return=-22.0\n",
      "[2023-09-13 14:17:12][INFO] global_step=137904, episodic_reward_predictor_return=0.46235227584838867\n",
      "[2023-09-13 14:17:12][INFO] global_step=137904, episodic_env_return=78.0\n",
      "[2023-09-13 14:17:12][INFO] global_step=137912, episodic_reward_predictor_return=0.38852494955062866\n",
      "[2023-09-13 14:17:12][INFO] global_step=137912, episodic_env_return=72.0\n",
      "[2023-09-13 14:17:12][INFO] global_step=137944, episodic_reward_predictor_return=0.3051146864891052\n",
      "[2023-09-13 14:17:12][INFO] global_step=137944, episodic_env_return=86.0\n",
      "[2023-09-13 14:17:13][INFO] global_step=137976, episodic_reward_predictor_return=0.5209092497825623\n",
      "[2023-09-13 14:17:13][INFO] global_step=137976, episodic_env_return=76.0\n",
      "[2023-09-13 14:17:13][INFO] global_step=138000, episodic_reward_predictor_return=0.5175380110740662\n",
      "[2023-09-13 14:17:13][INFO] global_step=138000, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:14][INFO] global_step=138040, episodic_reward_predictor_return=-0.43225640058517456\n",
      "[2023-09-13 14:17:14][INFO] global_step=138040, episodic_env_return=41.0\n",
      "[2023-09-13 14:17:14][INFO] global_step=138064, episodic_reward_predictor_return=0.3644114136695862\n",
      "[2023-09-13 14:17:14][INFO] global_step=138064, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:14][INFO] global_step=138080, episodic_reward_predictor_return=0.31973257660865784\n",
      "[2023-09-13 14:17:14][INFO] global_step=138080, episodic_env_return=76.0\n",
      "[2023-09-13 14:17:16][INFO] global_step=138200, episodic_reward_predictor_return=-0.05250921472907066\n",
      "[2023-09-13 14:17:16][INFO] global_step=138200, episodic_env_return=42.0\n",
      "[2023-09-13 14:17:17][INFO] global_step=138240, episodic_reward_predictor_return=0.45516666769981384\n",
      "[2023-09-13 14:17:17][INFO] global_step=138240, episodic_env_return=71.0\n",
      "[2023-09-13 14:17:17][INFO] global_step=138248, episodic_reward_predictor_return=0.23543792963027954\n",
      "[2023-09-13 14:17:17][INFO] global_step=138248, episodic_env_return=53.0\n",
      "[2023-09-13 14:17:17][INFO] global_step=138264, episodic_reward_predictor_return=0.564039945602417\n",
      "[2023-09-13 14:17:17][INFO] global_step=138264, episodic_env_return=61.0\n",
      "[2023-09-13 14:17:19][INFO] global_step=138336, episodic_reward_predictor_return=0.14146669209003448\n",
      "[2023-09-13 14:17:19][INFO] global_step=138336, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:19][INFO] global_step=138360, episodic_reward_predictor_return=0.2015703022480011\n",
      "[2023-09-13 14:17:19][INFO] global_step=138360, episodic_env_return=-8.0\n",
      "[2023-09-13 14:17:20][INFO] global_step=138424, episodic_reward_predictor_return=0.8651242256164551\n",
      "[2023-09-13 14:17:20][INFO] global_step=138424, episodic_env_return=56.0\n",
      "[2023-09-13 14:17:22][INFO] global_step=138512, episodic_reward_predictor_return=0.2842938303947449\n",
      "[2023-09-13 14:17:22][INFO] global_step=138512, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:23][INFO] global_step=138560, episodic_reward_predictor_return=0.21430236101150513\n",
      "[2023-09-13 14:17:23][INFO] global_step=138560, episodic_env_return=36.0\n",
      "[2023-09-13 14:17:23][INFO] global_step=138576, episodic_reward_predictor_return=1.1610125303268433\n",
      "[2023-09-13 14:17:23][INFO] global_step=138576, episodic_env_return=62.0\n",
      "[2023-09-13 14:17:23][INFO] global_step=138592, episodic_reward_predictor_return=0.12138902395963669\n",
      "[2023-09-13 14:17:23][INFO] global_step=138592, episodic_env_return=27.0\n",
      "[2023-09-13 14:17:24][INFO] global_step=138640, episodic_reward_predictor_return=1.4619174003601074\n",
      "[2023-09-13 14:17:24][INFO] global_step=138640, episodic_env_return=51.0\n",
      "[2023-09-13 14:17:24][INFO] global_step=138640, episodic_reward_predictor_return=0.9394264817237854\n",
      "[2023-09-13 14:17:24][INFO] global_step=138640, episodic_env_return=46.0\n",
      "[2023-09-13 14:17:24][INFO] global_step=138648, episodic_reward_predictor_return=0.27541980147361755\n",
      "[2023-09-13 14:17:24][INFO] global_step=138648, episodic_env_return=92.0\n",
      "[2023-09-13 14:17:25][INFO] global_step=138736, episodic_reward_predictor_return=0.3472089171409607\n",
      "[2023-09-13 14:17:25][INFO] global_step=138736, episodic_env_return=79.0\n",
      "[2023-09-13 14:17:26][INFO] global_step=138760, episodic_reward_predictor_return=-0.43396854400634766\n",
      "[2023-09-13 14:17:26][INFO] global_step=138760, episodic_env_return=38.0\n",
      "[2023-09-13 14:17:26][INFO] global_step=138768, episodic_reward_predictor_return=0.29691600799560547\n",
      "[2023-09-13 14:17:26][INFO] global_step=138768, episodic_env_return=86.0\n",
      "[2023-09-13 14:17:27][INFO] global_step=138848, episodic_reward_predictor_return=0.7300918698310852\n",
      "[2023-09-13 14:17:27][INFO] global_step=138848, episodic_env_return=75.0\n",
      "[2023-09-13 14:17:28][INFO] global_step=138888, episodic_reward_predictor_return=0.27167171239852905\n",
      "[2023-09-13 14:17:28][INFO] global_step=138888, episodic_env_return=49.0\n",
      "[2023-09-13 14:17:29][INFO] global_step=138936, episodic_reward_predictor_return=-0.002457583323121071\n",
      "[2023-09-13 14:17:29][INFO] global_step=138936, episodic_env_return=64.0\n",
      "[2023-09-13 14:17:29][INFO] global_step=138960, episodic_reward_predictor_return=1.0098106861114502\n",
      "[2023-09-13 14:17:29][INFO] global_step=138960, episodic_env_return=55.0\n",
      "[2023-09-13 14:17:31][INFO] global_step=139040, episodic_reward_predictor_return=1.0519933700561523\n",
      "[2023-09-13 14:17:31][INFO] global_step=139040, episodic_env_return=63.0\n",
      "[2023-09-13 14:17:32][INFO] global_step=139104, episodic_reward_predictor_return=0.40775585174560547\n",
      "[2023-09-13 14:17:32][INFO] global_step=139104, episodic_env_return=64.0\n",
      "[2023-09-13 14:17:32][INFO] global_step=139104, episodic_reward_predictor_return=1.0190658569335938\n",
      "[2023-09-13 14:17:32][INFO] global_step=139104, episodic_env_return=59.0\n",
      "[2023-09-13 14:17:32][INFO] global_step=139120, episodic_reward_predictor_return=0.33758506178855896\n",
      "[2023-09-13 14:17:32][INFO] global_step=139120, episodic_env_return=91.0\n",
      "[2023-09-13 14:17:33][INFO] global_step=139144, episodic_reward_predictor_return=0.38796883821487427\n",
      "[2023-09-13 14:17:33][INFO] global_step=139144, episodic_env_return=69.0\n",
      "[2023-09-13 14:17:33][INFO] global_step=139152, episodic_reward_predictor_return=0.15455548465251923\n",
      "[2023-09-13 14:17:33][INFO] global_step=139152, episodic_env_return=47.0\n",
      "[2023-09-13 14:17:33][INFO] global_step=139168, episodic_reward_predictor_return=0.2864559590816498\n",
      "[2023-09-13 14:17:33][INFO] global_step=139168, episodic_env_return=75.0\n",
      "[2023-09-13 14:17:33][INFO] global_step=139176, episodic_reward_predictor_return=0.3691878616809845\n",
      "[2023-09-13 14:17:33][INFO] global_step=139176, episodic_env_return=71.0\n",
      "[2023-09-13 14:17:34][INFO] global_step=139240, episodic_reward_predictor_return=0.24294202029705048\n",
      "[2023-09-13 14:17:34][INFO] global_step=139240, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:34][INFO] global_step=139256, episodic_reward_predictor_return=0.08862383663654327\n",
      "[2023-09-13 14:17:34][INFO] global_step=139256, episodic_env_return=90.0\n",
      "[2023-09-13 14:17:34][INFO] Current Mean Episodic Return = 0.47831693291664124\n",
      "[2023-09-13 14:17:34][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_139264`...\n",
      "[2023-09-13 14:17:35][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_139264`!\n",
      "[2023-09-13 14:17:37][INFO] SPS: 21\n",
      "[2023-09-13 14:17:38][INFO] global_step=139312, episodic_reward_predictor_return=0.9885504245758057\n",
      "[2023-09-13 14:17:38][INFO] global_step=139312, episodic_env_return=-43.0\n",
      "[2023-09-13 14:17:39][INFO] global_step=139384, episodic_reward_predictor_return=0.18946459889411926\n",
      "[2023-09-13 14:17:39][INFO] global_step=139384, episodic_env_return=61.0\n",
      "[2023-09-13 14:17:40][INFO] global_step=139448, episodic_reward_predictor_return=0.5685617327690125\n",
      "[2023-09-13 14:17:40][INFO] global_step=139448, episodic_env_return=77.0\n",
      "[2023-09-13 14:17:40][INFO] global_step=139464, episodic_reward_predictor_return=0.016418982297182083\n",
      "[2023-09-13 14:17:40][INFO] global_step=139464, episodic_env_return=51.0\n",
      "[2023-09-13 14:17:41][INFO] global_step=139512, episodic_reward_predictor_return=0.22380973398685455\n",
      "[2023-09-13 14:17:41][INFO] global_step=139512, episodic_env_return=45.0\n",
      "[2023-09-13 14:17:41][INFO] global_step=139520, episodic_reward_predictor_return=0.959913432598114\n",
      "[2023-09-13 14:17:41][INFO] global_step=139520, episodic_env_return=51.0\n",
      "[2023-09-13 14:17:42][INFO] global_step=139576, episodic_reward_predictor_return=0.2001684308052063\n",
      "[2023-09-13 14:17:42][INFO] global_step=139576, episodic_env_return=68.0\n",
      "[2023-09-13 14:17:43][INFO] global_step=139592, episodic_reward_predictor_return=0.4461970031261444\n",
      "[2023-09-13 14:17:43][INFO] global_step=139592, episodic_env_return=52.0\n",
      "[2023-09-13 14:17:44][INFO] global_step=139680, episodic_reward_predictor_return=0.4421396255493164\n",
      "[2023-09-13 14:17:44][INFO] global_step=139680, episodic_env_return=81.0\n",
      "[2023-09-13 14:17:44][INFO] global_step=139680, episodic_reward_predictor_return=0.30582210421562195\n",
      "[2023-09-13 14:17:44][INFO] global_step=139680, episodic_env_return=72.0\n",
      "[2023-09-13 14:17:45][INFO] global_step=139728, episodic_reward_predictor_return=0.40266409516334534\n",
      "[2023-09-13 14:17:45][INFO] global_step=139728, episodic_env_return=82.0\n",
      "[2023-09-13 14:17:45][INFO] global_step=139728, episodic_reward_predictor_return=-0.5930365920066833\n",
      "[2023-09-13 14:17:45][INFO] global_step=139728, episodic_env_return=22.0\n",
      "[2023-09-13 14:17:45][INFO] global_step=139760, episodic_reward_predictor_return=0.20504264533519745\n",
      "[2023-09-13 14:17:45][INFO] global_step=139760, episodic_env_return=64.0\n",
      "[2023-09-13 14:17:46][INFO] global_step=139816, episodic_reward_predictor_return=0.0034232139587402344\n",
      "[2023-09-13 14:17:46][INFO] global_step=139816, episodic_env_return=42.0\n",
      "[2023-09-13 14:17:47][INFO] global_step=139880, episodic_reward_predictor_return=0.46940022706985474\n",
      "[2023-09-13 14:17:47][INFO] global_step=139880, episodic_env_return=82.0\n",
      "[2023-09-13 14:17:48][INFO] global_step=139888, episodic_reward_predictor_return=0.640494704246521\n",
      "[2023-09-13 14:17:48][INFO] global_step=139888, episodic_env_return=85.0\n",
      "[2023-09-13 14:17:48][INFO] global_step=139896, episodic_reward_predictor_return=0.4281386137008667\n",
      "[2023-09-13 14:17:48][INFO] global_step=139896, episodic_env_return=74.0\n",
      "[2023-09-13 14:17:48][INFO] global_step=139896, episodic_reward_predictor_return=0.767109751701355\n",
      "[2023-09-13 14:17:48][INFO] global_step=139896, episodic_env_return=53.0\n",
      "[2023-09-13 14:17:50][INFO] global_step=140024, episodic_reward_predictor_return=0.3307178020477295\n",
      "[2023-09-13 14:17:50][INFO] global_step=140024, episodic_env_return=85.0\n",
      "[2023-09-13 14:17:50][INFO] global_step=140032, episodic_reward_predictor_return=0.7561999559402466\n",
      "[2023-09-13 14:17:50][INFO] global_step=140032, episodic_env_return=41.0\n",
      "[2023-09-13 14:17:51][INFO] global_step=140088, episodic_reward_predictor_return=0.30320289731025696\n",
      "[2023-09-13 14:17:51][INFO] global_step=140088, episodic_env_return=56.0\n",
      "[2023-09-13 14:17:52][INFO] global_step=140128, episodic_reward_predictor_return=0.9577441215515137\n",
      "[2023-09-13 14:17:52][INFO] global_step=140128, episodic_env_return=62.0\n",
      "[2023-09-13 14:17:52][INFO] global_step=140160, episodic_reward_predictor_return=0.08951247483491898\n",
      "[2023-09-13 14:17:52][INFO] global_step=140160, episodic_env_return=92.0\n",
      "[2023-09-13 14:17:52][INFO] global_step=140184, episodic_reward_predictor_return=-0.16464556753635406\n",
      "[2023-09-13 14:17:52][INFO] global_step=140184, episodic_env_return=28.0\n",
      "[2023-09-13 14:17:53][INFO] global_step=140232, episodic_reward_predictor_return=0.4852920472621918\n",
      "[2023-09-13 14:17:53][INFO] global_step=140232, episodic_env_return=88.0\n",
      "[2023-09-13 14:17:54][INFO] global_step=140256, episodic_reward_predictor_return=-0.015486292541027069\n",
      "[2023-09-13 14:17:54][INFO] global_step=140256, episodic_env_return=50.0\n",
      "[2023-09-13 14:17:54][INFO] global_step=140264, episodic_reward_predictor_return=0.3777114450931549\n",
      "[2023-09-13 14:17:54][INFO] global_step=140264, episodic_env_return=55.0\n",
      "[2023-09-13 14:17:54][INFO] global_step=140296, episodic_reward_predictor_return=0.8366050720214844\n",
      "[2023-09-13 14:17:54][INFO] global_step=140296, episodic_env_return=68.0\n",
      "[2023-09-13 14:17:54][INFO] global_step=140296, episodic_reward_predictor_return=0.4403397738933563\n",
      "[2023-09-13 14:17:54][INFO] global_step=140296, episodic_env_return=87.0\n",
      "[2023-09-13 14:17:55][INFO] global_step=140312, episodic_reward_predictor_return=0.8171237707138062\n",
      "[2023-09-13 14:17:55][INFO] global_step=140312, episodic_env_return=65.0\n",
      "[2023-09-13 14:17:55][INFO] global_step=140360, episodic_reward_predictor_return=0.3542502522468567\n",
      "[2023-09-13 14:17:55][INFO] global_step=140360, episodic_env_return=76.0\n",
      "[2023-09-13 14:17:56][INFO] global_step=140368, episodic_reward_predictor_return=0.7464296817779541\n",
      "[2023-09-13 14:17:56][INFO] global_step=140368, episodic_env_return=35.0\n",
      "[2023-09-13 14:17:56][INFO] global_step=140384, episodic_reward_predictor_return=0.19281360507011414\n",
      "[2023-09-13 14:17:56][INFO] global_step=140384, episodic_env_return=92.0\n",
      "[2023-09-13 14:17:57][INFO] global_step=140456, episodic_reward_predictor_return=0.6705580353736877\n",
      "[2023-09-13 14:17:57][INFO] global_step=140456, episodic_env_return=81.0\n",
      "[2023-09-13 14:17:57][INFO] global_step=140472, episodic_reward_predictor_return=0.5261701345443726\n",
      "[2023-09-13 14:17:57][INFO] global_step=140472, episodic_env_return=75.0\n",
      "[2023-09-13 14:17:58][INFO] global_step=140520, episodic_reward_predictor_return=0.3750603497028351\n",
      "[2023-09-13 14:17:58][INFO] global_step=140520, episodic_env_return=84.0\n",
      "[2023-09-13 14:17:58][INFO] global_step=140536, episodic_reward_predictor_return=0.39768773317337036\n",
      "[2023-09-13 14:17:58][INFO] global_step=140536, episodic_env_return=80.0\n",
      "[2023-09-13 14:17:58][INFO] global_step=140552, episodic_reward_predictor_return=0.6229039430618286\n",
      "[2023-09-13 14:17:58][INFO] global_step=140552, episodic_env_return=64.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140576, episodic_reward_predictor_return=0.8224622011184692\n",
      "[2023-09-13 14:17:59][INFO] global_step=140576, episodic_env_return=74.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140592, episodic_reward_predictor_return=0.4029320180416107\n",
      "[2023-09-13 14:17:59][INFO] global_step=140592, episodic_env_return=86.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140608, episodic_reward_predictor_return=0.19563499093055725\n",
      "[2023-09-13 14:17:59][INFO] global_step=140608, episodic_env_return=92.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140688, episodic_reward_predictor_return=0.6874318718910217\n",
      "[2023-09-13 14:17:59][INFO] global_step=140688, episodic_env_return=87.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140720, episodic_reward_predictor_return=1.698284387588501\n",
      "[2023-09-13 14:17:59][INFO] global_step=140720, episodic_env_return=40.0\n",
      "[2023-09-13 14:17:59][INFO] global_step=140776, episodic_reward_predictor_return=0.3769872188568115\n",
      "[2023-09-13 14:17:59][INFO] global_step=140776, episodic_env_return=80.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140808, episodic_reward_predictor_return=1.1509515047073364\n",
      "[2023-09-13 14:18:00][INFO] global_step=140808, episodic_env_return=57.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140848, episodic_reward_predictor_return=0.6217692494392395\n",
      "[2023-09-13 14:18:00][INFO] global_step=140848, episodic_env_return=69.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140848, episodic_reward_predictor_return=0.9070939421653748\n",
      "[2023-09-13 14:18:00][INFO] global_step=140848, episodic_env_return=60.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140944, episodic_reward_predictor_return=0.02077438309788704\n",
      "[2023-09-13 14:18:00][INFO] global_step=140944, episodic_env_return=73.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140960, episodic_reward_predictor_return=0.4782891571521759\n",
      "[2023-09-13 14:18:00][INFO] global_step=140960, episodic_env_return=78.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=140968, episodic_reward_predictor_return=0.7093254923820496\n",
      "[2023-09-13 14:18:00][INFO] global_step=140968, episodic_env_return=2.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=141008, episodic_reward_predictor_return=0.29871314764022827\n",
      "[2023-09-13 14:18:00][INFO] global_step=141008, episodic_env_return=76.0\n",
      "[2023-09-13 14:18:00][INFO] global_step=141016, episodic_reward_predictor_return=0.7372301816940308\n",
      "[2023-09-13 14:18:00][INFO] global_step=141016, episodic_env_return=60.0\n",
      "[2023-09-13 14:18:01][INFO] global_step=141144, episodic_reward_predictor_return=0.15857093036174774\n",
      "[2023-09-13 14:18:01][INFO] global_step=141144, episodic_env_return=64.0\n",
      "[2023-09-13 14:18:01][INFO] global_step=141152, episodic_reward_predictor_return=0.22647172212600708\n",
      "[2023-09-13 14:18:01][INFO] global_step=141152, episodic_env_return=78.0\n",
      "[2023-09-13 14:18:01][INFO] global_step=141160, episodic_reward_predictor_return=0.9457912445068359\n",
      "[2023-09-13 14:18:01][INFO] global_step=141160, episodic_env_return=62.0\n",
      "[2023-09-13 14:18:01][INFO] global_step=141192, episodic_reward_predictor_return=0.5386332869529724\n",
      "[2023-09-13 14:18:01][INFO] global_step=141192, episodic_env_return=72.0\n",
      "[2023-09-13 14:18:01][INFO] global_step=141232, episodic_reward_predictor_return=0.32452529668807983\n",
      "[2023-09-13 14:18:01][INFO] global_step=141232, episodic_env_return=65.0\n",
      "[2023-09-13 14:18:02][INFO] Current Mean Episodic Return = 0.4748481810092926\n",
      "[2023-09-13 14:18:02][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_141312`...\n",
      "[2023-09-13 14:18:02][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_141312`!\n",
      "[2023-09-13 14:18:04][INFO] SPS: 21\n",
      "[2023-09-13 14:18:05][INFO] global_step=141344, episodic_reward_predictor_return=0.8655019998550415\n",
      "[2023-09-13 14:18:05][INFO] global_step=141344, episodic_env_return=59.0\n",
      "[2023-09-13 14:18:05][INFO] global_step=141352, episodic_reward_predictor_return=0.20526492595672607\n",
      "[2023-09-13 14:18:05][INFO] global_step=141352, episodic_env_return=76.0\n",
      "[2023-09-13 14:18:08][INFO] global_step=141520, episodic_reward_predictor_return=0.08941978216171265\n",
      "[2023-09-13 14:18:08][INFO] global_step=141520, episodic_env_return=28.0\n",
      "[2023-09-13 14:18:08][INFO] global_step=141528, episodic_reward_predictor_return=0.06694826483726501\n",
      "[2023-09-13 14:18:08][INFO] global_step=141528, episodic_env_return=78.0\n",
      "[2023-09-13 14:18:08][INFO] global_step=141528, episodic_reward_predictor_return=0.08375422656536102\n",
      "[2023-09-13 14:18:08][INFO] global_step=141528, episodic_env_return=48.0\n",
      "[2023-09-13 14:18:08][INFO] global_step=141552, episodic_reward_predictor_return=-0.29577019810676575\n",
      "[2023-09-13 14:18:08][INFO] global_step=141552, episodic_env_return=56.0\n",
      "[2023-09-13 14:18:10][INFO] global_step=141648, episodic_reward_predictor_return=0.29942235350608826\n",
      "[2023-09-13 14:18:10][INFO] global_step=141648, episodic_env_return=85.0\n",
      "[2023-09-13 14:18:10][INFO] global_step=141648, episodic_reward_predictor_return=-0.12333254516124725\n",
      "[2023-09-13 14:18:10][INFO] global_step=141648, episodic_env_return=30.0\n",
      "[2023-09-13 14:18:10][INFO] global_step=141672, episodic_reward_predictor_return=0.3870570957660675\n",
      "[2023-09-13 14:18:10][INFO] global_step=141672, episodic_env_return=83.0\n",
      "[2023-09-13 14:18:12][INFO] global_step=141784, episodic_reward_predictor_return=0.8033332824707031\n",
      "[2023-09-13 14:18:12][INFO] global_step=141784, episodic_env_return=47.0\n",
      "[2023-09-13 14:18:13][INFO] global_step=141824, episodic_reward_predictor_return=0.2577683925628662\n",
      "[2023-09-13 14:18:13][INFO] global_step=141824, episodic_env_return=67.0\n",
      "[2023-09-13 14:18:13][INFO] global_step=141848, episodic_reward_predictor_return=0.19163839519023895\n",
      "[2023-09-13 14:18:13][INFO] global_step=141848, episodic_env_return=56.0\n",
      "[2023-09-13 14:18:15][INFO] global_step=141936, episodic_reward_predictor_return=0.5537958145141602\n",
      "[2023-09-13 14:18:15][INFO] global_step=141936, episodic_env_return=65.0\n",
      "[2023-09-13 14:18:15][INFO] global_step=141976, episodic_reward_predictor_return=0.20832397043704987\n",
      "[2023-09-13 14:18:15][INFO] global_step=141976, episodic_env_return=77.0\n",
      "[2023-09-13 14:18:16][INFO] global_step=142000, episodic_reward_predictor_return=-0.09814884513616562\n",
      "[2023-09-13 14:18:16][INFO] global_step=142000, episodic_env_return=47.0\n",
      "[2023-09-13 14:18:18][INFO] global_step=142152, episodic_reward_predictor_return=0.2922742962837219\n",
      "[2023-09-13 14:18:18][INFO] global_step=142152, episodic_env_return=36.0\n",
      "[2023-09-13 14:18:19][INFO] global_step=142176, episodic_reward_predictor_return=0.36103522777557373\n",
      "[2023-09-13 14:18:19][INFO] global_step=142176, episodic_env_return=76.0\n",
      "[2023-09-13 14:18:19][INFO] global_step=142224, episodic_reward_predictor_return=0.6185219287872314\n",
      "[2023-09-13 14:18:19][INFO] global_step=142224, episodic_env_return=65.0\n",
      "[2023-09-13 14:18:20][INFO] global_step=142240, episodic_reward_predictor_return=0.4111630916595459\n",
      "[2023-09-13 14:18:20][INFO] global_step=142240, episodic_env_return=47.0\n",
      "[2023-09-13 14:18:20][INFO] global_step=142272, episodic_reward_predictor_return=1.0504902601242065\n",
      "[2023-09-13 14:18:20][INFO] global_step=142272, episodic_env_return=45.0\n",
      "[2023-09-13 14:18:22][INFO] global_step=142360, episodic_reward_predictor_return=0.220076322555542\n",
      "[2023-09-13 14:18:22][INFO] global_step=142360, episodic_env_return=75.0\n",
      "[2023-09-13 14:18:22][INFO] global_step=142384, episodic_reward_predictor_return=0.8631992340087891\n",
      "[2023-09-13 14:18:22][INFO] global_step=142384, episodic_env_return=53.0\n",
      "[2023-09-13 14:18:23][INFO] global_step=142456, episodic_reward_predictor_return=0.5086718797683716\n",
      "[2023-09-13 14:18:23][INFO] global_step=142456, episodic_env_return=72.0\n",
      "[2023-09-13 14:18:23][INFO] global_step=142464, episodic_reward_predictor_return=-0.1991114616394043\n",
      "[2023-09-13 14:18:23][INFO] global_step=142464, episodic_env_return=77.0\n",
      "[2023-09-13 14:18:26][INFO] global_step=142608, episodic_reward_predictor_return=0.1762683391571045\n",
      "[2023-09-13 14:18:26][INFO] global_step=142608, episodic_env_return=55.0\n",
      "[2023-09-13 14:18:26][INFO] global_step=142632, episodic_reward_predictor_return=1.3058491945266724\n",
      "[2023-09-13 14:18:26][INFO] global_step=142632, episodic_env_return=-94.0\n",
      "[2023-09-13 14:18:28][INFO] global_step=142744, episodic_reward_predictor_return=1.077030897140503\n",
      "[2023-09-13 14:18:28][INFO] global_step=142744, episodic_env_return=56.0\n",
      "[2023-09-13 14:18:28][INFO] global_step=142776, episodic_reward_predictor_return=-0.370318204164505\n",
      "[2023-09-13 14:18:28][INFO] global_step=142776, episodic_env_return=62.0\n",
      "[2023-09-13 14:18:30][INFO] global_step=142848, episodic_reward_predictor_return=0.5642674565315247\n",
      "[2023-09-13 14:18:30][INFO] global_step=142848, episodic_env_return=52.0\n",
      "[2023-09-13 14:18:30][INFO] global_step=142880, episodic_reward_predictor_return=0.4275716245174408\n",
      "[2023-09-13 14:18:30][INFO] global_step=142880, episodic_env_return=31.0\n",
      "[2023-09-13 14:18:32][INFO] global_step=142952, episodic_reward_predictor_return=0.7340160012245178\n",
      "[2023-09-13 14:18:32][INFO] global_step=142952, episodic_env_return=61.0\n",
      "[2023-09-13 14:18:32][INFO] global_step=142952, episodic_reward_predictor_return=-4.677479267120361\n",
      "[2023-09-13 14:18:32][INFO] global_step=142952, episodic_env_return=-365.0\n",
      "[2023-09-13 14:18:32][INFO] global_step=142968, episodic_reward_predictor_return=0.712982177734375\n",
      "[2023-09-13 14:18:32][INFO] global_step=142968, episodic_env_return=77.0\n",
      "[2023-09-13 14:18:32][INFO] global_step=142976, episodic_reward_predictor_return=0.36813101172447205\n",
      "[2023-09-13 14:18:32][INFO] global_step=142976, episodic_env_return=55.0\n",
      "[2023-09-13 14:18:34][INFO] global_step=143072, episodic_reward_predictor_return=0.7761675715446472\n",
      "[2023-09-13 14:18:34][INFO] global_step=143072, episodic_env_return=73.0\n",
      "[2023-09-13 14:18:35][INFO] global_step=143136, episodic_reward_predictor_return=0.4726627767086029\n",
      "[2023-09-13 14:18:35][INFO] global_step=143136, episodic_env_return=-29.0\n",
      "[2023-09-13 14:18:36][INFO] global_step=143224, episodic_reward_predictor_return=0.7383637428283691\n",
      "[2023-09-13 14:18:36][INFO] global_step=143224, episodic_env_return=67.0\n",
      "[2023-09-13 14:18:36][INFO] global_step=143232, episodic_reward_predictor_return=1.5115280151367188\n",
      "[2023-09-13 14:18:36][INFO] global_step=143232, episodic_env_return=57.0\n",
      "[2023-09-13 14:18:37][INFO] global_step=143240, episodic_reward_predictor_return=1.822654128074646\n",
      "[2023-09-13 14:18:37][INFO] global_step=143240, episodic_env_return=39.0\n",
      "[2023-09-13 14:18:38][INFO] global_step=143304, episodic_reward_predictor_return=0.5453903675079346\n",
      "[2023-09-13 14:18:38][INFO] global_step=143304, episodic_env_return=59.0\n",
      "[2023-09-13 14:18:38][INFO] global_step=143336, episodic_reward_predictor_return=0.02642173320055008\n",
      "[2023-09-13 14:18:38][INFO] global_step=143336, episodic_env_return=68.0\n",
      "[2023-09-13 14:18:38][INFO] global_step=143352, episodic_reward_predictor_return=0.36330583691596985\n",
      "[2023-09-13 14:18:38][INFO] global_step=143352, episodic_env_return=85.0\n",
      "[2023-09-13 14:18:38][INFO] Current Mean Episodic Return = 0.33800262212753296\n",
      "[2023-09-13 14:18:38][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_143360`...\n",
      "[2023-09-13 14:18:39][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_143360`!\n",
      "[2023-09-13 14:18:41][INFO] SPS: 22\n",
      "[2023-09-13 14:21:05][INFO] user_preference = 0\n",
      "[2023-09-13 14:21:05][INFO] reward_predictor_training_loss=3.6058075428009033\n",
      "[2023-09-13 14:22:17][INFO] user_preference = 0.5\n",
      "[2023-09-13 14:22:17][INFO] reward_predictor_training_loss=1.292993187904358\n",
      "[2023-09-13 14:22:44][INFO] user_preference = 0\n",
      "[2023-09-13 14:22:44][INFO] reward_predictor_training_loss=0.9946796894073486\n",
      "[2023-09-13 14:22:55][INFO] user_preference = 1\n",
      "[2023-09-13 14:22:55][INFO] reward_predictor_training_loss=0.0038702182937413454\n",
      "[2023-09-13 14:24:02][INFO] user_preference = 0.5\n",
      "[2023-09-13 14:24:02][INFO] reward_predictor_training_loss=0.6973996162414551\n",
      "[2023-09-13 14:24:25][INFO] user_preference = 1\n",
      "[2023-09-13 14:24:25][INFO] reward_predictor_training_loss=0.29283466935157776\n",
      "[2023-09-13 14:24:38][INFO] user_preference = 1\n",
      "[2023-09-13 14:24:38][INFO] reward_predictor_training_loss=0.34400099515914917\n",
      "[2023-09-13 14:24:54][INFO] user_preference = 0\n",
      "[2023-09-13 14:24:54][INFO] reward_predictor_training_loss=0.19490936398506165\n",
      "[2023-09-13 14:25:35][INFO] user_preference = 0\n",
      "[2023-09-13 14:25:35][INFO] reward_predictor_training_loss=0.013192327693104744\n",
      "[2023-09-13 14:25:56][INFO] user_preference = 0\n",
      "[2023-09-13 14:25:56][INFO] reward_predictor_training_loss=0.18994824588298798\n",
      "[2023-09-13 14:26:53][INFO] user_preference = 0\n",
      "[2023-09-13 14:26:53][INFO] reward_predictor_training_loss=0.9705041646957397\n",
      "[2023-09-13 14:27:08][INFO] user_preference = 0\n",
      "[2023-09-13 14:27:08][INFO] reward_predictor_training_loss=0.6988922953605652\n",
      "[2023-09-13 14:27:27][INFO] user_preference = 0\n",
      "[2023-09-13 14:27:27][INFO] reward_predictor_training_loss=0.4475090205669403\n",
      "[2023-09-13 14:28:08][INFO] user_preference = 0.5\n",
      "[2023-09-13 14:28:08][INFO] reward_predictor_training_loss=0.7535640001296997\n",
      "[2023-09-13 14:28:37][INFO] user_preference = 0.5\n",
      "[2023-09-13 14:28:37][INFO] reward_predictor_training_loss=0.7422418594360352\n",
      "[2023-09-13 14:28:46][INFO] user_preference = 0\n",
      "[2023-09-13 14:28:46][INFO] reward_predictor_training_loss=0.41180017590522766\n",
      "[2023-09-13 14:28:47][INFO] global_step=143424, episodic_reward_predictor_return=1.3948993682861328\n",
      "[2023-09-13 14:28:47][INFO] global_step=143424, episodic_env_return=45.0\n",
      "[2023-09-13 14:28:48][INFO] global_step=143488, episodic_reward_predictor_return=0.39475634694099426\n",
      "[2023-09-13 14:28:48][INFO] global_step=143488, episodic_env_return=84.0\n",
      "[2023-09-13 14:28:48][INFO] global_step=143488, episodic_reward_predictor_return=1.0803440809249878\n",
      "[2023-09-13 14:28:48][INFO] global_step=143488, episodic_env_return=34.0\n",
      "[2023-09-13 14:28:49][INFO] global_step=143512, episodic_reward_predictor_return=0.5809438228607178\n",
      "[2023-09-13 14:28:49][INFO] global_step=143512, episodic_env_return=67.0\n",
      "[2023-09-13 14:28:49][INFO] global_step=143536, episodic_reward_predictor_return=0.28133440017700195\n",
      "[2023-09-13 14:28:49][INFO] global_step=143536, episodic_env_return=87.0\n",
      "[2023-09-13 14:28:49][INFO] global_step=143544, episodic_reward_predictor_return=0.7089636921882629\n",
      "[2023-09-13 14:28:49][INFO] global_step=143544, episodic_env_return=62.0\n",
      "[2023-09-13 14:28:50][INFO] global_step=143608, episodic_reward_predictor_return=1.09915292263031\n",
      "[2023-09-13 14:28:50][INFO] global_step=143608, episodic_env_return=63.0\n",
      "[2023-09-13 14:28:51][INFO] global_step=143672, episodic_reward_predictor_return=0.2433609515428543\n",
      "[2023-09-13 14:28:51][INFO] global_step=143672, episodic_env_return=85.0\n",
      "[2023-09-13 14:28:51][INFO] global_step=143680, episodic_reward_predictor_return=0.5311959981918335\n",
      "[2023-09-13 14:28:51][INFO] global_step=143680, episodic_env_return=58.0\n",
      "[2023-09-13 14:28:52][INFO] global_step=143712, episodic_reward_predictor_return=0.2976681888103485\n",
      "[2023-09-13 14:28:52][INFO] global_step=143712, episodic_env_return=73.0\n",
      "[2023-09-13 14:28:52][INFO] global_step=143736, episodic_reward_predictor_return=0.46345439553260803\n",
      "[2023-09-13 14:28:52][INFO] global_step=143736, episodic_env_return=73.0\n",
      "[2023-09-13 14:28:53][INFO] global_step=143800, episodic_reward_predictor_return=0.19410468637943268\n",
      "[2023-09-13 14:28:53][INFO] global_step=143800, episodic_env_return=62.0\n",
      "[2023-09-13 14:28:55][INFO] global_step=143920, episodic_reward_predictor_return=0.5945752859115601\n",
      "[2023-09-13 14:28:55][INFO] global_step=143920, episodic_env_return=53.0\n",
      "[2023-09-13 14:28:56][INFO] global_step=143944, episodic_reward_predictor_return=0.6513404846191406\n",
      "[2023-09-13 14:28:56][INFO] global_step=143944, episodic_env_return=67.0\n",
      "[2023-09-13 14:28:56][INFO] global_step=143952, episodic_reward_predictor_return=0.6986565589904785\n",
      "[2023-09-13 14:28:56][INFO] global_step=143952, episodic_env_return=58.0\n",
      "[2023-09-13 14:28:58][INFO] global_step=144104, episodic_reward_predictor_return=-0.2333691269159317\n",
      "[2023-09-13 14:28:58][INFO] global_step=144104, episodic_env_return=47.0\n",
      "[2023-09-13 14:28:59][INFO] global_step=144112, episodic_reward_predictor_return=0.6300448179244995\n",
      "[2023-09-13 14:28:59][INFO] global_step=144112, episodic_env_return=54.0\n",
      "[2023-09-13 14:28:59][INFO] global_step=144144, episodic_reward_predictor_return=0.6370444297790527\n",
      "[2023-09-13 14:28:59][INFO] global_step=144144, episodic_env_return=43.0\n",
      "[2023-09-13 14:29:01][INFO] global_step=144264, episodic_reward_predictor_return=0.2382250726222992\n",
      "[2023-09-13 14:29:01][INFO] global_step=144264, episodic_env_return=53.0\n",
      "[2023-09-13 14:29:01][INFO] global_step=144296, episodic_reward_predictor_return=0.6452475190162659\n",
      "[2023-09-13 14:29:01][INFO] global_step=144296, episodic_env_return=82.0\n",
      "[2023-09-13 14:29:02][INFO] global_step=144304, episodic_reward_predictor_return=0.9225215911865234\n",
      "[2023-09-13 14:29:02][INFO] global_step=144304, episodic_env_return=56.0\n",
      "[2023-09-13 14:29:02][INFO] global_step=144328, episodic_reward_predictor_return=-0.7237972021102905\n",
      "[2023-09-13 14:29:02][INFO] global_step=144328, episodic_env_return=-73.0\n",
      "[2023-09-13 14:29:02][INFO] global_step=144336, episodic_reward_predictor_return=0.34407755732536316\n",
      "[2023-09-13 14:29:02][INFO] global_step=144336, episodic_env_return=73.0\n",
      "[2023-09-13 14:29:03][INFO] global_step=144360, episodic_reward_predictor_return=0.6310802102088928\n",
      "[2023-09-13 14:29:03][INFO] global_step=144360, episodic_env_return=50.0\n",
      "[2023-09-13 14:29:05][INFO] global_step=144504, episodic_reward_predictor_return=0.4761933982372284\n",
      "[2023-09-13 14:29:05][INFO] global_step=144504, episodic_env_return=76.0\n",
      "[2023-09-13 14:29:06][INFO] global_step=144576, episodic_reward_predictor_return=0.5189152359962463\n",
      "[2023-09-13 14:29:06][INFO] global_step=144576, episodic_env_return=71.0\n",
      "[2023-09-13 14:29:08][INFO] global_step=144688, episodic_reward_predictor_return=0.3991231918334961\n",
      "[2023-09-13 14:29:08][INFO] global_step=144688, episodic_env_return=52.0\n",
      "[2023-09-13 14:29:09][INFO] global_step=144744, episodic_reward_predictor_return=0.1630876660346985\n",
      "[2023-09-13 14:29:09][INFO] global_step=144744, episodic_env_return=31.0\n",
      "[2023-09-13 14:29:09][INFO] global_step=144760, episodic_reward_predictor_return=0.9850151538848877\n",
      "[2023-09-13 14:29:09][INFO] global_step=144760, episodic_env_return=47.0\n",
      "[2023-09-13 14:29:10][INFO] global_step=144824, episodic_reward_predictor_return=-0.08272772282361984\n",
      "[2023-09-13 14:29:10][INFO] global_step=144824, episodic_env_return=65.0\n",
      "[2023-09-13 14:29:11][INFO] global_step=144872, episodic_reward_predictor_return=0.054906729608774185\n",
      "[2023-09-13 14:29:11][INFO] global_step=144872, episodic_env_return=27.0\n",
      "[2023-09-13 14:29:12][INFO] global_step=144952, episodic_reward_predictor_return=0.27694347500801086\n",
      "[2023-09-13 14:29:12][INFO] global_step=144952, episodic_env_return=85.0\n",
      "[2023-09-13 14:29:12][INFO] global_step=144960, episodic_reward_predictor_return=-0.15764759480953217\n",
      "[2023-09-13 14:29:12][INFO] global_step=144960, episodic_env_return=74.0\n",
      "[2023-09-13 14:29:13][INFO] global_step=144968, episodic_reward_predictor_return=0.9664592146873474\n",
      "[2023-09-13 14:29:13][INFO] global_step=144968, episodic_env_return=-22.0\n",
      "[2023-09-13 14:29:13][INFO] global_step=145016, episodic_reward_predictor_return=0.8853066563606262\n",
      "[2023-09-13 14:29:13][INFO] global_step=145016, episodic_env_return=60.0\n",
      "[2023-09-13 14:29:14][INFO] global_step=145072, episodic_reward_predictor_return=0.5261818170547485\n",
      "[2023-09-13 14:29:14][INFO] global_step=145072, episodic_env_return=25.0\n",
      "[2023-09-13 14:29:15][INFO] global_step=145096, episodic_reward_predictor_return=-0.18571951985359192\n",
      "[2023-09-13 14:29:15][INFO] global_step=145096, episodic_env_return=54.0\n",
      "[2023-09-13 14:29:17][INFO] global_step=145240, episodic_reward_predictor_return=0.47392043471336365\n",
      "[2023-09-13 14:29:17][INFO] global_step=145240, episodic_env_return=65.0\n",
      "[2023-09-13 14:29:18][INFO] global_step=145312, episodic_reward_predictor_return=1.087733507156372\n",
      "[2023-09-13 14:29:18][INFO] global_step=145312, episodic_env_return=58.0\n",
      "[2023-09-13 14:29:19][INFO] global_step=145344, episodic_reward_predictor_return=0.56477952003479\n",
      "[2023-09-13 14:29:19][INFO] global_step=145344, episodic_env_return=53.0\n",
      "[2023-09-13 14:29:20][INFO] global_step=145392, episodic_reward_predictor_return=0.8016289472579956\n",
      "[2023-09-13 14:29:20][INFO] global_step=145392, episodic_env_return=-113.0\n",
      "[2023-09-13 14:29:20][INFO] global_step=145408, episodic_reward_predictor_return=0.2819027006626129\n",
      "[2023-09-13 14:29:20][INFO] global_step=145408, episodic_env_return=59.0\n",
      "[2023-09-13 14:29:20][INFO] Current Mean Episodic Return = 0.4843292236328125\n",
      "[2023-09-13 14:29:20][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_145408`...\n",
      "[2023-09-13 14:29:20][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_145408`!\n",
      "[2023-09-13 14:29:23][INFO] SPS: 20\n",
      "[2023-09-13 14:29:23][INFO] global_step=145424, episodic_reward_predictor_return=0.24140940606594086\n",
      "[2023-09-13 14:29:23][INFO] global_step=145424, episodic_env_return=50.0\n",
      "[2023-09-13 14:29:24][INFO] global_step=145488, episodic_reward_predictor_return=1.1127636432647705\n",
      "[2023-09-13 14:29:24][INFO] global_step=145488, episodic_env_return=52.0\n",
      "[2023-09-13 14:29:25][INFO] global_step=145520, episodic_reward_predictor_return=0.4830078184604645\n",
      "[2023-09-13 14:29:25][INFO] global_step=145520, episodic_env_return=79.0\n",
      "[2023-09-13 14:29:27][INFO] global_step=145672, episodic_reward_predictor_return=0.7380674481391907\n",
      "[2023-09-13 14:29:27][INFO] global_step=145672, episodic_env_return=56.0\n",
      "[2023-09-13 14:29:28][INFO] global_step=145744, episodic_reward_predictor_return=0.8565696477890015\n",
      "[2023-09-13 14:29:28][INFO] global_step=145744, episodic_env_return=38.0\n",
      "[2023-09-13 14:29:29][INFO] global_step=145768, episodic_reward_predictor_return=1.1067670583724976\n",
      "[2023-09-13 14:29:29][INFO] global_step=145768, episodic_env_return=-21.0\n",
      "[2023-09-13 14:29:30][INFO] global_step=145824, episodic_reward_predictor_return=0.8245528340339661\n",
      "[2023-09-13 14:29:30][INFO] global_step=145824, episodic_env_return=49.0\n",
      "[2023-09-13 14:29:30][INFO] global_step=145832, episodic_reward_predictor_return=1.2065351009368896\n",
      "[2023-09-13 14:29:30][INFO] global_step=145832, episodic_env_return=46.0\n",
      "[2023-09-13 14:29:30][INFO] global_step=145832, episodic_reward_predictor_return=0.22389428317546844\n",
      "[2023-09-13 14:29:30][INFO] global_step=145832, episodic_env_return=81.0\n",
      "[2023-09-13 14:29:31][INFO] global_step=145896, episodic_reward_predictor_return=0.8938177227973938\n",
      "[2023-09-13 14:29:31][INFO] global_step=145896, episodic_env_return=50.0\n",
      "[2023-09-13 14:29:32][INFO] global_step=145944, episodic_reward_predictor_return=0.357829213142395\n",
      "[2023-09-13 14:29:32][INFO] global_step=145944, episodic_env_return=79.0\n",
      "[2023-09-13 14:29:32][INFO] global_step=145952, episodic_reward_predictor_return=0.6076003909111023\n",
      "[2023-09-13 14:29:32][INFO] global_step=145952, episodic_env_return=47.0\n",
      "[2023-09-13 14:29:32][INFO] global_step=145968, episodic_reward_predictor_return=0.6925492286682129\n",
      "[2023-09-13 14:29:32][INFO] global_step=145968, episodic_env_return=28.0\n",
      "[2023-09-13 14:29:34][INFO] global_step=146112, episodic_reward_predictor_return=0.3882848620414734\n",
      "[2023-09-13 14:29:34][INFO] global_step=146112, episodic_env_return=65.0\n",
      "[2023-09-13 14:29:34][INFO] global_step=146120, episodic_reward_predictor_return=0.31600743532180786\n",
      "[2023-09-13 14:29:34][INFO] global_step=146120, episodic_env_return=79.0\n",
      "[2023-09-13 14:29:36][INFO] global_step=146216, episodic_reward_predictor_return=1.1151903867721558\n",
      "[2023-09-13 14:29:36][INFO] global_step=146216, episodic_env_return=53.0\n",
      "[2023-09-13 14:29:37][INFO] global_step=146296, episodic_reward_predictor_return=1.0290372371673584\n",
      "[2023-09-13 14:29:37][INFO] global_step=146296, episodic_env_return=43.0\n",
      "[2023-09-13 14:29:37][INFO] global_step=146304, episodic_reward_predictor_return=0.407817542552948\n",
      "[2023-09-13 14:29:37][INFO] global_step=146304, episodic_env_return=59.0\n",
      "[2023-09-13 14:29:38][INFO] global_step=146352, episodic_reward_predictor_return=1.3500568866729736\n",
      "[2023-09-13 14:29:38][INFO] global_step=146352, episodic_env_return=51.0\n",
      "[2023-09-13 14:29:38][INFO] global_step=146360, episodic_reward_predictor_return=0.7583674192428589\n",
      "[2023-09-13 14:29:38][INFO] global_step=146360, episodic_env_return=19.0\n",
      "[2023-09-13 14:29:39][INFO] global_step=146368, episodic_reward_predictor_return=1.2709940671920776\n",
      "[2023-09-13 14:29:39][INFO] global_step=146368, episodic_env_return=42.0\n",
      "[2023-09-13 14:29:40][INFO] global_step=146464, episodic_reward_predictor_return=0.714477002620697\n",
      "[2023-09-13 14:29:40][INFO] global_step=146464, episodic_env_return=58.0\n",
      "[2023-09-13 14:29:41][INFO] global_step=146496, episodic_reward_predictor_return=0.34565281867980957\n",
      "[2023-09-13 14:29:41][INFO] global_step=146496, episodic_env_return=84.0\n",
      "[2023-09-13 14:29:41][INFO] global_step=146504, episodic_reward_predictor_return=0.1294311136007309\n",
      "[2023-09-13 14:29:41][INFO] global_step=146504, episodic_env_return=76.0\n",
      "[2023-09-13 14:29:42][INFO] global_step=146576, episodic_reward_predictor_return=0.2945832908153534\n",
      "[2023-09-13 14:29:42][INFO] global_step=146576, episodic_env_return=56.0\n",
      "[2023-09-13 14:29:44][INFO] global_step=146696, episodic_reward_predictor_return=0.4939897060394287\n",
      "[2023-09-13 14:29:44][INFO] global_step=146696, episodic_env_return=60.0\n",
      "[2023-09-13 14:29:45][INFO] global_step=146768, episodic_reward_predictor_return=1.2663142681121826\n",
      "[2023-09-13 14:29:45][INFO] global_step=146768, episodic_env_return=49.0\n",
      "[2023-09-13 14:29:46][INFO] global_step=146808, episodic_reward_predictor_return=0.5466274619102478\n",
      "[2023-09-13 14:29:46][INFO] global_step=146808, episodic_env_return=62.0\n",
      "[2023-09-13 14:29:46][INFO] global_step=146856, episodic_reward_predictor_return=0.8673032522201538\n",
      "[2023-09-13 14:29:46][INFO] global_step=146856, episodic_env_return=52.0\n",
      "[2023-09-13 14:29:47][INFO] global_step=146904, episodic_reward_predictor_return=0.8118565082550049\n",
      "[2023-09-13 14:29:47][INFO] global_step=146904, episodic_env_return=60.0\n",
      "[2023-09-13 14:29:48][INFO] global_step=146920, episodic_reward_predictor_return=0.29534420371055603\n",
      "[2023-09-13 14:29:48][INFO] global_step=146920, episodic_env_return=82.0\n",
      "[2023-09-13 14:29:49][INFO] global_step=146968, episodic_reward_predictor_return=0.5090264081954956\n",
      "[2023-09-13 14:29:49][INFO] global_step=146968, episodic_env_return=38.0\n",
      "[2023-09-13 14:29:49][INFO] global_step=147016, episodic_reward_predictor_return=0.16646870970726013\n",
      "[2023-09-13 14:29:49][INFO] global_step=147016, episodic_env_return=87.0\n",
      "[2023-09-13 14:29:52][INFO] global_step=147168, episodic_reward_predictor_return=0.2903563976287842\n",
      "[2023-09-13 14:29:52][INFO] global_step=147168, episodic_env_return=82.0\n",
      "[2023-09-13 14:29:52][INFO] global_step=147208, episodic_reward_predictor_return=0.29873788356781006\n",
      "[2023-09-13 14:29:52][INFO] global_step=147208, episodic_env_return=65.0\n",
      "[2023-09-13 14:29:53][INFO] global_step=147216, episodic_reward_predictor_return=0.47928932309150696\n",
      "[2023-09-13 14:29:53][INFO] global_step=147216, episodic_env_return=50.0\n",
      "[2023-09-13 14:29:55][INFO] global_step=147352, episodic_reward_predictor_return=0.14520809054374695\n",
      "[2023-09-13 14:29:55][INFO] global_step=147352, episodic_env_return=-41.0\n",
      "[2023-09-13 14:29:55][INFO] global_step=147400, episodic_reward_predictor_return=1.0710221529006958\n",
      "[2023-09-13 14:29:55][INFO] global_step=147400, episodic_env_return=33.0\n",
      "[2023-09-13 14:29:56][INFO] Current Mean Episodic Return = 0.6501792073249817\n",
      "[2023-09-13 14:29:56][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_147456`...\n",
      "[2023-09-13 14:29:56][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_147456`!\n",
      "[2023-09-13 14:29:59][INFO] SPS: 20\n",
      "[2023-09-13 14:30:00][INFO] global_step=147504, episodic_reward_predictor_return=-0.47856950759887695\n",
      "[2023-09-13 14:30:00][INFO] global_step=147504, episodic_env_return=-93.0\n",
      "[2023-09-13 14:30:00][INFO] global_step=147504, episodic_reward_predictor_return=-0.23265784978866577\n",
      "[2023-09-13 14:30:00][INFO] global_step=147504, episodic_env_return=29.0\n",
      "[2023-09-13 14:30:01][INFO] global_step=147600, episodic_reward_predictor_return=0.2531864047050476\n",
      "[2023-09-13 14:30:01][INFO] global_step=147600, episodic_env_return=89.0\n",
      "[2023-09-13 14:30:02][INFO] global_step=147616, episodic_reward_predictor_return=0.7833876013755798\n",
      "[2023-09-13 14:30:02][INFO] global_step=147616, episodic_env_return=50.0\n",
      "[2023-09-13 14:30:03][INFO] global_step=147696, episodic_reward_predictor_return=1.4865663051605225\n",
      "[2023-09-13 14:30:03][INFO] global_step=147696, episodic_env_return=41.0\n",
      "[2023-09-13 14:30:05][INFO] global_step=147832, episodic_reward_predictor_return=0.9490389823913574\n",
      "[2023-09-13 14:30:05][INFO] global_step=147832, episodic_env_return=47.0\n",
      "[2023-09-13 14:30:06][INFO] global_step=147912, episodic_reward_predictor_return=0.6896504759788513\n",
      "[2023-09-13 14:30:06][INFO] global_step=147912, episodic_env_return=26.0\n",
      "[2023-09-13 14:30:08][INFO] global_step=147992, episodic_reward_predictor_return=0.40339282155036926\n",
      "[2023-09-13 14:30:08][INFO] global_step=147992, episodic_env_return=81.0\n",
      "[2023-09-13 14:30:09][INFO] global_step=148064, episodic_reward_predictor_return=0.07040160894393921\n",
      "[2023-09-13 14:30:09][INFO] global_step=148064, episodic_env_return=43.0\n",
      "[2023-09-13 14:30:10][INFO] global_step=148104, episodic_reward_predictor_return=1.1781586408615112\n",
      "[2023-09-13 14:30:10][INFO] global_step=148104, episodic_env_return=40.0\n",
      "[2023-09-13 14:30:10][INFO] global_step=148112, episodic_reward_predictor_return=-0.21396438777446747\n",
      "[2023-09-13 14:30:10][INFO] global_step=148112, episodic_env_return=-27.0\n",
      "[2023-09-13 14:30:10][INFO] global_step=148136, episodic_reward_predictor_return=0.9139369130134583\n",
      "[2023-09-13 14:30:10][INFO] global_step=148136, episodic_env_return=46.0\n",
      "[2023-09-13 14:30:13][INFO] global_step=148280, episodic_reward_predictor_return=0.3313140571117401\n",
      "[2023-09-13 14:30:13][INFO] global_step=148280, episodic_env_return=55.0\n",
      "[2023-09-13 14:30:15][INFO] global_step=148432, episodic_reward_predictor_return=-0.40453916788101196\n",
      "[2023-09-13 14:30:15][INFO] global_step=148432, episodic_env_return=41.0\n",
      "[2023-09-13 14:30:16][INFO] global_step=148504, episodic_reward_predictor_return=1.0103204250335693\n",
      "[2023-09-13 14:30:16][INFO] global_step=148504, episodic_env_return=46.0\n",
      "[2023-09-13 14:30:17][INFO] global_step=148528, episodic_reward_predictor_return=-0.24808260798454285\n",
      "[2023-09-13 14:30:17][INFO] global_step=148528, episodic_env_return=-37.0\n",
      "[2023-09-13 14:30:18][INFO] global_step=148592, episodic_reward_predictor_return=0.6838626265525818\n",
      "[2023-09-13 14:30:18][INFO] global_step=148592, episodic_env_return=36.0\n",
      "[2023-09-13 14:30:19][INFO] global_step=148640, episodic_reward_predictor_return=0.18975211679935455\n",
      "[2023-09-13 14:30:19][INFO] global_step=148640, episodic_env_return=75.0\n",
      "[2023-09-13 14:30:19][INFO] global_step=148648, episodic_reward_predictor_return=0.7235742807388306\n",
      "[2023-09-13 14:30:19][INFO] global_step=148648, episodic_env_return=37.0\n",
      "[2023-09-13 14:30:19][INFO] global_step=148656, episodic_reward_predictor_return=0.7464704513549805\n",
      "[2023-09-13 14:30:19][INFO] global_step=148656, episodic_env_return=54.0\n",
      "[2023-09-13 14:30:19][INFO] global_step=148680, episodic_reward_predictor_return=-1.2736672163009644\n",
      "[2023-09-13 14:30:19][INFO] global_step=148680, episodic_env_return=-182.0\n",
      "[2023-09-13 14:30:21][INFO] global_step=148768, episodic_reward_predictor_return=-0.122709721326828\n",
      "[2023-09-13 14:30:21][INFO] global_step=148768, episodic_env_return=87.0\n",
      "[2023-09-13 14:30:21][INFO] global_step=148768, episodic_reward_predictor_return=0.39199891686439514\n",
      "[2023-09-13 14:30:21][INFO] global_step=148768, episodic_env_return=90.0\n",
      "[2023-09-13 14:30:23][INFO] global_step=148896, episodic_reward_predictor_return=1.0665340423583984\n",
      "[2023-09-13 14:30:23][INFO] global_step=148896, episodic_env_return=55.0\n",
      "[2023-09-13 14:30:23][INFO] global_step=148896, episodic_reward_predictor_return=0.11336663365364075\n",
      "[2023-09-13 14:30:23][INFO] global_step=148896, episodic_env_return=85.0\n",
      "[2023-09-13 14:30:24][INFO] global_step=148992, episodic_reward_predictor_return=1.1409647464752197\n",
      "[2023-09-13 14:30:24][INFO] global_step=148992, episodic_env_return=40.0\n",
      "[2023-09-13 14:30:24][INFO] global_step=149000, episodic_reward_predictor_return=1.2629833221435547\n",
      "[2023-09-13 14:30:24][INFO] global_step=149000, episodic_env_return=-11.0\n",
      "[2023-09-13 14:30:25][INFO] global_step=149016, episodic_reward_predictor_return=1.1406357288360596\n",
      "[2023-09-13 14:30:25][INFO] global_step=149016, episodic_env_return=54.0\n",
      "[2023-09-13 14:30:25][INFO] global_step=149048, episodic_reward_predictor_return=0.9357995390892029\n",
      "[2023-09-13 14:30:25][INFO] global_step=149048, episodic_env_return=44.0\n",
      "[2023-09-13 14:30:26][INFO] global_step=149096, episodic_reward_predictor_return=0.6418742537498474\n",
      "[2023-09-13 14:30:26][INFO] global_step=149096, episodic_env_return=45.0\n",
      "[2023-09-13 14:30:26][INFO] global_step=149104, episodic_reward_predictor_return=0.4053175747394562\n",
      "[2023-09-13 14:30:26][INFO] global_step=149104, episodic_env_return=59.0\n",
      "[2023-09-13 14:30:27][INFO] global_step=149168, episodic_reward_predictor_return=0.12300783395767212\n",
      "[2023-09-13 14:30:27][INFO] global_step=149168, episodic_env_return=80.0\n",
      "[2023-09-13 14:30:28][INFO] global_step=149224, episodic_reward_predictor_return=0.4361328184604645\n",
      "[2023-09-13 14:30:28][INFO] global_step=149224, episodic_env_return=60.0\n",
      "[2023-09-13 14:30:30][INFO] global_step=149344, episodic_reward_predictor_return=0.5938520431518555\n",
      "[2023-09-13 14:30:30][INFO] global_step=149344, episodic_env_return=40.0\n",
      "[2023-09-13 14:30:31][INFO] global_step=149400, episodic_reward_predictor_return=0.27854490280151367\n",
      "[2023-09-13 14:30:31][INFO] global_step=149400, episodic_env_return=72.0\n",
      "[2023-09-13 14:30:32][INFO] global_step=149424, episodic_reward_predictor_return=0.7629901170730591\n",
      "[2023-09-13 14:30:32][INFO] global_step=149424, episodic_env_return=54.0\n",
      "[2023-09-13 14:30:32][INFO] global_step=149440, episodic_reward_predictor_return=0.015453971922397614\n",
      "[2023-09-13 14:30:32][INFO] global_step=149440, episodic_env_return=58.0\n",
      "[2023-09-13 14:30:33][INFO] global_step=149488, episodic_reward_predictor_return=0.6016814708709717\n",
      "[2023-09-13 14:30:33][INFO] global_step=149488, episodic_env_return=53.0\n",
      "[2023-09-13 14:30:33][INFO] global_step=149488, episodic_reward_predictor_return=0.34184756875038147\n",
      "[2023-09-13 14:30:33][INFO] global_step=149488, episodic_env_return=42.0\n",
      "[2023-09-13 14:30:33][INFO] Current Mean Episodic Return = 0.453636109828949\n",
      "[2023-09-13 14:30:33][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_149504`...\n",
      "[2023-09-13 14:30:33][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_149504`!\n",
      "[2023-09-13 14:30:35][INFO] SPS: 20\n",
      "[2023-09-13 14:30:36][INFO] global_step=149536, episodic_reward_predictor_return=-0.21247266232967377\n",
      "[2023-09-13 14:30:36][INFO] global_step=149536, episodic_env_return=23.0\n",
      "[2023-09-13 14:30:37][INFO] global_step=149584, episodic_reward_predictor_return=0.7136966586112976\n",
      "[2023-09-13 14:30:37][INFO] global_step=149584, episodic_env_return=56.0\n",
      "[2023-09-13 14:30:39][INFO] global_step=149752, episodic_reward_predictor_return=0.10808855295181274\n",
      "[2023-09-13 14:30:39][INFO] global_step=149752, episodic_env_return=80.0\n",
      "[2023-09-13 14:30:39][INFO] global_step=149760, episodic_reward_predictor_return=0.9455853700637817\n",
      "[2023-09-13 14:30:39][INFO] global_step=149760, episodic_env_return=49.0\n",
      "[2023-09-13 14:30:41][INFO] global_step=149848, episodic_reward_predictor_return=0.0259030070155859\n",
      "[2023-09-13 14:30:41][INFO] global_step=149848, episodic_env_return=89.0\n",
      "[2023-09-13 14:30:41][INFO] global_step=149864, episodic_reward_predictor_return=0.635999858379364\n",
      "[2023-09-13 14:30:41][INFO] global_step=149864, episodic_env_return=43.0\n",
      "[2023-09-13 14:30:41][INFO] global_step=149864, episodic_reward_predictor_return=0.7675145864486694\n",
      "[2023-09-13 14:30:41][INFO] global_step=149864, episodic_env_return=54.0\n",
      "[2023-09-13 14:30:41][INFO] global_step=149872, episodic_reward_predictor_return=0.8358709216117859\n",
      "[2023-09-13 14:30:41][INFO] global_step=149872, episodic_env_return=59.0\n",
      "[2023-09-13 14:30:41][INFO] global_step=149872, episodic_reward_predictor_return=0.5788596272468567\n",
      "[2023-09-13 14:30:41][INFO] global_step=149872, episodic_env_return=47.0\n",
      "[2023-09-13 14:30:46][INFO] global_step=150152, episodic_reward_predictor_return=0.45111769437789917\n",
      "[2023-09-13 14:30:46][INFO] global_step=150152, episodic_env_return=66.0\n",
      "[2023-09-13 14:30:48][INFO] global_step=150320, episodic_reward_predictor_return=0.44534438848495483\n",
      "[2023-09-13 14:30:48][INFO] global_step=150320, episodic_env_return=44.0\n",
      "[2023-09-13 14:30:49][INFO] global_step=150360, episodic_reward_predictor_return=0.7787993550300598\n",
      "[2023-09-13 14:30:49][INFO] global_step=150360, episodic_env_return=21.0\n",
      "[2023-09-13 14:30:49][INFO] global_step=150368, episodic_reward_predictor_return=-0.28773534297943115\n",
      "[2023-09-13 14:30:49][INFO] global_step=150368, episodic_env_return=28.0\n",
      "[2023-09-13 14:30:50][INFO] global_step=150424, episodic_reward_predictor_return=1.5763550996780396\n",
      "[2023-09-13 14:30:50][INFO] global_step=150424, episodic_env_return=-24.0\n",
      "[2023-09-13 14:30:51][INFO] global_step=150456, episodic_reward_predictor_return=0.4783337712287903\n",
      "[2023-09-13 14:30:51][INFO] global_step=150456, episodic_env_return=25.0\n",
      "[2023-09-13 14:30:53][INFO] global_step=150624, episodic_reward_predictor_return=1.2899905443191528\n",
      "[2023-09-13 14:30:53][INFO] global_step=150624, episodic_env_return=-46.0\n",
      "[2023-09-13 14:30:54][INFO] global_step=150672, episodic_reward_predictor_return=0.541022002696991\n",
      "[2023-09-13 14:30:54][INFO] global_step=150672, episodic_env_return=63.0\n",
      "[2023-09-13 14:30:55][INFO] global_step=150736, episodic_reward_predictor_return=1.2212029695510864\n",
      "[2023-09-13 14:30:55][INFO] global_step=150736, episodic_env_return=-7.0\n",
      "[2023-09-13 14:30:55][INFO] global_step=150752, episodic_reward_predictor_return=0.29780587553977966\n",
      "[2023-09-13 14:30:55][INFO] global_step=150752, episodic_env_return=47.0\n",
      "[2023-09-13 14:30:56][INFO] global_step=150792, episodic_reward_predictor_return=0.6237480044364929\n",
      "[2023-09-13 14:30:56][INFO] global_step=150792, episodic_env_return=55.0\n",
      "[2023-09-13 14:30:56][INFO] global_step=150816, episodic_reward_predictor_return=0.9402599930763245\n",
      "[2023-09-13 14:30:56][INFO] global_step=150816, episodic_env_return=56.0\n",
      "[2023-09-13 14:30:57][INFO] global_step=150848, episodic_reward_predictor_return=1.0765258073806763\n",
      "[2023-09-13 14:30:57][INFO] global_step=150848, episodic_env_return=14.0\n",
      "[2023-09-13 14:30:59][INFO] global_step=150984, episodic_reward_predictor_return=0.5716044306755066\n",
      "[2023-09-13 14:30:59][INFO] global_step=150984, episodic_env_return=56.0\n",
      "[2023-09-13 14:31:01][INFO] global_step=151104, episodic_reward_predictor_return=0.6796479821205139\n",
      "[2023-09-13 14:31:01][INFO] global_step=151104, episodic_env_return=57.0\n",
      "[2023-09-13 14:31:01][INFO] global_step=151112, episodic_reward_predictor_return=0.6610067486763\n",
      "[2023-09-13 14:31:01][INFO] global_step=151112, episodic_env_return=61.0\n",
      "[2023-09-13 14:31:02][INFO] global_step=151192, episodic_reward_predictor_return=0.3088442087173462\n",
      "[2023-09-13 14:31:02][INFO] global_step=151192, episodic_env_return=58.0\n",
      "[2023-09-13 14:31:02][INFO] global_step=151200, episodic_reward_predictor_return=1.563732624053955\n",
      "[2023-09-13 14:31:02][INFO] global_step=151200, episodic_env_return=35.0\n",
      "[2023-09-13 14:31:04][INFO] global_step=151272, episodic_reward_predictor_return=0.32744184136390686\n",
      "[2023-09-13 14:31:04][INFO] global_step=151272, episodic_env_return=81.0\n",
      "[2023-09-13 14:31:05][INFO] global_step=151344, episodic_reward_predictor_return=-0.23289000988006592\n",
      "[2023-09-13 14:31:05][INFO] global_step=151344, episodic_env_return=25.0\n",
      "[2023-09-13 14:31:05][INFO] global_step=151344, episodic_reward_predictor_return=0.590823233127594\n",
      "[2023-09-13 14:31:05][INFO] global_step=151344, episodic_env_return=15.0\n",
      "[2023-09-13 14:31:05][INFO] global_step=151352, episodic_reward_predictor_return=0.7029373049736023\n",
      "[2023-09-13 14:31:05][INFO] global_step=151352, episodic_env_return=55.0\n",
      "[2023-09-13 14:31:07][INFO] global_step=151464, episodic_reward_predictor_return=0.17421495914459229\n",
      "[2023-09-13 14:31:07][INFO] global_step=151464, episodic_env_return=56.0\n",
      "[2023-09-13 14:31:07][INFO] global_step=151472, episodic_reward_predictor_return=1.2780975103378296\n",
      "[2023-09-13 14:31:07][INFO] global_step=151472, episodic_env_return=-43.0\n",
      "[2023-09-13 14:31:08][INFO] Current Mean Episodic Return = 0.6199174523353577\n",
      "[2023-09-13 14:31:08][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_151552`...\n",
      "[2023-09-13 14:31:08][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_151552`!\n",
      "[2023-09-13 14:31:11][INFO] SPS: 20\n",
      "[2023-09-13 14:31:11][INFO] global_step=151576, episodic_reward_predictor_return=0.4312276244163513\n",
      "[2023-09-13 14:31:11][INFO] global_step=151576, episodic_env_return=54.0\n",
      "[2023-09-13 14:31:11][INFO] global_step=151600, episodic_reward_predictor_return=0.7493203282356262\n",
      "[2023-09-13 14:31:11][INFO] global_step=151600, episodic_env_return=50.0\n",
      "[2023-09-13 14:31:14][INFO] global_step=151744, episodic_reward_predictor_return=0.9246844053268433\n",
      "[2023-09-13 14:31:14][INFO] global_step=151744, episodic_env_return=51.0\n",
      "[2023-09-13 14:31:15][INFO] global_step=151800, episodic_reward_predictor_return=0.5470804572105408\n",
      "[2023-09-13 14:31:15][INFO] global_step=151800, episodic_env_return=35.0\n",
      "[2023-09-13 14:31:16][INFO] global_step=151896, episodic_reward_predictor_return=0.9358169436454773\n",
      "[2023-09-13 14:31:16][INFO] global_step=151896, episodic_env_return=47.0\n",
      "[2023-09-13 14:31:17][INFO] global_step=151936, episodic_reward_predictor_return=0.43022480607032776\n",
      "[2023-09-13 14:31:17][INFO] global_step=151936, episodic_env_return=38.0\n",
      "[2023-09-13 14:31:17][INFO] global_step=151936, episodic_reward_predictor_return=0.3895265460014343\n",
      "[2023-09-13 14:31:17][INFO] global_step=151936, episodic_env_return=56.0\n",
      "[2023-09-13 14:31:19][INFO] global_step=152040, episodic_reward_predictor_return=0.8267159461975098\n",
      "[2023-09-13 14:31:19][INFO] global_step=152040, episodic_env_return=64.0\n",
      "[2023-09-13 14:31:19][INFO] global_step=152048, episodic_reward_predictor_return=0.5575830340385437\n",
      "[2023-09-13 14:31:19][INFO] global_step=152048, episodic_env_return=45.0\n",
      "[2023-09-13 14:31:22][INFO] global_step=152256, episodic_reward_predictor_return=0.4010298550128937\n",
      "[2023-09-13 14:31:22][INFO] global_step=152256, episodic_env_return=-22.0\n",
      "[2023-09-13 14:31:24][INFO] global_step=152360, episodic_reward_predictor_return=1.0076587200164795\n",
      "[2023-09-13 14:31:24][INFO] global_step=152360, episodic_env_return=48.0\n",
      "[2023-09-13 14:31:25][INFO] global_step=152448, episodic_reward_predictor_return=0.921115517616272\n",
      "[2023-09-13 14:31:25][INFO] global_step=152448, episodic_env_return=51.0\n",
      "[2023-09-13 14:31:25][INFO] global_step=152448, episodic_reward_predictor_return=0.36345526576042175\n",
      "[2023-09-13 14:31:25][INFO] global_step=152448, episodic_env_return=37.0\n",
      "[2023-09-13 14:31:28][INFO] global_step=152608, episodic_reward_predictor_return=0.7330574989318848\n",
      "[2023-09-13 14:31:28][INFO] global_step=152608, episodic_env_return=57.0\n",
      "[2023-09-13 14:31:28][INFO] global_step=152632, episodic_reward_predictor_return=0.8103400468826294\n",
      "[2023-09-13 14:31:28][INFO] global_step=152632, episodic_env_return=78.0\n",
      "[2023-09-13 14:31:29][INFO] global_step=152664, episodic_reward_predictor_return=-0.13836199045181274\n",
      "[2023-09-13 14:31:29][INFO] global_step=152664, episodic_env_return=63.0\n",
      "[2023-09-13 14:31:31][INFO] global_step=152840, episodic_reward_predictor_return=1.5812572240829468\n",
      "[2023-09-13 14:31:31][INFO] global_step=152840, episodic_env_return=1.0\n",
      "[2023-09-13 14:31:32][INFO] global_step=152904, episodic_reward_predictor_return=2.4447238445281982\n",
      "[2023-09-13 14:31:32][INFO] global_step=152904, episodic_env_return=-94.0\n",
      "[2023-09-13 14:31:34][INFO] global_step=152992, episodic_reward_predictor_return=0.8676900267601013\n",
      "[2023-09-13 14:31:34][INFO] global_step=152992, episodic_env_return=53.0\n",
      "[2023-09-13 14:31:35][INFO] global_step=153072, episodic_reward_predictor_return=0.7814088463783264\n",
      "[2023-09-13 14:31:35][INFO] global_step=153072, episodic_env_return=50.0\n",
      "[2023-09-13 14:31:36][INFO] global_step=153160, episodic_reward_predictor_return=1.274096131324768\n",
      "[2023-09-13 14:31:36][INFO] global_step=153160, episodic_env_return=-79.0\n",
      "[2023-09-13 14:31:37][INFO] global_step=153176, episodic_reward_predictor_return=0.1528330147266388\n",
      "[2023-09-13 14:31:37][INFO] global_step=153176, episodic_env_return=33.0\n",
      "[2023-09-13 14:31:37][INFO] global_step=153184, episodic_reward_predictor_return=0.5044817924499512\n",
      "[2023-09-13 14:31:37][INFO] global_step=153184, episodic_env_return=58.0\n",
      "[2023-09-13 14:31:38][INFO] global_step=153272, episodic_reward_predictor_return=0.4686278998851776\n",
      "[2023-09-13 14:31:38][INFO] global_step=153272, episodic_env_return=76.0\n",
      "[2023-09-13 14:31:39][INFO] global_step=153336, episodic_reward_predictor_return=0.5619184374809265\n",
      "[2023-09-13 14:31:39][INFO] global_step=153336, episodic_env_return=47.0\n",
      "[2023-09-13 14:31:40][INFO] global_step=153360, episodic_reward_predictor_return=3.192138910293579\n",
      "[2023-09-13 14:31:40][INFO] global_step=153360, episodic_env_return=-82.0\n",
      "[2023-09-13 14:31:41][INFO] global_step=153424, episodic_reward_predictor_return=2.203103542327881\n",
      "[2023-09-13 14:31:41][INFO] global_step=153424, episodic_env_return=-21.0\n",
      "[2023-09-13 14:31:42][INFO] global_step=153504, episodic_reward_predictor_return=0.15018868446350098\n",
      "[2023-09-13 14:31:42][INFO] global_step=153504, episodic_env_return=83.0\n",
      "[2023-09-13 14:31:43][INFO] global_step=153560, episodic_reward_predictor_return=0.5619287490844727\n",
      "[2023-09-13 14:31:43][INFO] global_step=153560, episodic_env_return=51.0\n",
      "[2023-09-13 14:31:44][INFO] Current Mean Episodic Return = 0.8494783639907837\n",
      "[2023-09-13 14:31:44][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_153600`...\n",
      "[2023-09-13 14:31:44][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_153600`!\n",
      "[2023-09-13 14:31:47][INFO] SPS: 21\n",
      "[2023-09-13 14:31:47][INFO] global_step=153608, episodic_reward_predictor_return=0.7645902633666992\n",
      "[2023-09-13 14:31:47][INFO] global_step=153608, episodic_env_return=59.0\n",
      "[2023-09-13 14:31:47][INFO] global_step=153616, episodic_reward_predictor_return=0.7730854749679565\n",
      "[2023-09-13 14:31:47][INFO] global_step=153616, episodic_env_return=46.0\n",
      "[2023-09-13 14:31:49][INFO] global_step=153776, episodic_reward_predictor_return=1.3399662971496582\n",
      "[2023-09-13 14:31:49][INFO] global_step=153776, episodic_env_return=46.0\n",
      "[2023-09-13 14:31:51][INFO] global_step=153856, episodic_reward_predictor_return=0.7933821678161621\n",
      "[2023-09-13 14:31:51][INFO] global_step=153856, episodic_env_return=47.0\n",
      "[2023-09-13 14:31:52][INFO] global_step=153960, episodic_reward_predictor_return=0.07454660534858704\n",
      "[2023-09-13 14:31:52][INFO] global_step=153960, episodic_env_return=-35.0\n",
      "[2023-09-13 14:31:52][INFO] global_step=153968, episodic_reward_predictor_return=1.066580057144165\n",
      "[2023-09-13 14:31:52][INFO] global_step=153968, episodic_env_return=56.0\n",
      "[2023-09-13 14:31:53][INFO] global_step=154008, episodic_reward_predictor_return=0.5088039636611938\n",
      "[2023-09-13 14:31:53][INFO] global_step=154008, episodic_env_return=52.0\n",
      "[2023-09-13 14:31:54][INFO] global_step=154064, episodic_reward_predictor_return=1.0034676790237427\n",
      "[2023-09-13 14:31:54][INFO] global_step=154064, episodic_env_return=31.0\n",
      "[2023-09-13 14:31:55][INFO] global_step=154128, episodic_reward_predictor_return=1.1745206117630005\n",
      "[2023-09-13 14:31:55][INFO] global_step=154128, episodic_env_return=-17.0\n",
      "[2023-09-13 14:31:55][INFO] global_step=154152, episodic_reward_predictor_return=0.9275801181793213\n",
      "[2023-09-13 14:31:55][INFO] global_step=154152, episodic_env_return=54.0\n",
      "[2023-09-13 14:32:00][INFO] global_step=154440, episodic_reward_predictor_return=0.8226456642150879\n",
      "[2023-09-13 14:32:00][INFO] global_step=154440, episodic_env_return=54.0\n",
      "[2023-09-13 14:32:00][INFO] global_step=154464, episodic_reward_predictor_return=0.6351743936538696\n",
      "[2023-09-13 14:32:00][INFO] global_step=154464, episodic_env_return=29.0\n",
      "[2023-09-13 14:32:00][INFO] global_step=154464, episodic_reward_predictor_return=0.7560557126998901\n",
      "[2023-09-13 14:32:00][INFO] global_step=154464, episodic_env_return=38.0\n",
      "[2023-09-13 14:32:01][INFO] global_step=154504, episodic_reward_predictor_return=0.5949589014053345\n",
      "[2023-09-13 14:32:01][INFO] global_step=154504, episodic_env_return=54.0\n",
      "[2023-09-13 14:32:02][INFO] global_step=154544, episodic_reward_predictor_return=1.910872459411621\n",
      "[2023-09-13 14:32:02][INFO] global_step=154544, episodic_env_return=-22.0\n",
      "[2023-09-13 14:32:02][INFO] global_step=154552, episodic_reward_predictor_return=0.3080846071243286\n",
      "[2023-09-13 14:32:02][INFO] global_step=154552, episodic_env_return=90.0\n",
      "[2023-09-13 14:32:02][INFO] global_step=154584, episodic_reward_predictor_return=0.95187908411026\n",
      "[2023-09-13 14:32:02][INFO] global_step=154584, episodic_env_return=29.0\n",
      "[2023-09-13 14:32:05][INFO] global_step=154736, episodic_reward_predictor_return=0.9014654159545898\n",
      "[2023-09-13 14:32:05][INFO] global_step=154736, episodic_env_return=28.0\n",
      "[2023-09-13 14:32:07][INFO] global_step=154880, episodic_reward_predictor_return=2.2162578105926514\n",
      "[2023-09-13 14:32:07][INFO] global_step=154880, episodic_env_return=-27.0\n",
      "[2023-09-13 14:32:07][INFO] global_step=154888, episodic_reward_predictor_return=0.4036509394645691\n",
      "[2023-09-13 14:32:07][INFO] global_step=154888, episodic_env_return=59.0\n",
      "[2023-09-13 14:32:09][INFO] global_step=154984, episodic_reward_predictor_return=1.0375529527664185\n",
      "[2023-09-13 14:32:09][INFO] global_step=154984, episodic_env_return=33.0\n",
      "[2023-09-13 14:32:09][INFO] global_step=154984, episodic_reward_predictor_return=0.2521054148674011\n",
      "[2023-09-13 14:32:09][INFO] global_step=154984, episodic_env_return=36.0\n",
      "[2023-09-13 14:32:09][INFO] global_step=155000, episodic_reward_predictor_return=0.5354769229888916\n",
      "[2023-09-13 14:32:09][INFO] global_step=155000, episodic_env_return=34.0\n",
      "[2023-09-13 14:32:13][INFO] global_step=155256, episodic_reward_predictor_return=0.3581484258174896\n",
      "[2023-09-13 14:32:13][INFO] global_step=155256, episodic_env_return=55.0\n",
      "[2023-09-13 14:32:13][INFO] global_step=155264, episodic_reward_predictor_return=0.3351988196372986\n",
      "[2023-09-13 14:32:13][INFO] global_step=155264, episodic_env_return=30.0\n",
      "[2023-09-13 14:32:15][INFO] global_step=155360, episodic_reward_predictor_return=0.9308962225914001\n",
      "[2023-09-13 14:32:15][INFO] global_step=155360, episodic_env_return=41.0\n",
      "[2023-09-13 14:32:15][INFO] global_step=155408, episodic_reward_predictor_return=0.4285052716732025\n",
      "[2023-09-13 14:32:15][INFO] global_step=155408, episodic_env_return=48.0\n",
      "[2023-09-13 14:32:19][INFO] Current Mean Episodic Return = 0.8076093196868896\n",
      "[2023-09-13 14:32:19][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_155648`...\n",
      "[2023-09-13 14:32:19][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_155648`!\n",
      "[2023-09-13 14:32:22][INFO] SPS: 21\n",
      "[2023-09-13 14:32:24][INFO] global_step=155784, episodic_reward_predictor_return=0.7135804891586304\n",
      "[2023-09-13 14:32:24][INFO] global_step=155784, episodic_env_return=35.0\n",
      "[2023-09-13 14:32:25][INFO] global_step=155808, episodic_reward_predictor_return=0.7507011294364929\n",
      "[2023-09-13 14:32:25][INFO] global_step=155808, episodic_env_return=45.0\n",
      "[2023-09-13 14:32:25][INFO] global_step=155840, episodic_reward_predictor_return=0.7798987030982971\n",
      "[2023-09-13 14:32:25][INFO] global_step=155840, episodic_env_return=-11.0\n",
      "[2023-09-13 14:32:27][INFO] global_step=155984, episodic_reward_predictor_return=1.3109545707702637\n",
      "[2023-09-13 14:32:27][INFO] global_step=155984, episodic_env_return=29.0\n",
      "[2023-09-13 14:32:30][INFO] global_step=156136, episodic_reward_predictor_return=3.014636278152466\n",
      "[2023-09-13 14:32:30][INFO] global_step=156136, episodic_env_return=-93.0\n",
      "[2023-09-13 14:32:31][INFO] global_step=156176, episodic_reward_predictor_return=0.6938837170600891\n",
      "[2023-09-13 14:32:31][INFO] global_step=156176, episodic_env_return=55.0\n",
      "[2023-09-13 14:32:35][INFO] global_step=156416, episodic_reward_predictor_return=2.827448844909668\n",
      "[2023-09-13 14:32:35][INFO] global_step=156416, episodic_env_return=-133.0\n",
      "[2023-09-13 14:32:37][INFO] global_step=156576, episodic_reward_predictor_return=0.9025180339813232\n",
      "[2023-09-13 14:32:37][INFO] global_step=156576, episodic_env_return=46.0\n",
      "[2023-09-13 14:32:37][INFO] global_step=156584, episodic_reward_predictor_return=0.9477831721305847\n",
      "[2023-09-13 14:32:37][INFO] global_step=156584, episodic_env_return=50.0\n",
      "[2023-09-13 14:32:39][INFO] global_step=156664, episodic_reward_predictor_return=3.391132354736328\n",
      "[2023-09-13 14:32:39][INFO] global_step=156664, episodic_env_return=-74.0\n",
      "[2023-09-13 14:32:40][INFO] global_step=156752, episodic_reward_predictor_return=2.277865409851074\n",
      "[2023-09-13 14:32:40][INFO] global_step=156752, episodic_env_return=-20.0\n",
      "[2023-09-13 14:32:41][INFO] global_step=156832, episodic_reward_predictor_return=0.9968857765197754\n",
      "[2023-09-13 14:32:41][INFO] global_step=156832, episodic_env_return=-23.0\n",
      "[2023-09-13 14:32:44][INFO] global_step=156992, episodic_reward_predictor_return=0.7786781787872314\n",
      "[2023-09-13 14:32:44][INFO] global_step=156992, episodic_env_return=71.0\n",
      "[2023-09-13 14:32:44][INFO] global_step=157024, episodic_reward_predictor_return=0.5556567907333374\n",
      "[2023-09-13 14:32:44][INFO] global_step=157024, episodic_env_return=46.0\n",
      "[2023-09-13 14:32:44][INFO] global_step=157032, episodic_reward_predictor_return=2.5648834705352783\n",
      "[2023-09-13 14:32:44][INFO] global_step=157032, episodic_env_return=-30.0\n",
      "[2023-09-13 14:32:49][INFO] global_step=157296, episodic_reward_predictor_return=0.6906653046607971\n",
      "[2023-09-13 14:32:49][INFO] global_step=157296, episodic_env_return=43.0\n",
      "[2023-09-13 14:32:49][INFO] global_step=157320, episodic_reward_predictor_return=0.27811378240585327\n",
      "[2023-09-13 14:32:49][INFO] global_step=157320, episodic_env_return=60.0\n",
      "[2023-09-13 14:32:50][INFO] global_step=157400, episodic_reward_predictor_return=2.6049540042877197\n",
      "[2023-09-13 14:32:50][INFO] global_step=157400, episodic_env_return=-300.0\n",
      "[2023-09-13 14:32:51][INFO] global_step=157440, episodic_reward_predictor_return=0.6103344559669495\n",
      "[2023-09-13 14:32:51][INFO] global_step=157440, episodic_env_return=49.0\n",
      "[2023-09-13 14:32:53][INFO] global_step=157560, episodic_reward_predictor_return=0.7656634449958801\n",
      "[2023-09-13 14:32:53][INFO] global_step=157560, episodic_env_return=35.0\n",
      "[2023-09-13 14:32:55][INFO] Current Mean Episodic Return = 1.3728119134902954\n",
      "[2023-09-13 14:32:55][INFO] Saving models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_157696`...\n",
      "[2023-09-13 14:32:55][INFO] Successfully saved models to `./models/rlhf_pipeline/training_run_2023_09_13_12_30_28/doom_ppo_agent/checkpoint_step_157696`!\n",
      "[2023-09-13 14:32:58][INFO] SPS: 21\n"
     ]
    }
   ],
   "source": [
    "%gui asyncio\n",
    "\n",
    "from utils.env import make_vizdoom_env\n",
    "\n",
    "# Displaying UI and showing only the loading screen\n",
    "clear_output()\n",
    "display(layout)\n",
    "hide_all_screens()\n",
    "\n",
    "# Initializing environments with only the first enviroment rendering\n",
    "num_envs = pipeline_args.get('num_envs')\n",
    "envs = gym.vector.SyncVectorEnv([ make_vizdoom_env('envs/vizdoom/scenarios/basic.cfg', render_mode=\"human\" if i == 0 else None) for i in range(num_envs)])\n",
    "\n",
    "# Setting up agent and reward predictor\n",
    "agent = DoomPpoAgent(envs.single_observation_space,\n",
    "                     envs.single_action_space,\n",
    "                     learning_rate=agent_args.get('learning_rate'),\n",
    "                     use_gpu=pipeline_args.get('enable_gpu'))\n",
    "reward_predictor = DoomHumanPreferenceRewardPredictor(envs.single_observation_space,\n",
    "                                                      hidden_layer_size=reward_predictor_args.get('hidden_layer_size'), \n",
    "                                                      learning_rate=reward_predictor_args.get('learning_rate'),\n",
    "                                                      use_gpu=pipeline_args.get('enable_gpu'))\n",
    "\n",
    "if reward_predictor_args.get('model_path'):\n",
    "    log_info(f\"Loading reward predictor model from {reward_predictor_args.get('model_path')}...\")\n",
    "    reward_predictor.load_models(reward_predictor_args.get('model_path'))\n",
    "    log_info(f\"Successfully loaded reward predictor model from {reward_predictor_args.get('model_path')}!\")\n",
    "\n",
    "# Starting training process\n",
    "event_loop = asyncio.get_event_loop()\n",
    "training_task = event_loop.create_task(run_training_pipeline(envs, \n",
    "                                                             agent, \n",
    "                                                             reward_predictor,\n",
    "                                                             pipeline_args=pipeline_args,\n",
    "                                                             agent_args=agent_args,\n",
    "                                                             reward_predictor_args=reward_predictor_args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doom-rlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
